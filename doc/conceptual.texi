\input texinfo   @c -*-texinfo-*-
@c %**start of header
@setfilename conceptual.info
@settitle coNCePTuaL User's Guide
@setchapternewpage on
@include version.texi
@include langversion.texi
@dircategory Programming
@direntry
* coNCePTuaL: (conceptual).   A domain-specific language for network benchmarks
@end direntry
@finalout
@c Attempt to produce nicer typeset output.
@iftex
@raggedbottom
@tex
\global\topskip 1.25cm plus 0.75cm minus 0.25cm
@end tex
@end iftex
@c Declare indexes for nonterminals, keywords, command-line options,
@c environment variables, filenames, other-language functions, GUI menus
@c and menu items, and all of the above (plus keyboard commands,
@c variables, and concepts).
@defindex nt
@defcodeindex kw
@defcodeindex op
@defcodeindex ev
@defcodeindex fi
@defcodeindex ol
@defindex mn
@defindex al
@synindex nt al
@syncodeindex kw al
@syncodeindex op al
@syncodeindex ev al
@syncodeindex fi al
@syncodeindex ol al
@syncodeindex ky al
@synindex mn al
@synindex cp al
@syncodeindex vr al
@c %**end of header

@ifinfo
This file describes the coNCePTuaL language and tool suite.

Copyright (C) 2012, Los Alamos National Security, LLC
@end ifinfo

@c ===========================================================================

@c Define a macro for typesetting the coNCePTuaL logo.
@macro ncptl
@sc{coNCePTuaL}
@end macro

@c Older versions of Texinfo didn't provide a @LaTeX macro or a @comma
@c macro but newer ones do.  For TeX output, we simply require a newer
@c texinfo.tex.  Because makeinfo doesn't care about macro redefinitions,
@c we just go ahead and redefine @LaTeX and @comma for non-TeX output.
@iftex
@macro latex
@cindex LaTeX
@LaTeX
@end macro
@c
@end iftex
@ifnottex
@macro latex
@cindex LaTeX
LaTeX
@end macro
@c
@macro comma
,
@end macro
@end ifnottex

@c Define macros for typesetting command-line options.
@macro copt {option}
@opindex --\option\
@w{@kbd{-@w{}-\option\}}
@end macro
@macro coptargs {option, args}
@opindex --\option\
@w{@kbd{-@w{}-\option\=\args\}}
@end macro
@macro copts {option}
@opindex -\option\
@w{@kbd{-\option\}}
@end macro

@c Define macros for typesetting environment variables.
@macro envvar {evar}
@evindex \evar\
@cindex environment variables
@cindex variables, environment
@w{@kbd{\evar\}}
@end macro

@c Define a macro for indicating a nonterminal in the grammar.
@macro nonterm {ntname}
@ntindex \ntname\
@w{@r{@texmath{@langle, <}@var{\ntname\}@texmath{@rangle, >}}}
@end macro

@c Define macros for indicating keyboard commands.
@macro kcmd {command}
@kyindex \command\
@w{@kbd{\command\}}
@end macro
@macro kcmdargs {command, args}
@kyindex \command\
@w{@kbd{\command\ \args\}}
@end macro

@c Define a macro for indicating a filespec.
@macro filespec {fspec}
@fiindex \fspec\
@w{@file{\fspec\}}
@end macro

@c Define a macro for indicating a backend module or backend filespec.
@macro backend {bkend}
@fiindex codegen_@w{\bkend\}.py
@fiindex \bkend\@ (@file{codegen_\bkend\.py})
@code{\bkend\}
@end macro
@macro backendpy {bkend}
@fiindex codegen_@w{\bkend\}.py
@fiindex \bkend\@ (@file{codegen_\bkend\.py})
@w{@file{codegen_\bkend\.py}}
@end macro

@c Define a macro for indicating a coNCePTuaL keyword.
@macro keyw {token}
@kwindex \token\
@code{\token\}
@end macro

@c Define a macro for indicating code in a language other than coNCePTuaL.
@c (It can also be used to typeset a coNCePTuaL variable name.)  Also,
@c define a macro specifically for indicating a C function name.
@macro ocode {token}
@olindex \token\
@w{@code{\token\}}
@end macro
@macro ocodecf {token}
@olindex \token\
@w{@code{\token\()}}
@end macro

@c Define a macro for nicely typesetting mathematical expressions.
@macro texmath {texcode, othercode}
@iftex
@tex
$\texcode\$%
@end tex
@end iftex
@c
@ifnottex
@math{\othercode\}@c
@end ifnottex
@end macro

@c Define a macro for typesetting and indexing an arbitrary concept.
@macro cncp {concept}
@cindex \concept\
\concept\
@end macro

@c Define macros for typesetting a GUI menu, menu item, or button.
@macro gmenu {mname}
@mnindex \mname\ (GUI menu)
@cindex GUI menus
@cindex menus, GUI
@emph{\mname\}
@end macro
@macro gmenuitem {mname}
@mnindex \mname\ (GUI menu item)
@emph{\mname\}
@end macro
@macro gbutton {mname}
@mnindex \mname\ (GUI button)
@cindex GUI buttons
@cindex buttons, GUI
@emph{\mname\}
@end macro

@c Define a macro for typesetting the separator between a GUI menu and
@c another menu or a menu item.
@iftex
@macro glevelsep
@math{@rightarrow}
@end macro
@end iftex
@ifhtml
@macro glevelsep
@html
&rarr;
@end html
@end macro
@end ifhtml
@ifnottex
@ifnothtml
@macro glevelsep
->
@end macro
@end ifnothtml
@end ifnottex

@c Define macros for typesetting and indexing various common words and phrases.
@macro AST
@cindex abstract-syntax tree (AST)
@cindex AST (abstract-syntax tree)
AST
@end macro
@c
@macro configure {args}
@kyindex configure
@kbd{./configure \args\}
@end macro
@c
@macro GNU
@cncp{GNU}
@end macro
@c
@macro Linux
@cncp{Linux}
@end macro
@c
@macro Bourne
@cindex Bourne shell
Bourne
@end macro
@c
@macro cpreproc
@cindex C preprocessor
@w{C preprocessor}
@end macro
@c
@macro MPI
@cindex Message Passing Interface (MPI)
MPI
@end macro
@c
@macro TEX
@cindex TeX
@TeX{}
@end macro
@c
@macro PLY
@cindex Python Lex--Yacc (PLY)
PLY
@end macro
@c
@macro ncptlGUI
@cindex @sc{coNCePTuaL} GUI
@sc{coNCePTuaL} GUI
@end macro

@c Define a macro for indenting a paragraph within a list or table.
@iftex
@tex
\gdef\iindent{\hskip\defaultparindent\relax}
@end tex
@end iftex
@ifnottex
@macro iindent
@end macro
@end ifnottex

@c ===========================================================================

@titlepage

@iftex
@tex

% Undo Texinfo's default vertical spacing.
\vskip -\titlepagetopglue
\vfill

% Define some fonts.
\font\hsu=pagdc7t at 64pt
\font\hsl=pagkc7t at 64pt
\font\tbl=pagk7t at 28pt
\font\tiny=pagk7t at 14pt
\tbl

% Define a strut to force all rows to be the same height.
\setbox0=\hbox{Mg}%
\newdimen\strutht\strutht=\ht0
\newdimen\strutdp\strutdp=\dp0
\def\rowstrut{\vrule height \strutht depth \strutdp width 0pt}%

% Draw a top rule.
\leavevmode\leaders\hrule height 5pt\hfill\hbox{}
\vskip 1cm

% Draw a fancy coNCePTuaL logo.
\hfill\vbox{%
\halign{\hfil#\hfil&\hfil#\hfil&%
        \hfil#\hfil&\hfil#\hfil&%
        \hfil#\hfil&\hfil#\hfil&%
        \hfil#\hfil&\hfil#\hfil&%
        \hfil#\hfil&\hfil#\hfil\rowstrut\cr
\hsl c&\hsl o&\hsu N&\hsu C&\hsl e&\hsu P&\hsu T&\hsl u&\hsl a&\hsu L\cr
&&e&o&&e&e&&&a\cr
&&t&r&&r&s&&&n\cr
&&w&r&&f&t&&&g\cr
&{\tiny The}&o&e&{\tiny and}&o&i&&&u\cr
&&r&c&&r&n&&&a\cr
&&k&t&&m&g&&&g\cr
&& &n&&a& &&&e\cr
&& &e&&n& &&& \cr
&& &s&&c& &&& \cr
&& &s&&e& &&& \cr}%
}\hfill\hbox{}

% Draw a bottom rule.
\vskip 0.5cm
\leavevmode\leaders\hrule height 5pt\hfill\hbox{}

% List the author using the default author font.
\vbox{}\vfill
\hfill \authorfont Scott Pakin, \email{pakin@@lanl.gov}
\finishedtitlepagetrue

% If we're using pdfTeX in PDF-generating mode then include some
% document metadata.
\ifx\pdfoutput\undefined
\else
  \ifx\pdfoutput\relax
  \else
    \ifcase\pdfoutput
    \else
      \pdfinfo {
        /Title   (coNCePTuaL User's Guide)
        /Subject (Documentation for the coNCePTuaL toolset)
        /Author  (Scott Pakin <pakin@@lanl.gov>)
        /Keywords (networking, performance testing, benchmarking,
                   communication, domain-specific languages)
      }
    \fi
  \fi
\fi

@end tex
@end iftex

@ifnottex
@title coNCePTuaL
@subtitle The Network Correctness and Performance Testing Language
@author Scott Pakin @email{pakin@@lanl.gov}
@end ifnottex

@page
@vskip 0pt plus 1filll
@hfil
Copyright @copyright{} 2012, Los Alamos National Security, LLC
@hfil
@vskip 0pt plus 1filll
This document describes @ncptl{} @w{version @value{VERSION}.}

@end titlepage

@c ===========================================================================

@ifnottex
@node Top, Introduction, (dir), (dir)
@ifnothtml
@top coNCePTuaL
@end ifnothtml

This document presents a simple, special-purpose language called
@ncptl{}@.  @ncptl{} is intended for rapidly generating programs that
measure the performance and/or test the correctness of networks and
network protocol layers.  A few lines of @ncptl{} code can produce
programs that would take significantly more effort to write in a
conventional programming language.

This document describes @ncptl{} @w{version @value{VERSION}.}

@ifhtml
@html
<!----
@end html
@end ifhtml
@menu
* Introduction::                Introduction to coNCePTuaL and this manual
* Installation::                Installing coNCePTuaL on your computer
* Usage::                       Running the compiler and related tools
* Grammar::                     Specification of the coNCePTuaL grammar
* Examples::                    Examples of complete coNCePTuaL programs
* Implementation::              How coNCePTuaL is implemented
* Tips and Tricks::             Helpful advice for using coNCePTuaL
* Troubleshooting::             Diagnosing coNCePTuaL errors
* Reserved Words::              Lists of token names not available as varaibles
* Backend Developer's Reference::  Lists of importance to backend developers
* Environment Variables::       List of environment variables honored
* Cache Variables::             List of variables used by the configure script
* Referenced Applications::     URLs for applications mentioned in this manual
* License::                     The coNCePTuaL copyright and license agreement
* Index::                       Index to terms used in this manual
@end menu
@ifhtml
@html
---->
@end html
@end ifhtml
@end ifnottex

@contents

@node Introduction, Installation, Top, Top
@chapter Introduction

This document presents a simple, special-purpose language called
@ncptl{}@.  @ncptl{} is intended for rapidly generating programs that
measure the performance and/or test the correctness of networks and
network protocol layers.  A few lines of @ncptl{} code can produce
programs that would take significantly more effort to write in a
conventional programming language.

@ncptl{} is not merely a language specification.  The @ncptl{} toolset
includes a compiler, run-time library, and associated utility programs
that enable users to analyze network behavior quickly, conveniently,
and accurately.

@menu
* Motivation::                  Why there's a need for coNCePTuaL
* Limitations::                 Things coNCePTuaL can't do
* Typesetting conventions::     How to read this manual
@end menu


@node Motivation, Limitations, Introduction, Introduction
@section Motivation

A frequently reinvented wheel among network researchers is a suite of
programs that test a network's performance.  A problem with having
umpteen versions of performance tests is that it leads to a variety in
the way results are reported; colloquially, apples are often compared
to oranges.  Consider a bandwidth test.  Does a bandwidth test run for
a fixed number of iterations or a fixed length of time?  Is bandwidth
measured as ping-pong bandwidth @w{(i.e., 2 @texmath{\times, *}}
message @w{length @texmath{\div, /}} round-trip time) or
unidirectional throughput @w{(@math{N} messages} in one direction
followed by a single acknowledgement message)?  Is the acknowledgement
message of minimal length or as long as the entire message?  Does its
length contribute to the total bandwidth?  Is data sent
unidirectionally or in both directions at once?  How many warmup
messages (if any) are sent before the timing loop?  Is there a delay
after the warmup messages (to give the network a chance to reclaim any
scarce resources)?  Are receives nonblocking (possibly allowing
overlap in the NIC) or blocking?

The motivation behind creating @ncptl{}, a simple specification
language designed for describing network benchmarks, is that it
enables a benchmark to be described sufficiently tersely as to fit
easily in a report or research paper, facilitating peer review of the
experimental setup and timing measurements.  Because @ncptl{} code is
simple to write, network tests can be developed and deployed with low
turnaround times---useful when the results of one test suggest a
following test that should be written.  Because @ncptl{} is
special-purpose its run-time system can perform the following
functions, which benchmark writers often neglect to implement:

@itemize @bullet
@item
logging information about the environment under which the benchmark
ran: operating system, CPU architecture and clock speed, timer type
and resolution, etc.

@item
aborting a program if it takes longer than a predetermined length of
time to complete

@item
writing measurement data and descriptive statistics to a variety of
output formats, including the input formats of various graph-plotting
programs
@end itemize

@noindent
@ncptl{} is not limited to network peformance tests, however.  It can
also be used for network verification.  That is, @ncptl{} programs can
be used to locate failed links or to determine the frequency of bit
errors---even those that may sneak past the network's CRC hardware.

In addition, because @ncptl{} is a very high-level language, the
@ncptl{} compiler's backend has a great deal of potential.  It would
be possible for the backend to produce a variety of target formats
such as @w{Fortran +} @MPI{}, @w{Perl +} sockets, @w{C +} a network
vendor's low-level messaging layer, and so forth.  It could directly
manipulate a network simulator.  It could feed into a graphics program
to produce a space-time diagram of a @ncptl{} program.  The
possibilities are endless.


@node Limitations, Typesetting conventions, Motivation, Introduction
@section Limitations

Although @ncptl{} can express a wide variety of race-free
communication patterns it cannot currently express data-dependent
communication.  For example, @ncptl{} canot express a master-worker
pattern in which a master task sends a message to a worker task as a
reaction to that particular worker's sending of a message to the
master.  Such a communication pattern is not independent of the order
in which messages happen to arrive from the workers.  Similarly,
@ncptl{} cannot use run-time performance data to guide its operations.
It is therefore not currently possible to express a communication
benchmark that repeats until the standard error of some performance
metric drops below a given threshold.  These limitations may be lifted
in a future release of the system.


@node Typesetting conventions,  , Limitations, Introduction
@section Typesetting conventions
@cindex typesetting conventions

The following table showcases the typesetting conventions used in this
manual to attribute various meanings to text.  Note that not all of
the conventions are typographically distinct.

@c Be sure to keep the following table entries up-to-date with
@c the appropriate macros.

@cartouche
@table @asis
@c @copts and @copt
@item @w{@kbd{-a}}
@itemx @w{@kbd{-@w{}-abcdef}}
command-line options (e.g., @copts{C} or @copt{help})

@c @envvar
@item @w{@kbd{ABCDEF}}
environment variables (e.g., @envvar{PATH})

@c @nonterm
@item @w{@texmath{@langle, <}@var{abcdef}@texmath{@rangle, >}}
nonterminals in the @ncptl{} grammar (e.g., @nonterm{ident})

@c @kcmd
@item @w{@kbd{abcdef}}
commands to enter on the keyboard (e.g., @kcmd{make install})

@c @filespec
@item @w{@file{abcdef}}
file and directory names (e.g., @filespec{conceptual.pdf})

@c @keyw
@item @code{ABCDEF}
@ncptl{} keywords (e.g., @keyw{RECEIVE})

@c @code
@item @code{abcdef}
variables, constants, functions, and types in any language (e.g.,
@code{bit_errors} or @code{gettimeofday()})

@c @var
@item @var{abcdef}
metasyntactic variables and formal function parameters (e.g.,
@var{fan-out})

@c @samp
@item @samp{abcdef}
snippets of code, command lines, files, etc.@: (e.g., @samp{10 MOD 3})
@end table
@end cartouche


@node Installation, Usage, Introduction, Top
@chapter Installation
@cindex installation

@ncptl{} uses the @GNU{} Autotools (@cncp{Autoconf}, @cncp{Automake},
and @cncp{Libtool}) to increase portability, to automate compilation,
and to facilitate installation.  As of this writing, @ncptl{} has
passed @kcmd{make check} (@pxref{make}) on the following platforms:

@c Put all compiler names in an equal-widthed box.
@macro compbox {text}
@iftex
@tex
@hbox to 5em{@filespec{\text\}}
@end tex
@end iftex
@ifnottex
@filespec{\text\}
@end ifnottex
@end macro

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item @b{Architecture} @tab @b{OS} @tab @b{Compiler}
@item IA-32         @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{icc}      (Intel)
@item               @tab           @tab @compbox{opencc}   (Open64)
@item               @tab FreeBSD   @tab @compbox{gcc}      (@GNU{})
@item               @tab OpenBSD   @tab @compbox{gcc}      (@GNU{})
@item               @tab NetBSD    @tab @compbox{gcc}      (@GNU{})
@item               @tab Solaris   @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{cc}       (Sun)
@item               @tab Syllable  @tab @compbox{gcc}      (@GNU{})
@item               @tab Windows @* (via @cncp{Cygwin}) @tab @compbox{gcc} (@GNU{})
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item @cncp{x86-64} @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{pgcc}     (PGI)
@item               @tab           @tab @compbox{pathcc}   (PathScale)
@item               @tab           @tab @compbox{llvm-gcc} (LLVM)
@item               @tab           @tab @compbox{clang}    (LLVM)
@item               @tab Catamount @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{pgcc}     (PGI)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item IA-64         @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{ecc}      (Intel)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item PowerPC       @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{xlc}      (IBM)
@item               @tab AIX       @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{xlc}      (IBM)
@item               @tab MacOS X   @tab @compbox{gcc}      (@GNU{})
@item               @tab BLRTS     @tab @compbox{xlc}      (IBM)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item Cell (Power)  @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item Cray X1       @tab UNICOS/mp @tab @compbox{cc}       (Cray)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item UltraSPARC    @tab Solaris   @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{cc}       (Sun)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item MIPS          @tab IRIX      @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{cc}       (MIPSpro)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item Alpha         @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{ccc}      (HP)
@item               @tab Tru64     @tab @compbox{gcc}      (@GNU{})
@item               @tab           @tab @compbox{cc}       (HP)
@end multitable

@sp 1

@multitable {@b{Architecture}M} {UNICOS/mpM} {@file{MMMMMMM} (PathScale)M}
@item ARM           @tab @Linux{}  @tab @compbox{gcc}      (@GNU{})
@end multitable

@sp 1

In its simplest form, @ncptl{} installation works by executing the
following commands at the operating-system prompt:

@kyindex configure
@kyindex make
@kyindex make install
@cartouche
@example
./configure
make
make install
@end example
@end cartouche

@noindent
(@filespec{configure} is normally run as @configure{} to force it
to run from the current directory on the assumption that @file{.} is
not in the executable search path.)  We now describe those three
installation steps in detail, listing a variety of customization
options for each step.

@menu
* configure::                   Create a customized Makefile for your system
* make::                        Compile the coNCePTuaL run-time library
* make install::                Install coNCePTuaL in your system
@end menu


@node configure, make, Installation, Installation
@section @kbd{configure}

@filespec{configure} is a @Bourne{}-shell script that analyzes your
system's capabilities (compiler features, library and header-file
availability, function and datatype availability, linker flags for
various options, etc.) and custom-generates a @filespec{Makefile} and
miscellaneous other files.  @filespec{configure} accepts a variety of
command-line options.  @configure{@copt{help}} lists all of the
options.  The following are some of the more useful ones:

@table @asis
@item @copt{disable-shared}
@ncptl{} normally installs both static and dynamic libraries.  While
dynamic libraries have a number of advantages they do need to be
installed on all nodes that run the compiled @ncptl{} programs.  If
global installation is not convenient/feasible, @copt{disable-shared}
can be used to force static linking of executables.  Note, however,
that @filespec{libncptlmodule.so}, the @cncp{Python} interface to the
@ncptl{} run-time library, needs to be built as a shared object so
that it can be loaded dynamically into a running @cncp{Python} interpreter.
@copt{disable-shared} inhibits the compilation and installation of
@filespec{libncptlmodule.so}.

@item @kbd{@copt{prefix}=@var{directory}}
@kyindex make install
@kcmd{make install} normally installs @ncptl{} into the
@file{/usr/local} directory.  The @copt{prefix} option instructs
@filespec{configure} to write a @filespec{Makefile} with a different
installation directory.  For example,
@kbd{@copt{prefix}=/local/encap/conceptual-@value{VERSION}} will cause
@ncptl{}'s files to be installed in
@file{/local/encap/conceptual-@value{VERSION}/bin},
@file{/local/encap/conceptual-@value{VERSION}/include}, etc.

@item @kbd{@copt{with-ignored-libs}=@var{lib1},@var{lib2},@enddots{}}
In some circumstances it may be necessary to prevent @ncptl{} from
using certain libraries even when @configure{} detects them and
believes them to be usable.  The @copt{with-ignored-libs}
configuration option forces @configure{} to ignore one or more
specified libraries.  Only the base name of each library should be
used; omit directory names, the @samp{lib} prefix (on Unix-like
systems), and the file suffix.  For example, to disable the use of
@file{/usr/local/lib/libpapi.a} you should specify @coptargs{with-ignored-libs, papi}.

@item @copt{without-fork}
@configure{} detects automatically if your system provides a working
@ocodecf{fork} function.  However, it cannot detect if @ocodecf{fork}
correctly spawns a child process but corrupts the parent's memory map
while doing so, as is the case when using some @cncp{InfiniBand}
software stacks.  The @copt{without-fork} option inhibits the use of
@ocodecf{fork} and well as functions that implicitly invoke
@ocodecf{fork} such as @ocodecf{system} and @ocodecf{popen}.

@item @copt{with-gettimeofday}
The @ncptl{} run-time library is able to use any of a variety of
platform-specific microsecond timers to take timing measurements.
(@xref{Time-related functions}, for a complete list.)  The
@copt{with-gettimeofday} option forces the run-time library to utilize
instead the generic C @ocodecf{gettimeofday} function.  This can be
useful in the rare, but not impossible, case that a quirk in some
particular platform misleads one of @ncptl{}'s other timers.  The
@filespec{validatetimer} utility (@pxref{Validating the coNCePTuaL
timer}) can help determine whether @copt{with-gettimeofday} is
necessary.

@item @copt{with-mpi-wtime}
On some systems the most accurate timer available is provided by the
@ocodecf{MPI_Wtime} function in the @MPI{} library.  The
@copt{with-mpi-wtime} option forces the run-time library to measure
elapsed time using @ocodecf{MPI_Wtime} instead of any of the other
available timers.  (@xref{Time-related functions}, for a complete
list).  The ramifications of @copt{with-mpi-wtime} are threefold:

@enumerate
@item
The option requires that you link all @ncptl{} programs against an
@MPI{} library and run them like any other @MPI{} program.  (You may
need to set @envvar{CPPFLAGS}, @envvar{LIBS}, @envvar{LDFLAGS}, or
some of the other command-line variables described below.)

@item
@ocodecf{MPI_Wtime} may be @emph{less} accurate than some of the other
timers available to @ncptl{}@.  In many @MPI{} implementations,
@ocodecf{MPI_Wtime} simply invokes @ocodecf{gettimeofday}, for
instance.

@item
Although this is a rare problem, it may not be safe to invoke
@ocodecf{MPI_Wtime} without first invoking @ocodecf{MPI_Init}.
Fortunately, proper juxtaposition of the two functions is not a
concern for the @ncptl{} C+@MPI{} backend (@pxref{The c_mpi backend}),
which ensures that @ocodecf{MPI_Init} is invoked before
@ocodecf{MPI_Wtime}.
@end enumerate

In short, you should specify @copt{with-mpi-wtime} only if you have
good reason to believe that @ocodecf{MPI_Wtime} is likely to produce
the most accurate timing measurements on your system.

@item @kbd{@envvar{CC}=@var{C compiler}}
@filespec{configure} automatically searches for a C compiler to use.
To override its selection, assign a value to @envvar{CC} on the
command line.  For example, @configure{CC=ecc} will cause @ncptl{} to
be built with @filespec{ecc}.

@item @kbd{@envvar{CFLAGS}=@var{C compiler flags}}
@itemx @kbd{@envvar{LDFLAGS}=@var{linker flags}}
@itemx @kbd{@envvar{CPPFLAGS}=@var{C preprocessor flags}}
@itemx @kbd{@envvar{LIBS}=@var{extra libraries}}
@cindex C preprocessor
Like @envvar{CC}, these variables override the values determined
automatically by @filespec{configure}.  As an illustration,
@configure{@w{CPPFLAGS="-DSPECIAL} @w{-I/home/pakin/include/special}
@w{-I."}  @w{CFLAGS="-O3} -g -Wall -W" @w{LDFLAGS=--static}
@w{LIBS="-lz} /usr/lib/libstuff.a"} assigns values to all four
variables.

@item @kbd{@envvar{MPICC}=@var{C compiler}}
@itemx @kbd{@envvar{MPICPPFLAGS}=@var{C preprocessor flags}}
@itemx @kbd{@envvar{MPILDFLAGS}=@var{extra linker flags}}
@itemx @kbd{@envvar{MPILIBS}=@var{extra libraries}}
@cindex C preprocessor
These variables are analagous to @envvar{CC}, @envvar{CPPFLAGS},
@envvar{LDFLAGS}, and @envvar{LIBS}, respectively.  The difference is
that they are not used to build the @ncptl{} run-time library but
rather to build user programs targeted to the C+@MPI{} compiler backend.
For example, if your @MPI{} installation lacks an @filespec{mpicc}
script, you may need to specify extra header files and libraries
explicitly: @configure{@w{MPICPPFLAGS="-I/usr/lib/mpi/include"}
@w{MPILIBS="-lmpich"}}.
@end table

As a rather complex illustration of how some of the preceding options
(as well as a few mentioned by @configure{@copt{help}}) might be
combined, the following is how @ncptl{} was once configured to
cross-compile from a @Linux{}/PowerPC build machine to a prototype of the
BlueGene/L supercomputer (containing, at the time, 2048 embedded
PowerPC processors, each executing a minimal run-time system, BLRTS).
IBM's @filespec{xlc} compiler was accessed via a wrapper script called
@file{mpcc}.

@quotation
@configure{CFLAGS="-g -O -qmaxmem=64000" CC=/bgl/local/bin/mpcc
CPP="gcc -E" @w{--host=powerpc-ibm-linux-gnu}
@w{--build=powerpc-unknown-linux-gnu} @w{--with-alignment=8}
@w{--with-gettimeofday} @w{--prefix=/bgl/bgguest/LANL/ncptl}
MPICC=/bgl/local/bin/mpcc CPPFLAGS=-I/BlueLight/floor/bglsys/include}
@end quotation

It's always best to specify environment variables as arguments to
@configure{} because the @filespec{configure} script writes its entire
command line as a comment to @filespec{config.log} and as a shell
command to @filespec{config.status} to enable re-running @configure{}
with exactly the same parameters.

@sp 1

@cpindex warnings
When @configure{} finishes running it outputs a list of the warning
messages that were issued during the run.  If no warnings were issued,
@configure{} will output @samp{Configuration completed without any
errors or warnings.}.  Warnings are also written to
@filespec{config.log} and can therefore be redisplayed at any time by
executing a shell command such as @kbd{grep WARNING config.log}.


@node make, make install, configure, Installation
@section @kbd{make}

@kyindex make
Running @kcmd{make} by itself will compile the @ncptl{} run-time
library.  However, the @filespec{Makefile} generated by @filespec{configure}
can perform a variety of other actions, as well:

@table @kcmd
@item make check

Perform a series of regression tests on the @ncptl{} run-time library.
This is a good thing to do after a @kcmd{make} to ensure that the
run-time library built properly on your system.  When
@kcmd{make check} finishes it summarizes the test results.  The
following output signifies a successful completion of
@kcmd{make check}:

@cartouche
@example
===================
All 21 tests passed
===================
@end example
@end cartouche

@noindent
The total number of tests performed depends upon the way that @ncptl{}
was configured.  @ncptl{} components that could not be built are not
tested.

@iindent
If any tests behave unexpectedly it may be possible to gain more
information about the source of the problem by re-running @kcmd{make
check} with the @envvar{DEBUG} environment variable set to a non-empty
value:

@kyindex make check
@cartouche
@example
env DEBUG=1 make check
@end example
@end cartouche

@noindent
Tests can also be re-run individually:

@kyindex runtime_random
@cartouche
@example
cd tests
env DEBUG=1 runtime_random
@end example
@end cartouche


@item make clean
@itemx make distclean
@itemx make maintainer-clean

@kcmd{make clean} deletes all files generated by a preceding
@kcmd{make} command.  @kcmd{make distclean} deletes all files
generated by a preceding @w{@configure{}} command.  @kcmd{make
maintainer-clean} delete all generated files.  Run @kcmd{make
maintainer-clean} only if you have fairly recent versions of the
@GNU{} Autotools @w{(@cncp{Autoconf} 2.53,} @w{@cncp{Automake} 1.6,}
and @w{@cncp{Libtool} 1.4)} because those are needed to regenerate
some of the generated files.  The sequence of operations to regenerate
all of the configuration files needed by @ncptl{} is shown below.

@cartouche
@kyindex libtoolize
@kyindex aclocal
@kyindex autoheader
@kyindex automake
@kyindex autoconf
@example
libtoolize --force --copy
aclocal
autoheader
automake --add-missing --copy
autoconf
@end example
@end cartouche

@item make install

Install @ncptl{}, including the compiler, run-time library, header
files, and tools.  @kcmd{make install} is described in detail
in @ref{make install}.

@item make uninstall

Remove all of the files that @kcmd{make install} installed.  Most of
the top-level directories are retained, however, as @filespec{make}
cannot guarantee that these are not needed by other applications.

@item make info
@itemx make pdf
@itemx make docbook

Produce the @ncptl{} user's guide (this document) in, respectively,
@cncp{Emacs} info format, PDF format, or DocBook format.  The
resulting documentation (@filespec{conceptual.info*},
@filespec{conceptual.pdf}, or @filespec{conceptual.xml}) is created in
the @file{doc} subdirectory.

@item make ncptl-logextract.html

@ncptl{} comes with a postprocessor called @filespec{ncptl-logextract}
that facilitates extracting information from @ncptl{}-produced log
files.  The complete @filespec{ncptl-logextract} documentation is
presented in @ref{ncptl-logextract}.  As is readily apparent from that
documentation, @filespec{ncptl-logextract} supports an overwhelming
number of command-line options.  To make the
@filespec{ncptl-logextract} documentation more approachable, the
@kcmd{make ncptl-logextract.html} command creates a dynamic HTML
version of it (and stores in the @file{doc} subdirectory).  The
result, @filespec{ncptl-logextract.html}, initially presents only the
top level of the @filespec{ncptl-logextract} option hierarchy.  Users
can then click on the name of a command-line option to expand or
contract the list of subobtions.  This interactive behavior makes it
easy for a user to get more information on some options without being
distracted by the documentation for the others.

@item make empty.log

Create an empty log file called @filespec{empty.log} that contains a
complete prologue and epilogue but no data.  This is convenient for
validating that the @ncptl{} run-time library was built using your
preferred build options.

@item make stylesheets

@cindex syntax highlighting
@cindex stylesheets
@cindex coloring source listings
@ncptl{} can automatically produce stylesheets for a variety of
programs.  These stylesheets make keywords, comments, strings, and
other terms in the language visually distinct from each other for a
more aesthetically appealing appearance.
Currently, @kcmd{make stylesheets} produces a
@iftex
@tex
@latex@kern.15em2$_{@textstyle@varepsilon}$
@end tex
@end iftex
@ifnottex
La@TeX{}2e
@end ifnottex
package (@filespec{ncptl.sty}), an @cncp{a2ps} style sheet
(@filespec{ncptl.ssh}), an @cncp{Emacs} major mode
(@filespec{ncptl-mode.el} and @filespec{ncptl-mode.elc}), a @cncp{Vim}
syntax file (@filespec{ncptl.vim}), a @cncp{Source-highlight} language
definition (@filespec{ncptl.lang}), and a @cncp{GeSHi} language file
(@filespec{ncptl.php}).  Each of these can be built individually if
desired.  (For example, @kcmd{make ncptl-mode.vim} will create only
@filespec{ncptl-mode.vim}.)  Note that the @filespec{Makefile}
currently lacks provisions for installing these files so whichever
stylesheets are desired will need to be installed manually.
Stylesheet installation is detailed in @ref{Installing stylesheets}.

@item make modulefile

The @cncp{Environment Modules} package facilitates configuring the
operating-system shell for a given application.  The @kcmd{make
modulefile} command creates a @filespec{conceptual_@value{VERSION}}
modulefile that checks for conflicts with previously loaded @ncptl{}
modulefiles then sets the @envvar{PATH}, @envvar{MANPATH}, and
@envvar{LD_LIBRARY_PATH} environment variables to values appropriate
values as determined by @filespec{configure} (@pxref{configure}).

@iindent
Normally, @filespec{conceptual_@value{VERSION}} should be installed in
the system's module path (as described by the @envvar{MODULEPATH}
environment variable).  However, users without administrator access
can still use the @ncptl{} modulefile as a convenient mechanism for
properly setting all of the environment variables needed by @ncptl{}:

@cartouche
@kyindex make modulefile
@example
make modulefile
module load ./conceptual_@value{VERSION}
@end example
@end cartouche

@noindent
See the @filespec{module} man page for more information about modules.

@item make dist

Package together all of the files needed to rebuild @ncptl{}@.  The
resulting file is called @filespec{conceptual-@value{VERSION}.tar.gz} (for
this version of @ncptl{}).

@item make all

Although @kbd{all} is the default target it can also be specified
explicitly.  Doing so is convenient when performing multiple actions
at once, e.g., @kcmdargs{make, clean all}.

@item make tags

Produce/update a @filespec{TAGS} file that the @cncp{Emacs} text
editor can use to find function declarations, macro definitions,
variable definitions, @code{typedef}s, etc.@: in the @ncptl{} run-time
library source code.  This is useful primarily for developers wishing
to interface with the @ncptl{} run-time library.  Read the
@cncp{Emacs} documentation for @w{@kbd{M-x find-tag}} for more
information.

@item make gui

Compile the @ncptlGUI{}, producing
@filespec{ncptlGUI-@value{VERSION}.jar}.  Note that compilation
requires both a @cncp{Java} compiler @w{(e.g., @kcmd{javac})} and the
@cncp{Jython} @cncp{Python}-to-@cncp{Java} compiler (@kcmd{jythonc}).
Unfortunately, at the time of this writing (January 2009),
@kcmd{jythonc}'s future is uncertain
(@w{cf. @uref{http://www.jython.org/Project/jythonc.html}}).  Hence,
@kcmd{make gui} has been tested only with @kcmd{jythonc} @w{version
2.2.@var{x}}, not any later versions.

@end table

@menu
* Validating the coNCePTuaL timer::  Ensuring timing results are meaningful
@end menu


@node Validating the coNCePTuaL timer,  , make, make
@subheading Validating the coNCePTuaL timer
@cindex timer validation

@kcmd{make} automatically builds a program called
@filespec{validatetimer}.  @filespec{validatetimer} helps validate
that the real-time clock used by the @ncptl{} run-time library
accurately measures wall-clock time.  The idea is to compare
@ncptl{}'s timer to an external clock (i.e., one not associated with
the computer).  Simply follow the program's prompts:

@cartouche
@example
% validatetimer
Press <Enter> to start the clock ...
Press <Enter> again in exactly 60 seconds ...

coNCePTuaL measured 60.005103 seconds.
coNCePTuaL timer error = 0.008505%
@end example
@end cartouche

If the difference between @ncptl{}'s timer and an external clock is
significant, then performance results from @ncptl{}---and possibly
from other programs, as well---should not be trusted.  Note that only
extreme differences in timings are significant; there will always be
@emph{some} error caused by human response time and by system I/O
speed.  In the case that there @emph{is} an extreme performance
difference,@footnote{To date, extreme performance differences have
been observed primarily on PowerPC-based systems.  The PowerPC cycle
counter is clocked at a different rate from the CPU speed, which may
confuse @ncptl{}@.  The run-time library compensates for this behavior
on all tested platforms (@pxref{Installation}), but the user should
nevertheless make sure to run @filespec{validatetimer} to verify that
@ncptl{}'s timer is sufficiently accurate.}  the
@copt{with-gettimeofday} option to @filespec{configure}
(@pxref{configure}) may be a viable workaround.

@filespec{validatetimer} takes an optional command-line argument,
which is the number of seconds of wall-clock time to expect.  The
default is @samp{60}.  Larger numbers help amortize error; smaller
numbers enable the program to finish sooner.


@node make install,  , make, Installation
@section @kbd{make install}

@kyindex make install
The @ncptl{} compiler and run-time library are installed with
@kcmd{make install}.  Although @filespec{configure} can specify the
default installation directory (@pxref{configure}), this can be
overridden at @kcmd{make install} time in one of two ways.
@kcmdargs{make, DESTDIR=@var{prefix} install} prepends @var{prefix} to
every directory when installing.  However, the files are installed
believing that @kbd{DESTDIR} was not specified.  For example,
@kcmdargs{make, DESTDIR=/mnt install} would cause executables to be
installed into @file{/mnt/usr/local/bin}, but if any of these are
symbolic links, the link will omit the @file{/mnt} prefix.

The second technique for overriding installation directories is to
specify a new value for @samp{prefix} on the command line.  That is,
@kcmdargs{make, prefix=/opt/ncptl install} will install into
@file{/opt/ncptl/bin}, @file{/opt/ncptl/include},
@file{/opt/ncptl/man}, etc., regardless of the @copt{prefix} value
given to @filespec{configure}.  @ncptl{}'s @filespec{Makefile}
provides even finer-grained control than that.  Instead of---or in
addition to---specifying a @kbd{prefix} option on the command line,
individual installation directories can be named explicitly.  These
include @kbd{bindir}, @kbd{datadir}, @kbd{libdir}, @kbd{includedir},
@kbd{infodir}, @kbd{mandir}, @kbd{pkgdatadir}, @kbd{pythondir}, and
many others.  Scrutinize the @filespec{Makefile} to find a particular
directory that should be overridden.

The remainder of this section presents a number of optional
installation steps that add @ncptl{} support to a variety of
third-party software packages.

@menu
* Installing stylesheets::      Where to put the various stylesheet files
* SLOCCount::                   Automatically counting lines of coNCePTuaL code
* pkg-config::                  Linking with the coNCePTuaL run-time library
@end menu


@node Installing stylesheets, SLOCCount, make install, make install
@subheading Installing stylesheets
@cindex syntax highlighting
@cindex stylesheets
@cindex coloring source listings

The @kcmd{make stylesheets} command (@pxref{make}) produces a variety
of stylesheets for presenting @ncptl{} code in a more pleasant format
than ordinary, monochromatic text.  Stylesheets must currently be
installed manually as per the following instructions:

@table @filespec
@item ncptl.sty

@filespec{ncptl.sty} is typically installed in
@file{@var{texmf}/tex/latex/misc}, where @var{texmf} is likely to be
@file{/usr/local/share/texmf}.  On a Web2c version of @TEX{}@: the
command @kcmdargs{kpsewhich, -expand-var='$TEXMFLOCAL'} should output
the correct value of @var{texmf}.  In most @TEX{}@: distributions the
filename database needs to be refreshed after a new package is
installed.  See
@uref{http://www.tex.ac.uk/cgi-bin/texfaq2html?label=instpackages} for
more information.  @filespec{ncptl.sty} is merely a customization of
the @filespec{listings} package that defines a new language called
@samp{ncptl}.  See the @filespec{listings} documentation for
instructions on typesetting source code.

@item ncptl.ssh

Running @kcmdargs{a2ps, --list=defaults} outputs (among other things)
the @cncp{a2ps} library path.  @filespec{ncptl.ssh} should be
installed in one of the @filespec{sheets} directories listed there,
typically @file{/usr/share/a2ps/sheets}.

@item ncptl-mode.el
@itemx ncptl-mode.elc

@filespec{ncptl-mode.el} and @filespec{ncptl-mode.elc} belong in a
local Elisp directory that is part of the @cncp{Emacs}
@code{load-path}, e.g., @file{/usr/share/emacs/site-lisp}.  The
following Elisp code, which belongs in @file{~/.emacs} for @GNU{}
@cncp{Emacs} or @file{~/.xemacs/init.el} for @cncp{XEmacs}, makes
@cncp{Emacs} set @code{ncptl-mode} whenever opening a file with
extension @file{.ncptl}:

@cartouche
@example
(autoload 'ncptl-mode "ncptl-mode"
  "Major mode for editing coNCePTuaL programs." t)
(add-to-list 'auto-mode-alist '("\\.ncptl$" . ncptl-mode))
@end example
@end cartouche

@noindent
Syntax highlighting should be enabled by default.  If it isn't, the
@cncp{Emacs} command @kcmd{M-x font-lock-mode} should enable it for
the current buffer.

@item ncptl.vim

@cncp{Vim}'s syntax-file directory may be named after the @cncp{Vim}
version, e.g., @file{/usr/share/vim/vim61/syntax} for @w{Vim 6.1}.
Put @filespec{ncptl.vim} there.  To associate @file{.ncptl} files with
@ncptl{} code, the following lines need to be added to @cncp{Vim}'s
@filespec{filetype.vim} file somewhere between the @samp{augroup
filetypedetect} line and the @samp{augroup END} line:

@cartouche
@example
" coNCePTuaL
au BufNewFile,BufRead *.ncptl           setf ncptl
@end example
@end cartouche

@item ncptl.lang

@cncp{Source-highlight} stores all of its helper files in a single
directory, typically @file{/usr/share/source-highlight}.  Put
@filespec{ncptl.lang} there.  To associate @file{.ncptl} files with
@ncptl{} code you will also need to add the following line to the
@filespec{lang.map} file in the same directory:

@cartouche
@example
ncptl = ncptl.lang
@end example
@end cartouche

@item ncptl.php

@cncp{GeSHi} stores all of its language files in a @file{geshi}
subdirectory.  Simply put @filespec{ncptl.php} there, and it should be
ready for use.  A quick way to convert @ncptl{} programs to
color-coded HTML is to use the command-line version of the @cncp{PHP}
interpreter with the following shell script.

@cartouche
@example
#!/usr/bin/env php

<html>
<head>
<title><?php echo basename($argv[1]); ?></title>
</head>
<body>
<?php
include("@var{GeSHi_directory}/geshi.php");
$ncptl_code = file_get_contents($argv[1]);
geshi_highlight($ncptl_code, "ncptl");
?>
</body>
</html>
@end example
@end cartouche

@noindent
Simply replace @var{GeSHi_directory} with the name of your top-level
@cncp{GeSHi} directory and run the script with the name of a @ncptl{}
file as its sole argument.

A @cncp{GeSHi} extension for @cncp{Mediawiki} introduces a
@samp{<syntaxhighlight>} tag for presenting color-coded program
listings on a wiki.  @filespec{ncptl.php} makes it easy to use
@ncptl{} code in this context.

@end table

@node SLOCCount, pkg-config, Installing stylesheets, make install
@subheading SLOCCount

@cncp{SLOCCount} is a utility that counts the number of lines of code
in a file, excluding blank lines and comments.  @cncp{SLOCCount}
supports a variety of programming languages and it is straightforward
to get it to support @ncptl{}, as well.  The procedure follows the
``Adding support for new languages'' section of the @cncp{SLOCCount}
manual:

@enumerate
@item
Create an @file{ncptl_count} script with the following contents:

@cartouche
@example
#! /bin/sh

generic_count "#" $@@
@end example
@end cartouche

@item
Mark the script executable and install it somewhere in your executable
search path.

@item
Edit @cncp{SLOCCount}'s @file{break_filelist} Perl script to include the
following association in the @code{%file_extensions} hash:

@cartouche
@example
  "ncptl" => "ncptl",    # coNCePTuaL
@end example
@end cartouche
@end enumerate


@node pkg-config,  , SLOCCount, make install
@subheading pkg-config

The @cncp{pkg-config} utility helps ensure that programs are given
appropriate compiler and linker flags to use a particular package's C
header files and libraries.  @ncptl{}'s @filespec{configure} script
(@pxref{configure}) automatically produces a @cncp{pkg-config}
configuration file for the @ncptl{} header file (@filespec{ncptl.h})
and run-time library (@filespec{libncptl}).  This configuration file,
@filespec{ncptl.pc}, should be installed in one of the directories
searched by @cncp{pkg-config} (@file{/usr/lib/pkgconfig} on some
systems).  Once @filespec{ncptl.pc} is installed, @cncp{pkg-config}
can be used to compile C programs that require the @ncptl{} header
file and link programs that require the @ncptl{} run-time library, as
is shown in the following example:

@cartouche
@example
cc `pkg-config --cflags ncptl` -c myprog.c
cc -o myprog myprog.o `pkg-config --libs ncptl`
@end example
@end cartouche


@node Usage, Grammar, Installation, Top
@chapter Usage

@ncptl{} is more than just a language; it is a complete toolset that
consists of the following components:

@itemize @bullet
@item
the @ncptl{} language (@pxref{Grammar})

@item
a compiler and run-time library for @ncptl{} programs
(@pxref{Compiling coNCePTuaL programs})

@item
a set of compiler backends that can generate code for a variety of
languages and communication layers (@pxref{Supplied backends})

@item
utilities to help analyze the results (@pxref{ncptl-logextract})
@end itemize

This chapter explains how to compile and run @ncptl{} programs and how
to interpret the log files they output.

@menu
* The coNCePTuaL GUI::          Drawing communication patterns
* Compiling coNCePTuaL programs::  Options accepted by the compiler
* Supplied backends::           Descriptions of the standard backends
* Running coNCePTuaL programs::  Options accepted by coNCePTuaL programs
* Interpreting coNCePTuaL log files::  Understanding program output
@end menu


@node The coNCePTuaL GUI, Compiling coNCePTuaL programs, Usage, Usage
@section The coNCePTuaL GUI
@cindex graphical user interface

The @ncptl{} graphical user interface (GUI) is the easiest way to get
started with @ncptl{}.  Instead of writing code in the @ncptl{}
language (documented in detail in @ref{Grammar}), a user merely
@emph{draws} a communication pattern using the mouse, and the
@ncptlGUI{} automatically produces a @ncptl{} program from that
illustration.  The generated program can then be compiled just like a
hand-coded @ncptl{} program as per the instructions in @ref{Compiling
coNCePTuaL programs}.

The @ncptlGUI{} is written in @cncp{Java} and therefore requires a
@cncp{Java} virtual machine (JVM) to run.  However, the @ncptlGUI{} is
quite portable and should run identically on every platform for which
a JVM exists.  The following is a typical command for launching the
@ncptlGUI{} from the command line:

@cartouche
@example
@fiindex ncptlGUI-@value{VERSION}.jar
java -jar ncptlGUI-@value{VERSION}.jar
@end example
@end cartouche

The @ncptlGUI{} is split into two main panels. The @emph{program
panel} displays the components that make up the program and how they
interact with each other.  The @emph{dialog panel} displays fields for
setting the options of selected components.  Furthermore, a @emph{menu
bar} provides access to various GUI-wide operations, and a
@emph{command bar} includes buttons for creating new components in the
program panel.

@c The following TeX trickery is needed because of the way epsf.tex
@c operates differently in DVI and PDF modes.
@iftex
@tex
\ifpdf
  @center @image{gui, 0.8@pagewidth}
\else
  @center @image{gui, 4.8in}
\fi
@end tex
@end iftex
@ifnottex
@center @image{gui, , , Screenshot of the coNCePTuaL GUI}
@end ifnottex


@menu
* Components::                  Graphical representations of coNCePTuaL objects
* Menu bar::                    Operations performed by each menu item
* Command bar::                 Operations performed by each button
@end menu


@node Components, Menu bar, The coNCePTuaL GUI, The coNCePTuaL GUI
@subsection Components
@cindex components, GUI

Components are graphical representations of @ncptl{} objects and
operations used by the @ncptlGUI{} to specify programs.  Components
are added to the program panel by clicking on their corresponding
buttons in the command bar.  To select a component in the program
panel, simply left-click on it.  If the component has parameters that
can be edited, a dialog will appear in the dialog panel.  Multiple
components can be selected by dragging the mouse over target
components or holding down Ctrl as you left-click on several
components.

The @ncptlGUI{} lets a user manipulate the following components:

@table @asis
@item task/task row
Tasks represent operational units in @ncptl{} programs and are
analogous to a process or thread in a parallel program.  For example,
a @ncptl{} operation like point-to-point communication has a source
task that specifies how the message is sent and a target task that
specifies how the message is received.  Tasks are displayed
graphically as numbered circles in the @ncptlGUI{}@.  A task row
represents the total number of tasks available for operations at each
step of a @ncptl{} program.  @xref{Task descriptions}, for information
on how to specify subsets of a program's tasks.

@item communication message
Messages between tasks are displayed as directed edges (arrows) from
source task to target task in the @ncptlGUI{}@.  Messages are added to
the program panel via the command bar or by dragging the mouse from a
source task to a target task.  Communication messages in the
@ncptlGUI{} correspond to the @keyw{SEND} and @keyw{RECEIVE}
statements in the @ncptl{} language (@pxref{Sending}, and
@ref{Receiving}).

@item awaiting completion
Messages that are sent/received asynchronously must eventually be
waited on.  Awaits message completion is displayed as a solid line
under the associated tasks in the @ncptlGUI{}@.  Awaiting completion
in the @ncptlGUI{} correspond to the @keyw{AWAIT COMPLETION} statement
in the @ncptl{} language (@pxref{Awaiting completion}).

@item loop
One can add a loop around selected components to repeat the
corresponding @ncptl{} operations.  Loops in the @ncptlGUI{}
correspond to the @keyw{FOR} statement in the @ncptl{} language
(@pxref{Iterating}).

@item measurement block
One can log timing or other measurements of @ncptl{} operations by
placing them in a measurement block.  Measurement blocks in the
@ncptlGUI{} correspond to the @keyw{LOGS} statement in the @ncptl{}
language (@pxref{Writing to a log file}).

@item computation/sleeping
Artificial computation (really a spin loop) and sleeping, both of
which delay the program for a given length of time, can be performed
on a set of tasks.  Computation is shown with @samp{cmp} under a task
in the @ncptlGUI{}, and sleeping is shown with @samp{slp}.
Computation/sleeping in the @ncptlGUI{} corresponds to the
@keyw{COMPUTE} and @keyw{SLEEP} statements in the @ncptl{} language
(@pxref{Delaying execution}).

@item multicasting
A multicast operation sends a message from a source task to multiple
target tasks.  Multicasting in the @ncptlGUI{} corresponds to the
@keyw{MULTICAST} statement in the @ncptl{} language
(@pxref{Multicasting}).

@item reduction
A reduction operation combines messages from multiple source tasks to
a single target task.  Reduction in the @ncptlGUI{} corresponds to the
@keyw{REDUCE} statement in the @ncptl{} language (@pxref{Reducing}).

@item synchronization
Barrier synchronization forces a set of tasks to wait until each task
in the set reaches the synchronization point before any task in the
set proceeds past the synchronization point.  Synchronization is
displayed as a dotted line under the associated tasks in the
@ncptlGUI{}@.  Synchronization in the @ncptlGUI{} corresponds to the
@keyw{SYNCHRONIZE} statement in the @ncptl{} language
(@pxref{Synchronizing}).
@end table

@node Menu bar, Command bar, Components, The coNCePTuaL GUI
@subsection Menu bar

The @gmenu{File} menu, which appears only when the @ncptlGUI{} is
granted access to the filesystem, contains @gmenuitem{New},
@gmenuitem{Open}, @gmenuitem{Save}, @gmenuitem{Save As},
@gmenuitem{Print}, and @gmenuitem{Quit} commands that exhibit the
expected behavior.  Programs are saved as @ncptl{} source code that
can then be compiled with the @ncptl{} compiler as per @ref{Compiling
coNCePTuaL programs}.  @gmenuitem{Print} prints a graphical view of
the program as it appears on screen.  (@xref{The latex_vis backend},
for a more sophisticated way to produce graphical views of @ncptl{}
programs.)

The @gmenu{Edit} menu provides the usual @gmenuitem{Cut},
@gmenuitem{Copy}, @gmenuitem{Paste}, and @gmenuitem{Undo} commands.

@gmenu{Options}@glevelsep{}@gmenuitem{Settings} opens a dialog in the
dialog panel for setting the number of tasks in a task row. The
default number of tasks in a task row is 16.

@gmenu{Advanced}@glevelsep{}@gmenuitem{Add conditional} adds a
conditional statement to a program at the current cursor position in
the program panel.  A dialog in the dialog panel will open for
entering the conditional expression.  A placeholder expression @samp{1
= 1} is set by default.

@gmenu{Advanced}@glevelsep{}@gmenuitem{Command line options} opens a
dialog in the dialog panel for adding command-line options to a
program.  A placeholder @samp{reps} (@samp{number of repetitions})
option is set by default when this command is selected.


@node Command bar,  , Menu bar, The coNCePTuaL GUI
@subsection Command bar

The following buttons appear on the command bar:

@table @gbutton
@item Add Row
Insert a new, empty task row at the cursor position.

@item Delete
Delete the selected components.

@item Loop
Add a loop around the selected components.

@item Measure
Add a measurement block around the selected components.

@item Compute
Make the selected tasks ``compute'' or sleep for a length of time.

@item Communicate
Add point-to-point communication between selected tasks (different
task rows).  This can also be achieved by dragging an arrow from a
source task to a target task.

@item Wait
Make the selected tasks (same task row) or all tasks in the row above
the cursor wait for all outstanding messages sent or received
asynchronously to complete.

@item Extend
Extend a communication or computation pattern across an entire task
row.

@item Synchronize
Synchronize the selected tasks (same task row) or all tasks in the
task row above the cursor.

@item Reduce
Reduce data from the selected tasks in one task row to the selected
tasks in the next task row.  With no selection, reduce data from all
tasks above the cursor to @w{task 0} below the cursor.

@item Multicast
Multicast data from the selected tasks in one task row to the selected
tasks in the next task row.  With no selection, multicast data from
@w{task 0} above the cursor to all tasks below the cursor.

@item Normalize
Put the program into standard form as it will appear when translated
into @ncptl{} code.  After normalization, components are drawn as
early in time as possible without changing the program's semantics.
@end table


@node Compiling coNCePTuaL programs, Supplied backends, The coNCePTuaL GUI, Usage
@section Compiling coNCePTuaL programs
@cindex compiling

The @ncptl{} compiler is called @filespec{ncptl} and is, by default,
installed into @file{/usr/local/bin}.  Executing @kbd{ncptl
@copt{help}} produces a brief usage string:

@cartouche
@example
Usage: ncptl [--backend=<string>] [--quiet] [--no-link | --no-compile]
         [--keep-ints] [--lenient] [--filter=<sed expr>] [--output=<file>]
         <file.ncptl> | --program=<program>
         [<backend-specific options>]

       ncptl --help

       ncptl [--backend=<string>] --help-backend
@end example
@end cartouche

@noindent
The usage string is followed by a list of installed backends.

The following list describes each compiler option in turn:

@table @asis
@item @copt{backend} (abbreviation: @copts{b})
Specify the module that @ncptl{} should use as the compiler backend.
@kcmd{ncptl} must be told which backend to use with either
@kbd{@copt{backend}=@var{backend}} or by setting the environment
variable @envvar{NCPTL_BACKEND} to the desired backend.  Running
@kcmdargs{ncptl, --help} lists the available backends.  Most @ncptl{}
backends are code generators.  For example, @backend{c_mpi} causes
@filespec{ncptl} to compile @ncptl{} programs into C using @MPI{} as the
communication library.  However, a backend need not generate code
directly---or at all.  The @backend{c_trace} backend (@pxref{The
c_trace backend}), for instance, supplements the code generated by
another backend by adding tracing output to it.

@iindent
@kcmd{ncptl} searches for backends first using @envvar{NCPTL_PATH}, an
environment variable containing a colon-separated list of directories
(default: empty); then, in the directory in which @ncptl{} installed
all of its @cncp{Python} files; and finally, in the default
@cncp{Python} search path.  Non-directories (e.g., the @file{.zip}
archives used in newer versions of @cncp{Python}) are not searched.

@iindent
If no backend is specified, @kcmd{ncptl} runs the given @ncptl{}
program through the lexer, parser, and semantic analyzer but does not
generate an output file.

@item @copt{quiet} (abbreviation: @copts{q})
The @copt{quiet} option tells @filespec{ncptl} and the chosen backend
to output minimal status information.

@item @copt{no-link} (abbreviation: @copts{c})
By default, @filespec{ncptl} instructs the backend to compile and link
the user's @ncptl{} program into an executable file.  @copt{no-link}
tells the backend to skip the linking step and produce only an object
file.

@item @copt{no-compile} (abbreviation: @copts{E})
By default, @filespec{ncptl} instructs the backend to compile and link
the user's @ncptl{} program into an executable file.
@copt{no-compile} tells the backend to skip both the compilation and
the linking step and to produce only a source file in the target
language.

@item @copt{keep-ints} (abbreviation: @copts{K})
@ncptl{} backends normally delete any files created as part of the
compiling or linking process.  @copt{keep-ints} tells @filespec{ncptl}
and the chosen backend to preserve their intermediate files.

@item @copt{lenient} (abbreviation: @copts{L})
The @copt{lenient} option tells the compiler to permit certain
constructs that would otherwise result in a compilation error.  First,
using the same command-line option (either the long or short variant)
for two different variables normally generates an @samp{Option
@var{opt} is multiply defined} error.  (@xref{Command-line arguments},
for a description of how to declare command-line options in @ncptl{}@.)
@copt{lenient} tells the @ncptl{} compiler to automatically rename
duplicate options to avoid conflicts.  Only the option strings can be
renamed; the programmer must still ensure that the option variables
are unique.  Second, using a variable without declaring it normally
produces an error message at compile time.  Passing @copt{lenient} to
@filespec{ncptl} tells the compiler to automatically generate a
command-line option for each missing variable.  This is convenient
when entering brief programs on the command line with @copt{program}
(described below) as it can save a significant amount of typing.

@item @copt{filter} (abbreviation: @copts{f})
The @copt{filter} option applies a @filespec{sed}-style substitution
expression to the backend-translated code @w{(e.g., a} @file{.c} file
output by the @backend{c_udgram} backend or a @file{.tex} file output
by the @backend{latex_vis} backend) before the backend compiles it.
The @copt{filter} option can be used multiple times on the command
line; filters are applied in the order specified.  Substitution
expressions must be of the form
@samp{s/@var{pattern}/@var{replacement}/@var{flags}}, although the
@samp{/} characters can be replaced by any other character.
@var{pattern} is a regular expression; @var{replacement} is an
optional replacement string; and, @var{flags} is a sequence of zero or
more modifiers from the set @{@samp{i}, @samp{l}, @samp{m}, @samp{s},
@samp{u}, @samp{x}@}, as described in the @cncp{Python} Library Reference.
For example, @samp{i} means to perform a case-insensitive
substitution.  In addition, the @samp{g} flag performs a global
search-and-replace instead of replacing only the first occurrence of
@var{pattern}.  An important difference between @copt{filter} and
@filespec{sed} is that omitting the @samp{g} flag instructs
@copt{filter} to make at most one substitution @emph{total} while it
instructs @filespec{sed} to make at most one substitution @emph{per
line}.

@item @copt{output} (abbreviation: @copts{o})
@filespec{ncptl} normally writes its output to a file with the same
base name as the input file (or @filespec{a.out} if the program was
specified on the command line using @copt{program}).  @copt{output}
lets the user specify a file to which to write the generated code.

@item @copt{program} (abbreviation: @copts{p})
Because @ncptl{} programs can be quite short @copt{program} enables a
program to be specified in its entirety on the command line.  The
alternative to using @copt{program} is to specify the name of a file
containing a @ncptl{} program.  By convention, @ncptl{} programs have
a @file{.ncptl} file extension.

@item @copt{help-backend} (abbreviation: @copts{H})
Describe additional options that are meaningful only to the specified
backend.  The @copt{backend} option must be used in conjunction with
@copt{help-backend}.
@end table

The following---to be entered without line breaks---is a sample
command line:

@example
ncptl --backend=c_mpi --output=sample.c --program='Task 0 sends a 0
  byte message to task 1 then task 1 sends a 0 byte message to task 0
  then task 0 logs elapsed_usecs/2 as "Startup latency (usecs)".'
@end example

@filespec{ncptl} stops processing the command line at the first
unrecognized option it encounters.  That option and all subsequent
options---including those which @filespec{ncptl} would otherwise
process---are passed to the backend without interpretation by
@filespec{ncptl}.  Furthermore, the @copt{} @w{(i.e., empty)} option
tells @filespec{ncptl} explicitly to stop processing the command line
at that point.  For example, in the command @kbd{ncptl
--backend=some_backend --lenient myprogram.ncptl -- --program},
@filespec{ncptl} will process the @copt{backend} and @copt{lenient}
options but will pass @copt{program} to the @code{some_backend}
backend even though @filespec{ncptl} has its own @copt{program}
option.@footnote{As an aside, @copt{help-backend} is essentially
equivalent to @samp{-- --help}; the @copt{help-backend} synonym is
provided merely for convenience.}


@node Supplied backends, Running coNCePTuaL programs, Compiling coNCePTuaL programs, Usage
@section Supplied backends
@cindex backends, supplied

The @w{@ncptl{} @value{VERSION}} distribution includes the following
compiler backends:

@table @backend
@item c_seq
Generate @w{ANSI C} code with no communication support.

@item c_mpi
Generate @w{ANSI C} code with calls to the @MPI{} library for
communication.

@item c_udgram
Generate @w{ANSI C} code that communicates using Unix-domain (i.e.,
local to a single machine) datagram sockets.

@item c_trace
Instrument a C-based backend either to include a call to
@ocodecf{fprintf} before every program event or to utilize the
@filespec{curses} library to display graphically the execution of a
selected task.

@item c_profile
Instrument a C-based backend either to write event timings and tallies
to each log file or to the standard error device if the @ncptl{}
program doesn't use a log file.

@item interpret
Interpret a @ncptl{} program, simulating any number of processors and
checking for common problems such as deadlocks and mismatched sends
and receives.

@item stats
Output statistics of a program's execution---message tallies, byte
counts, communication peers, network bisection crossings, event
tallies, etc.

@item picl
Output in the @cncp{PICL} trace format a logical-time trace of a
@ncptl{} program's communication pattern.

@item paraver
Output in the @cncp{Paraver} trace format a logical-time trace of a
@ncptl{} program's communication pattern.

@item latex_vis
Use @latex{} to produce an Encapsulated @cncp{PostScript}
visualization of a program's communication pattern.

@item dot_ast
Output a program's parse tree in the @cncp{Graphviz} @cncp{dot} format.
@end table

@ncptl{} employs a highly modular software structure for its backends.
Many of the backends listed above are built atop other backends.  The
following figure illustrates the current set of dependencies:

@sp 1
@center @image{backend-deps}
@sp 1

Some dependencies are defined as a static characteristic of a backend.
For example, the @backend{c_mpi} backend is hardwired to derive some
of its functionality from @backend{c_generic}.  Other dependencies are
determined dynamically.  For example, the @backend{c_trace} backend
must be instructed to derive its functionality from one of
@backend{c_profile}, @backend{c_mpi}, @backend{c_udgram}, or
@backend{c_seq}.  (@xref{The c_trace backend}, for more information on
the @backend{c_trace} backend.)

Except for @backend{c_generic}, all of the compiler backends are
described in turn in the following sections.  The @backend{c_generic}
backend is unique because it is used exclusively to construct C-based
backends; it does nothing by itself.  @xref{Backend creation}, for a
detailed description of @backend{c_generic}.

Each backend accepts a @copt{help} option that explains the backend's
command-line options.  The easiest way to request help from a specific
backend is with @samp{ncptl --backend=@var{backend} -- --help}.  The
empty @copt{} option, mentioned in @ref{Compiling coNCePTuaL
programs}, prevents the compiler from intercepting @copt{help} and
providing the standard, backend-independent information.


@menu
* The c_seq backend::           ANSI C, sequential code only
* The c_mpi backend::           ANSI C + MPI
* The c_udgram backend::        ANSI C + Unix-domain datagram sockets
* The c_trace backend::         Instrument any of the above with tracing output
* The c_profile backend::       Profile events in any of the above
* The interpret backend::       Interpret coNCePTuaL programs
* The stats backend::           Report statistics on a program's execution
* The picl backend::            Trace a coNCePTuaL program's logical execution
* The paraver backend::         Trace a coNCePTuaL program's logical execution
* The latex_vis backend::       Visualize a communication pattern
* The dot_ast backend::         Graphviz DOT format (show abstract-syntax tree)
* The libsea_ast backend::      CAIDA LibSea format (show abstract-syntax tree)
@end menu


@node The c_seq backend, The c_mpi backend, Supplied backends, Supplied backends
@subsection The @code{c_seq} backend

The @backend{c_seq} backend is intended primarily to provide backend
developers with a minimal C-based backend that can be used as a
starting point for creating new backends.  @xref{Backend creation},
explains how to write backends.


@node The c_mpi backend, The c_udgram backend, The c_seq backend, Supplied backends
@subsection The @code{c_mpi} backend

The @backend{c_mpi} backend is @ncptl{}'s workhorse.  It generates
parallel programs written in @w{ANSI C} that communicate using the
industry-standard @MPI{} messaging library.

By default, @backend{c_mpi} produces an executable program that can be
run with @filespec{mpirun}, @filespec{prun}, @filespec{pdsh}, or
whatever other job-launching program is normally used to run @MPI{}
programs.  When @filespec{ncptl} is run with the @copt{no-link}
option, @backend{c_mpi} produces an object file that needs to be
linked with the appropriate @MPI{} library.  When @filespec{ncptl} is run
with the @copt{no-compile} option, @backend{c_mpi} outputs @w{ANSI C}
code that must be both compiled and linked.

@backend{c_mpi} honors the following environment variables when
compiling and linking C+@MPI{} programs: @envvar{MPICC},
@envvar{MPICPPFLAGS}, @envvar{MPICFLAGS}, @envvar{MPILDFLAGS},
@envvar{MPILIBS}.  If any of these variables is not found in the
environment, @backend{c_mpi} will use the value specified/discovered
at configuration time (@pxref{configure}).  @envvar{MPICC} defaults to
the value of @envvar{CC}; @envvar{MPICFLAGS} defaults to the value of
@envvar{CFLAGS}; the remaining variables are appended respectively to
@envvar{CPPFLAGS}, @envvar{LDFLAGS}, and @envvar{LIBS}.

The following is a complete list of @MPI{} functions employed by the
@backend{c_mpi} backend: @ocodecf{MPI_Allreduce},
@ocodecf{MPI_Alltoallv}, @ocodecf{MPI_Barrier}, @ocodecf{MPI_Bcast},
@ocodecf{MPI_Comm_group}, @ocodecf{MPI_Comm_rank},
@ocodecf{MPI_Comm_size}, @ocodecf{MPI_Comm_split},
@ocodecf{MPI_Errhandler_create}, @ocodecf{MPI_Errhandler_set},
@ocodecf{MPI_Finalize}, @ocodecf{MPI_Group_translate_ranks},
@ocodecf{MPI_Init}, @ocodecf{MPI_Irecv}, @ocodecf{MPI_Isend},
@ocodecf{MPI_Recv}, @ocodecf{MPI_Reduce}, @ocodecf{MPI_Send},
@ocodecf{MPI_Ssend}, @ocodecf{MPI_Waitall}.  In addition, if
@configure{} is passed the @copt{with-mpi-wtime} option as described
in @ref{configure}, then @emph{all} backends that utilize the @ncptl{}
run-time library, including @backend{c_mpi}, will use
@ocodecf{MPI_Wtime} for taking performance measurements.

@menu
* Command-line options for c_mpi::  Control over the generated C+MPI code
* Implementation of reductions::  How c_mpi implements the REDUCE statement
* Implementation of multicasts::  How c_mpi implements the MULTICAST statement
@end menu


@node Command-line options for c_mpi, Implementation of reductions, The c_mpi backend, The c_mpi backend
@subsubheading Command-line options for @code{c_mpi}

When @filespec{ncptl} is passed @kbd{@copt{backend}=c_mpi} as a
command-line option, @backend{c_mpi} processes the following
backend-specific command-line options:

@table @asis
@item @copt{ssend}
In the generated code, @ocodecf{MPI_Isend} and @ocodecf{MPI_Irecv} are
used for asynchronous communication and @ocodecf{MPI_Send} and
@ocodecf{MPI_Recv} are normally used for synchronous communication.
However, the @backend{c_mpi}-specific compiler option @copt{ssend}
instructs @backend{c_mpi} to replace all calls to @ocodecf{MPI_Send}
in the generated code with calls to @ocodecf{MPI_Ssend}, @MPI{}'s
synchronizing send function.  A program's log files indicate whether
the program was built to use @ocodecf{MPI_Send} or
@ocodecf{MPI_Ssend}.

@item @kbd{@copt{reduce}=@var{MPI_Op}}
The default reduction operation is @ocode{MPI_SUM} but a different
operation can be specified using the @backend{c_mpi}-specific
@copt{reduce} compiler option.  A program's log files indicate the
reduction operation that was used.
@end table


@node Implementation of reductions, Implementation of multicasts, Command-line options for c_mpi, The c_mpi backend
@subsubheading Implementation of reductions

The @backend{c_mpi} backend implements the @ncptl{} @keyw{REDUCE}
statement (@pxref{Reducing}) as follows.  Many-to-one reductions are
implemented with a single call to @ocodecf{MPI_Reduce}.  Many-to-many
reductions in which the sources exactly match the targets are
implemented with a single call to @ocodecf{MPI_Allreduce}.  All other
reductions are implemented by calling @ocodecf{MPI_Reduce} to reduce
the data to the first target task then @ocodecf{MPI_Bcast} to
distribute the reduced data to the remaining targets.

Because @MPI{} requires that the source and target buffers in an
@ocodecf{MPI_Reduce} or @ocodecf{MPI_Allreduce} be different, the
@backend{c_mpi} backend utilizes @emph{two} buffers when @keyw{UNIQUE}
(@pxref{Unique messages}) is specified.  It utilizes two
@emph{adjacent} buffers when @keyw{FROM BUFFER} or @keyw{INTO BUFFER}
(@pxref{Buffer control}) is specified.


@node Implementation of multicasts,  , Implementation of reductions, The c_mpi backend
@subsubheading Implementation of multicasts

The @keyw{MULTICAST} statement (@pxref{Multicasting}) enables any set
of tasks to transmit data to any other set of tasks.  The
@backend{c_mpi} backend implements @keyw{MULTICAST} using the simpler
@ocodecf{MPI_Bcast} when there is a single initiator (determined
dynamically at run time) and @ocodecf{MPI_Alltoallv} otherwise.  In
all cases, @backend{c_mpi} creates an @MPI{} communicator that
contains exactly the tasks involved in the multicast (as senders
and/or receivers).

@MPI{} requires that all tasks involved in an @ocodecf{MPI_Bcast}
belong to the same @MPI{} communicator.  Hence, in the @ncptl{}
statement

@example
TASK 4 MULTICASTS A 64 KILOBYTE MESSAGE TO TASKS r SUCH THAT r
IS IN @{1, 3, 5, 7, 9@}
@end example

@noindent
the generated communicator contains @w{tasks 1,} 3, 4, 5, 7, @w{and
9,} even though @w{task 4} transmits but does not receive any data.

Rather than repeatedly call @ocodecf{MPI_Bcast}, many-to-one and
many-to-many multicasts such as

@example
TASKS from_tasks SUCH THAT from_tasks < 8 MULTICAST 3 2-KILOBYTE
MESSAGES to TASKS to_tasks SUCH THAT 3 DIVIDES to_tasks
@end example

@noindent
perform a single @ocodecf{MPI_Alltoallv}.  Two message buffers are
used in this case, one for all outgoing data and one for all incoming
data.


@node The c_udgram backend, The c_trace backend, The c_mpi backend, Supplied backends
@subsection The @code{c_udgram} backend

@ncptl{} program development on a workstation is facilitated by the
@backend{c_udgram} backend.  @backend{c_udgram} runs on only a single
machine but, unlike @backend{c_seq}, supports all of @ncptl{}'s
communication statements.  Communication is performed over Unix-domain
datagram sockets.  Unix-domain datagrams are reliable and guarantee
order (unlike UDP/IP datagrams) but have a maximum packet size.
@backend{c_udgram} backend write this maximum to every log file and
automatically packetizes larger messages.

By default, @backend{c_udgram} produces an executable program that can
be run directly from the command line.  When @filespec{ncptl} is run
with the @copt{no-link} option, @backend{c_udgram} produces an object
file that needs to be linked with the appropriate sockets library (on
systems that require a separate library for socket calls).  When
@filespec{ncptl} is run with the @copt{no-compile} option,
@backend{c_udgram} outputs @w{ANSI C} code that must be both compiled
and linked.  Like all C-based backends, @backend{c_udgram} honors the
@envvar{CC}, @envvar{CPPFLAGS}, @envvar{LDFLAGS}, and @envvar{LIBS}
environment variables when compiling and linking.  Values not found in
the environment are taken from those specified/discovered at
configuration time (@pxref{configure}).

In addition to supporting the default set of command-line options,
programs generated using the @backend{c_udgram} backend further
support a @copt{tasks} option that designates the number of tasks to
use:

@cartouche
@example
  -T, --tasks=<number>        Number of tasks to use [default: 1]
@end example
@end cartouche

@noindent
@backend{c_udgram} programs spawn one OS-level process for each task
in the program.  They also create a number of sockets in the current
directory named @samp{c_udgram_@nonterm{tag}}.  These are
automatically deleted if the program exits cleanly but will need to be
removed manually in the case that the program is killed by an
non-trappable signal.

@menu
* Implementation of collectives::  How c_udgram implements collective operations
@end menu


@node Implementation of collectives,  , The c_udgram backend, The c_udgram backend
@subsubheading Implementation of collectives

The @backend{c_udgram} normally uses logarithmic-time algorithms for
multicasts (@pxref{Multicasting}), reductions (@pxref{Reducing}), and
barriers (@pxref{Synchronizing}).  One-to-many multicasts disperse
data in a binary-tree pattern.  Reductions reduce data in a
binary-tree pattern to the root, which then disperses the data in a
binary-tree pattern in the many-to-many case.  Barriers synchronize in
a butterfly pattern.  The only non-logarithmic-time algorithm is for
many-to-many multicasts, which are implemented as one
logarithmic-time, one-to-many multicast for each sender.


@node The c_trace backend, The c_profile backend, The c_udgram backend, Supplied backends
@subsection The @code{c_trace} backend

@cindex debugging
@cindex tracing
While most @ncptl{} backends are code generators, the
@backend{c_trace} backend adds tracing code to the code produced by a
code-generating backend.  @backend{c_trace} is useful as a debugging
aid and as a means to help understand the control flow of a @ncptl{}
program.

@menu
* Command-line options for c_trace::  Compiling with tracing enabled
* Default c_trace tracing::     Tracing to the standard error device
* c_trace tracing with curses::  Interactively tracing a live program
* Offline tracing with curses::  Playing back trace data interactively
@end menu


@node Command-line options for c_trace, Default c_trace tracing, The c_trace backend, The c_trace backend
@subsubheading Command-line options for @code{c_trace}

When @filespec{ncptl} is passed @kbd{@copt{backend}=c_trace} as a
command-line option, @backend{c_trace} processes the following
backend-specific command-line options:

@table @asis
@item @kbd{@copt{trace}=@var{backend}}
Specify a backend that will produce C code for @backend{c_trace} to
trace.  The @copt{trace} option is required to use @backend{c_trace};
@backend{c_trace} will issue an error message if @copt{trace} is not
specified.  The restrictions on @var{backend} are that it must produce
@w{C code} and must be derived from the @backend{c_generic} backend
(@pxref{Backend creation}).  Improper backends cause @backend{c_trace}
to abort abnormally.

@item @copt{curses}
Instead of injecting @ocodecf{fprintf} statements into the generated
@w{C code}, inject calls to the @filespec{curses} (or
@filespec{ncurses}) library to show graphically the line of code
currently executing on a given processor.
@end table


@node Default c_trace tracing, c_trace tracing with curses, Command-line options for c_trace, The c_trace backend
@subsubheading Default @code{c_trace} tracing

Without @copt{curses}, @backend{c_trace} alters the generated @w{C
code} to write data like the following to the standard error device:

@example
[TRACE] phys: 1 | virt: 1 | action: RECV | event: 1 / 44001 | lines: 18 - 18
[TRACE] phys: 0 | virt: 0 | action: RESET | event: 1 / 88023 | lines: 17 - 17
[TRACE] phys: 0 | virt: 0 | action: SEND | event: 2 / 88023 | lines: 18 - 18
[TRACE] phys: 0 | virt: 0 | action: RECV | event: 3 / 88023 | lines: 19 - 19
[TRACE] phys: 1 | virt: 1 | action: SEND | event: 2 / 44001 | lines: 19 - 19
[TRACE] phys: 1 | virt: 1 | action: RECV | event: 3 / 44001 | lines: 18 - 18
[TRACE] phys: 0 | virt: 0 | action: CODE | event: 4 / 88023 | lines: 20 - 21
[TRACE] phys: 0 | virt: 0 | action: RESET | event: 5 / 88023 | lines: 17 - 17
[TRACE] phys: 0 | virt: 0 | action: SEND | event: 6 / 88023 | lines: 18 - 18
[TRACE] phys: 0 | virt: 0 | action: RECV | event: 7 / 88023 | lines: 19 - 19
@iftex
@center @texmath{\vdots, N/A}
@end iftex
@ifnottex
                                       .
                                       .
                                       .
@end ifnottex
@end example

@noindent
The format is designed to be easy to read and easy for a program to
parse.  Each line of trace data begins with the string @samp{[TRACE]}
and lists the (physical) processor number, the (virtual) @w{task ID},
the action (a.k.a., event type) that is about to be performed, the
current event number and total number of events that will execute on
the given processor, and the range of lines of source code to which
the current event corresponds.  An ``event'' corresponds more-or-less
to a statement in the @ncptl{} language.@footnote{A more precise
correspondence is to a @nonterm{simple_stmt} in the formal grammar
presented in @ref{Grammar}.}  Loops are unrolled at initialization
time and therefore produce no events.  @ref{Event types}, lists and
briefly describes the various event types.


@node c_trace tracing with curses, Offline tracing with curses, Default c_trace tracing, The c_trace backend
@subsubheading @code{c_trace} tracing with @file{curses}

The @copt{curses} option enables a more interactive tracing
environment.  Generated programs must be linked with the
@filespec{curses} (or compatible, such as @filespec{ncurses}) library.
The resulting executable supports the following additional
command-line options:

@table @asis
@item @copts{D}, @kbd{@copt{delay}=@var{number}}
delay in milliseconds after each screen update (@samp{0}=no delay)

@item @copts{M}, @kbd{@copt{monitor}=@var{number}}
processor number to monitor

@item @copts{B}, @kbd{@copt{breakpoint}=@var{number}}
@cindex single-stepping
@cindex breakpoints
source line at which to enter single-stepping mode (@samp{-1}=none;
@samp{0}=first event)
@end table

When the program is run it brings up a screen like the following:

@cartouche
@example
 1.  # Determine computational "noise"
 2.
 3.  Require language version "@value{LANGUAGE-VERSION}".
 4.
 5.  accesses is "Number of data accesses to perform" and comes from
 6.    "--accesses" or "-a" with default 500000.
 7.
 8.  trials is "Number of timings to take" and comes from "--timings" or
 9.    "-t" with default 1000.
10.
11.  For trials repetitions @{
12.    all tasks reset their counters then
13.    all tasks touch a 1 word memory region accesses times with stride 0 w
14.    all tasks log a histogram of elapsed_usecs as "Actual time (usecs)"
15.  @}


Phys: 0  Virt: 0  Action: RESET    Event:    1/3001
@end example
@end cartouche

@noindent
The program displays its source code (truncated vertically if too tall
and truncated horizontally if too wide) at the top of the screen and a
status bar at the bottom of the screen.  As the program executes, a
cursor indicates the line of source code that is currently executing.
Likewise, the status bar updates dynamically to indicate the
processor's current task ID, action, and event number.  In
@filespec{curses} mode, the program's standard output (@pxref{Writing
to standard output}) is suppressed so as not to disrupt the trace
display.

Programs traced with @backend{c_trace} and the @copt{curses} option
are made interactive and support the following (case-insensitive)
keyboard commands:

@table @samp
@item S
@cindex single-stepping
Enable single-stepping mode.  While single-stepping mode is enabled
the traced processor will execute only one event per keystroke from
the user.

@item @var{space}
@cindex single-stepping
Disable single-stepping mode.  The program executes without further
user intervention.

@item D
@cindex breakpoints
Delete the breakpoint.

@item Q
Quit the program.  The log file will indicate that the program did not
run to completion.
@end table

@noindent
All other keystrokes cause the program to advance to the next event
immediately.

@cindex breakpoints
@cindex single-stepping
A single breakpoint can be set using the program's @copts{B} or
@copt{breakpoint} command-line option.  Whenever the monitored
processor reaches the source-code line at which a breakpoint has been
set, it enters single-stepping mode exactly as if @kbd{S} were
pressed.  Setting a breakpoint at @w{line 0} tells the program to
begin single-stepping as soon as the program begins.  Note that only
lines corresponding to @ncptl{} events can support breakpoints.


@node Offline tracing with curses,  , c_trace tracing with curses, The c_trace backend
@subsubheading Offline tracing with @file{curses}

The @backend{c_trace} backend can be told to trace by writing messages
to the standard error device (@pxref{Default c_trace tracing}) or by
employing an interactive display (@pxref{c_trace tracing with
curses}).  These two alternatives can be combined to support offline
tracing of a @ncptl{} program.  The idea is to compile the program
without the @copt{curses} option.  When running the program, the
standard-error output should be redirected to a file.  The
@filespec{ncptl-replaytrace} utility, which comes with @ncptl{}, can
then be used to play back the program's execution by reading and
displaying the file of redirected trace data.

@filespec{ncptl-replaytrace} accepts the following command-line
options, which correspond closely to those accepted by a program
compiled with the @copt{curses} option to @backend{c_trace}
(@pxref{c_trace tracing with curses}):

@table @kbd
@item @copt{trace}=@var{file}
Specify a file containing redirected trace data.  @var{file} defaults
to the standard input device.

@item @copt{delay}=@var{number}
Specify the delay in milliseconds after each screen update
(@samp{0}=no delay).

@item @copt{monitor}=@var{processor}
Specify the processor number to monitor.  @var{processor} defaults to
@samp{0}.

@item @copt{breakpoint}=@var{line}
@cindex single-stepping
@cindex breakpoints
Specify a line of source code at which to enter single-stepping mode
(@samp{-1}=none; @samp{0}=first event).
@end table

@noindent
In addition, @filespec{ncptl-replaytrace} requires that the @ncptl{}
source-code file be specified on the command line, as the source code
is not included in the trace data.

The interactive display presented by the offline
@filespec{ncptl-replaytrace} tool is nearly identical to that
presented by a program compiled with the @copt{curses} option to
@backend{c_trace}.  @xref{c_trace tracing with curses}, for a usage
description.


@node The c_profile backend, The interpret backend, The c_trace backend, Supplied backends
@subsection The @code{c_profile} backend

Profiling communication events can help explain surprising performance
measurements.  A profiling tool that automatically instruments
@ncptl{} programs is simpler than manually adding @keyw{LOGS} or
@keyw{OUTPUTS} statements to an existing program.

Like the @backend{c_trace} backend (@pxref{The c_trace backend}), the
@backend{c_profile} backend adds code to that produced by other
backends.  The @backend{c_profile} backend accepts a
single---mandatory---command-line argument,
@kbd{@copt{profile}=@var{backend}}, which designates a target backend
to use.  The restrictions on @var{backend} are that it must produce
@w{C code} and must be derived from the @backend{c_generic} backend
(@pxref{Backend creation}).  Improper backends cause
@backend{c_profile} to abort abnormally.

If the profiled @ncptl{} program produces log files, the log files
will include profiling information in the epilogue, one line for each
event type that was used at least once by the corresponding process.
(@ref{Event types}, lists and briefly describes the various event
types.)  Each line names an event and presents the total number of
microseconds spent processing that event, a tally of the number of
times that event type was executed, and the quotient of those two
numbers.  In addition, the amount of memory used to store the event
list is also logged.

For example, the following extract from a log file indicates that the
process that wrote it spent a total of 6.7@dmn{s} processing 22,000
@samp{RECV} events (which includes waiting time) for an average of
303.5@dmn{@texmath{\mu{}, u}s} per @samp{RECV} event:

@cartouche
@example
# Profile of SEND (microseconds, count, average): 5267469 22001 239.4
# Profile of RECV (microseconds, count, average): 6676521 22000 303.5
# Profile of REPEAT (microseconds, count, average): 11985167 1 11985167.0
# Profile of NEWSTMT (microseconds, count, average): 43 1 43.0
# Profile of CODE (microseconds, count, average): 5516 1 5516.0
# Profile of event memory: 528 bytes (6 events * 88 bytes/event)
@end example
@end cartouche

Each @samp{REPEAT} event includes the time for all of the events that
it repeats.

Although the preceding log-file excerpt indicates that a total of
@math{22001+22000+1+1+1 = 44004} events were executed, the @samp{event
memory} line clarifies that the event list contained only 6 unique
events and therefore required only @w{528 bytes} of memory.

Profiled programs that do not produce log files write profiling
information to the standard error device.  Because all processes may
share a single standard error device, each line of output is preceded
by a @w{processor ID} as in the following example:

@cartouche
@example
1 SEND 5527125 22000 251.2
1 RECV 6322699 22001 287.4
1 REPEAT 11894523 1 11894523.0
1 event-memory 352 4 88
0 SEND 5267469 22001 239.4
0 RECV 6676521 22000 303.5
0 REPEAT 11985167 1 11985167.0
0 event-memory 352 4 88
@end example
@end cartouche

@noindent
The columns are @w{@var{processor ID}}, @var{event}, @var{total
microseconds}, @var{tally}, and @var{average microseconds} except when
@var{event} is @samp{event-memory} in which case the columns are
@w{@var{processor ID}}, @samp{event-memory}, @var{total bytes},
@var{number of events}, and @var{bytes per event}.  The intention is
for the output to be easily parseable using tools such as
@filespec{awk}.


@node The interpret backend, The stats backend, The c_profile backend, Supplied backends
@subsection The @code{interpret} backend

Like the @backend{c_udgram} backend (@pxref{The c_udgram backend}),
the @backend{interpret} backend is designed to help programmers ensure
the correctness of @ncptl{} code.  The @backend{interpret} backend
does not output code.  As its name implies, @backend{interpret} is an
@emph{interpreter} of @ncptl{} programs rather than a compiler.
@backend{interpret} exhibits the following salient features:

@enumerate
@item
Some programs run faster than with a compiler because the interpreter
does not actually send messages.  @backend{interpret} merely simulates
communication.  It also skips over statements such as
@keyw{COMPUTES}/@keyw{SLEEPS} (@pxref{Delaying execution}) and
@keyw{TOUCHES} (@pxref{Touching memory}).

@item
@backend{interpret} can simulate massively parallel computer systems
from a single process.

@item
As @backend{interpret} runs it checks for common communication errors
such as deadlocks, asynchronous sends and receives that are never
completed, and blocking operations left over at the end of the program
(which would likely cause hung tasks under a real messaging layer).
@end enumerate

@noindent
The drawbacks are that @backend{interpret} is slow when interpreting
control-intensive programs and that timing measurements are not
indicative of any real network.  (The @backend{interpret} backend
utilizes logical time rather than physical time.)  @backend{interpret}
is intended primarily as a development tool for helping ensure the
correctness of @ncptl{} programs.

The @backend{interpret} backend accepts all of the command-line
options described in @ref{Running coNCePTuaL programs}, plus the
following four options:

@cartouche
@example
  -H, --hierarchy=<string>     Latency hierarchy as a comma-separated list
                               of task_factor:latency_delta pairs [default:
                               "tasks:1"]
  -K, --kill-reps=<number>     If nonzero, perform FOR...REPETITIONS loop
                               bodies exactly once [default: 0]
  -M, --mcastsync=<number>     Perform an implicit synchronization after a
                               multicast (0=no; 1=yes) [default: 0]
  -T, --tasks=<number>         Number of tasks to use [default: 1]
@end example
@end cartouche

Normally, the @backend{interpret} backend assigns unit latency to
every communication operation.  The @copt{hierarchy} option can make
communication with distant tasks observe more latency than
communication with nearby tasks.  An explanation of the argument to
@copt{hierarchy} is presented in @ref{Task latency hierarchies}.

To save execution time, the @copt{kill-reps} option alters the
behavior of all @keyw{FOR}@dots{}@keyw{REPETITIONS} statements in the
program, treating them as if they read, @samp{FOR 1 REPETITION}.  That
is, it ignores warmup repetitions, synchronizations, and the specified
number of repetitions, always using @samp{1} instead.

A multicast operation (@pxref{Multicasting}) is normally treated as
multiple point-to-point operations with the same send time.  The
@copt{mcastsync} option instructs the @backend{interpret} backend to
perform an implicit barrier synchronization at the end of the
multicast.

The @copt{tasks} option specifies the number of tasks to simulate.
Because this number can be quite large the @envvar{NCPTL_LOG_ONLY}
environment variable (@pxref{Environment Variables}) may be used to
limit the set of processors that are allowed to create log files.
That way, if @w{task 0} is the only task out of thousands that logs
any data, @envvar{NCPTL_LOG_ONLY} can specify that only one log file
will be produced, not thousands.  By default, all processors create a
log file.

All other command-line arguments are passed to the program being
interpreted.

The @copt{output} option described in @ref{Compiling coNCePTuaL
programs}, has special meaning to the @backend{interpret} backend.
When @copt{output} is used, @backend{interpret} dumps a list of events
to the specified file after a successful run.  For example, the
@ncptl{} program @samp{ALL TASKS t ASYNCHRONOUSLY SEND A 384 BYTE
MESSAGE TO TASK t XOR 2 THEN ALL TASKS AWAIT COMPLETION} results in
the following event dump:

@example
Task 0 posted a NEWSTMT at time 0 and completed it at time 0
Task 0 posted a RECEIVE at time 0 and completed it at time 0
Task 0 posted a SEND at time 1 and completed it at time 1
Task 0 posted a WAIT_ALL at time 2 and completed it at time 2
Task 1 posted a NEWSTMT at time 0 and completed it at time 0
Task 1 posted a RECEIVE at time 0 and completed it at time 0
Task 1 posted a SEND at time 1 and completed it at time 1
Task 1 posted a WAIT_ALL at time 2 and completed it at time 2
Task 2 posted a NEWSTMT at time 0 and completed it at time 0
Task 2 posted a RECEIVE at time 0 and completed it at time 0
Task 2 posted a SEND at time 1 and completed it at time 1
Task 2 posted a WAIT_ALL at time 2 and completed it at time 2
Task 3 posted a NEWSTMT at time 0 and completed it at time 0
Task 3 posted a RECEIVE at time 0 and completed it at time 0
Task 3 posted a SEND at time 1 and completed it at time 1
Task 3 posted a WAIT_ALL at time 2 and completed it at time 2
@end example

As an example of the @backend{interpret} backend's usage, here's how
to simulate 100,000 processors communicating in a simple ring pattern:

@example
% ncptl --backend=interpret --lenient --program='All tasks t send
    nummsgs 1024 gigabyte messages to task t+1 then task num_tasks-1
    sends nummsgs 1024 gigabyte messages to task 0.' --tasks=100000
    --nummsgs=5
@end example

@noindent
The preceding command ran to completion in under @w{5 minutes} on a
1.5@dmn{GHz} Xeon uniprocessor workstation---not too bad considering
that @w{488 petabytes} of data are transmitted on the program's
critical path.

The @backend{interpret} backend is especially useful for finding
communication-related program errors:

@example
% ncptl --backend=interpret --quiet --program='All tasks t send
    a 10 doubleword message to task (t+1) mod num_tasks.' --tasks=3
<command line>: The following tasks have deadlocked: 0 --> 2 --> 1
    --> 0
@end example

@noindent
Deadlocked tasks are shown with @samp{-->} signifying ``is blocked
waiting for''.  In the preceding example, all receives are posted
before all sends.  Hence, @w{task 0} is blocked waiting for @w{task 2}
to send it a message.  @w{Task 2}, in turn, is blocked waiting for
@w{task 1} to sent it a message.  Finally, @w{task 1} is blocked
waiting for @w{task 0} to send it a message, which creates a cycle of
dependencies.

The @backend{interpret} backend can find other errors, as well:

@example
% ncptl --backend=interpret --quiet --program='All tasks t
    asynchronously send a 10 doubleword message to task (t+1) mod
    num_tasks.' --tasks=4
<command line>: The program ended with the following leftover-event
    errors:
   * Task 0 posted an asynchronous RECEIVE that was never waited for
   * Task 0 posted an asynchronous SEND that was never waited for
   * Task 0 sent a message to task 1 that was never received
   * Task 1 posted an asynchronous RECEIVE that was never waited for
   * Task 1 posted an asynchronous SEND that was never waited for
   * Task 1 sent a message to task 2 that was never received
   * Task 2 posted an asynchronous RECEIVE that was never waited for
   * Task 2 posted an asynchronous SEND that was never waited for
   * Task 2 sent a message to task 3 that was never received
   * Task 3 posted an asynchronous RECEIVE that was never waited for
   * Task 3 posted an asynchronous SEND that was never waited for
   * Task 3 sent a message to task 0 that was never received
@end example

@noindent
(A message received @keyw{ASYNCHRONOUSLY} is not considered received
until after the corresponding @keyw{AWAITS COMPLETION}; hence, all of
the @samp{was never received} messages listed above.)

@example
% ncptl --backend=interpret --quiet --program='Task 0 sends a 40
    kilobyte message to unsuspecting task 1 then task 0 receives a 40
    kilobyte message from task 1.' --tasks=2
<command line>: The program ended with the following leftover-event
    errors:
   * Task 0 sent a message to task 1 that was never received
   * Task 1 terminated before satisfying task 0's RECEIVE operation
@end example


In short, it is well worth testing the correctness of new @ncptl{}
programs with @backend{interpret} before performing timing runs with
one of the message-passing backends.

@menu
* Task latency hierarchies::    Specifying latency as a function of distance
@end menu


@node Task latency hierarchies,  , The interpret backend, The interpret backend
@subsubheading Task latency hierarchies

The @backend{interpret} backend normally simulates a flat network in
which communication between any two tasks takes unit latency.
However, the @copt{hierarchy} option lets one specify a hierarchy of
latencies: latency @texmath{l_1, l1} within a set of @texmath{t_1, t1}
tasks, latency @texmath{l_1+l_2, l1+l2} within a set of @texmath{t_1
\cdot t_2, t1*t2} tasks, latency @texmath{l_1+l_2+l_3, l1+l2+l3}
within a set of @texmath{t_1 \cdot t_2 \cdot t_3, t1*t2*t3} tasks, and
so forth.

The argument to @copt{hierarchy} is a comma-separated list of
@texmath{\langle\hbox{\var{task factor}:\var{latency delta}}\rangle,
<@var{task factor}:@var{latency delta}>} pairs.  The @var{latency
delta} component is optional and defaults @w{to @samp{1}}.  If the
list ends with @samp{...}, the final @texmath{\langle\hbox{\var{task
factor}:\var{latency delta}}\rangle, <@var{task factor}:@var{latency
delta}>} pair is repeatedly indefinitely.  All @var{task factor}
values must be positive integers, and all @var{latency delta} values
must be nonnegative integers.

As an example, @coptargs{hierarchy, 4} (or @coptargs{hierarchy, 4:1})
partitions the program's tasks into sets of four with one unit of
additional latency to communicate with another set.  Hence, @w{tasks
0,} 1, 2, @w{and 3} can communicate with each other in unit time, as
can @w{tasks 4,} 5, 6, @w{and 7}.  However, communication between any
task in the first set and any task in the second set @w{(e.g.,
between} @w{tasks 3} @w{and 4)} takes an additional unit of time for a
total latency of two units.

As a more complex example, consider a cluster of symmetric
multiprocessors (SMPs) in which each SMP comprises two processor
sockets with each socket containing a quad-core processor (four CPUs).
Further assume that the SMPs are networked together via a fat-tree
network consisting of 12-port switches.  In this example, let's say
that it takes unit latency to communicate within a socket, two units
of latency to communicate with another socket in the same SMP, and an
additional three units of latency to traverse each switch.  This
configuration can be specified to the @backend{interpret} backend as
@coptargs{hierarchy, "4:1@comma{} 2:1@comma{} 12:3@comma{}
12:6@comma{} ..."} (or simply @coptargs{hierarchy,
4@comma{}2@comma{}12:3@comma{}12:6@comma{} ...}).  With this setting,
@w{task 0}, for instance, communicates with @w{tasks 1--3} in @w{1
time} unit, with @w{tasks 4--7} in @w{2 time} units, with @w{tasks
8--95} in @w{5 time} units (one switch crossing), with @w{tasks
96--1151} in @w{11 time} units (three switch crossings---a @w{level 0}
switch, a @w{level 1} switch, and another @w{level 0} switch), with
@w{tasks 1152--13,823} in @w{17 time} units (five switch
crossings---of switch @w{levels 0}, 1, 2, 1, @w{and 0}), and so forth.


@node The stats backend, The picl backend, The interpret backend, Supplied backends
@subsection The @code{stats} backend

The @backend{stats} backend outputs various statistics about a
@ncptl{} program.  It can be used to help verify a program's
correctness or merely to search for interesting patterns within a
complex communication pattern.  The following is some sample output
from a program compiled with @backend{stats}:

@smallexample
Execution parameters
--------------------
  Number of processors:          16
  Random-number seed:   -1727114895
  Command line:         ncptl --backend=stats hycom.ncptl --xdim=4 --ydim=4 --tasks=16 --iter=10
  Timestamp:            Wed Jan  4 17:32:04 2006

Message traffic
---------------
  Total messages sent:           710
  Total bytes sent:          1454080
  Unique message sizes sent: 2048

Per-processor message traffic
-----------------------------
  Processors sending a total of 61440 bytes:    0
  Processors sending a total of 81920 bytes:    1-3, 12-15
  Processors sending a total of 102400 bytes:   4-11
  Processors receiving a total of 61440 bytes:  1-3, 13-15
  Processors receiving a total of 81920 bytes:  5-7, 9-11
  Processors receiving a total of 122880 bytes: 12
  Processors receiving a total of 143360 bytes: 4, 8
  Processors receiving a total of 184320 bytes: 0
  Processors sending a total of 30 messages:    0
  Processors sending a total of 40 messages:    1-3, 12-15
  Processors sending a total of 50 messages:    4-11
  Processors receiving a total of 30 messages:  1-3, 13-15
  Processors receiving a total of 40 messages:  5-7, 9-11
  Processors receiving a total of 60 messages:  12
  Processors receiving a total of 70 messages:  4, 8
  Processors receiving a total of 90 messages:  0

Processor SEND-event peers
--------------------------
  Processors posting SEND events to offsets @{-12, -4, +1, +3@}:    12
  Processors posting SEND events to offsets @{-8, -4, +1, +3, +4@}: 8
  Processors posting SEND events to offsets @{-4, -3, -1@}:         15
  Processors posting SEND events to offsets @{-4, -3, -1, +4@}:     7, 11
  Processors posting SEND events to offsets @{-4, -2, -1, +1@}:     14
  Processors posting SEND events to offsets @{-4, -2, -1, +1, +4@}: 6, 10
  Processors posting SEND events to offsets @{-4, -1, +1@}:         13
  Processors posting SEND events to offsets @{-4, -1, +1, +4@}:     5, 9
  Processors posting SEND events to offsets @{-4, +1, +3, +4@}:     4
  Processors posting SEND events to offsets @{-3, -1, +4@}:         3
  Processors posting SEND events to offsets @{-2, -1, +1, +4@}:     2
  Processors posting SEND events to offsets @{-1, +1, +4@}:         1
  Processors posting SEND events to offsets @{+1, +3, +4@}:         0

Network bisection crossings
---------------------------
  Bisection messages:    100
  Bisection bytes:    204800

Event tallies
-------------
  Total number of LOG events:       10
  Total number of NEWSTMT events:   48
  Total number of RECEIVE events:  710
  Total number of RESET events:     10
  Total number of SEND events:     710
  Total number of WAIT_ALL events: 480

Per-processor event sets
------------------------
  Processors executing only @{LOG, NEWSTMT, RECEIVE, RESET, SEND, WAIT_ALL@}: 0
  Processors executing only @{NEWSTMT, RECEIVE, SEND, WAIT_ALL@}:             1-15

Per-processor event tallies
---------------------------
  Processors executing 10 LOG events:      0
  Processors executing 3 NEWSTMT events:   0-15
  Processors executing 30 RECEIVE events:  1-3, 13-15
  Processors executing 40 RECEIVE events:  5-7, 9-11
  Processors executing 60 RECEIVE events:  12
  Processors executing 70 RECEIVE events:  4, 8
  Processors executing 90 RECEIVE events:  0
  Processors executing 10 RESET events:    0
  Processors executing 30 SEND events:     0
  Processors executing 40 SEND events:     1-3, 12-15
  Processors executing 50 SEND events:     4-11
  Processors executing 30 WAIT_ALL events: 0-15
@end smallexample

@backend{stats} is derived from @backend{interpret} (@pxref{The
interpret backend}) and therefore supports the @backend{interpret}
backend's options as well as the standard options described in
@ref{Running coNCePTuaL programs}.  However, because @backend{stats}
does not produce log files, the @copt{logfile} option is absent.
@backend{stats} additionally supports the following three command-line
options:

@cartouche
@example
  -E, --expand-lists=<number>     0=collapse lists of numbers into ranges;
                                  1=show all numbers [default: 0]
  -F, --format=<string>           Output format, either "text", "excelcsv",
                                  or "sep:<string>" [default: "text"]
  -X, --exclude=<string>          Name of a category or individual field to
                                  exclude from output [default: ""]
@end example
@end cartouche

The @copt{expand-lists} option tells the @backend{stats} backend
whether it should output sets of numbers as comma-separated ranges
@w{(e.g., @samp{1-3, 12-15})} or as individual numbers (e.g., @samp{1,
2, 3, 12, 13, 14, 15}).  The @copt{format} option specifies the output
format.  By default, it outputs human-readable text, as shown in the
above example.  However, @coptargs{format, excelcsv} outputs the data
in comma-separated value format suitable for loading directly into
Microsoft Excel.  A more general form of computer-parseable output is
specified with the @samp{sep} sub-option, which takes a separator
string as a sub-option.  For example, @coptargs{format, sep:"#"}
produces output like the following:

@example
"Event tallies"#"Total number of LOG events"#10
#"Total number of NEWSTMT events"#48
#"Total number of RECEIVE events"#710
#"Total number of RESET events"#10
#"Total number of SEND events"#710
#"Total number of WAIT_ALL events"#480
@end example

@noindent
The difference between @coptargs{format, excelcsv} and
@coptargs{format, sep:"@comma{}"} is that the former employs a number
of bizarre special cases when quoting strings so as to coerce Excel
into properly processing the file.  The latter simply inserts a comma
between columns with no special string processing other than preceding
the characters @samp{"} and @samp{\} @w{with @samp{\}.}

The @backend{stats} backend issues a @samp{Column separator @var{sep}
appears within a field} warning if the separator string appears in any
of the output fields.  (Note that it will always appear in the
@samp{Command line} line because the @copt{format} line is specified
on the command line.)  The idea is to warn the user that automatic
parsing of the output @w{(e.g., using} @filespec{awk}) may need to be
careful when processing lines containing such fields.

As can be seen from the sample output, @backend{stats} outputs a lot
of information.  The @copt{exclude} option---which can be specified
repeatedly on the command line---provides the user with fine-grained
control over which output to suppress.  For example,
@coptargs{exclude, "Total number of NEWSTMT events"} tells
@backend{stats} not to output the line with that key.  Similarly,
@coptargs{exclude, "Processor SEND-event peers"} eliminates an entire
category of information.


@node The picl backend, The paraver backend, The stats backend, Supplied backends
@subsection The @code{picl} backend

@cncp{PICL}, the Portable Instrumented Communication Library, defines
a trace file format that records an execution trace of a
message-passing application.  In particular, @cncp{MPICL} is an
@MPI{}-specific implementation of @cncp{PICL} that facilitates
instrumenting @MPI{} programs.  Normally, one passes a @cncp{PICL}
file to a performance-visualization tool such as @cncp{ParaGraph},
which renders the trace data using any of a number of graphical views.

Although @cncp{MPICL} is compatible with the @backend{c_mpi} backend
(@pxref{The c_mpi backend}), @ncptl{} provides a @backend{picl}
backend that produces @cncp{PICL} files directly.  The intention is
to use the @cncp{PICL} format to represent an idealized view of a
communication pattern rather than to store a time-sensitive execution
trace.  For example, timing events recorded by @backend{picl} occur at
logical times instead of physical times and statements such as
@keyw{COMPUTES}/@keyw{SLEEPS} (@pxref{Delaying execution}) and
@keyw{TOUCHES} (@pxref{Touching memory}) take either zero time or unit
time, depending upon a command-line option.  By providing an idealized
view of a communication pattern, @backend{picl} abstracts away timing
artifacts so events that one would expect to occur simultaneously are
written to the trace file as being exactly simultaneous.

As an example, the following is the @cncp{PICL} output produced by
passing @backend{picl} the @ncptl{} program @samp{TASK 0 SENDS A 32
KILOBYTE MESSAGE TO TASK 1 THEN TASK 1 SENDS A 256 BYTE MESSAGE TO
TASK 0.}:

@example
-3 -901 0.00000 0 0 0
-3 -901 0.00000 1 1 0
-3 -21 0.00001 0 0 4 2 32768 1 1 1
-4 -21 0.00001 0 0 0
-3 -52 0.00001 1 1 3 2 1 0 0
-3 -52 0.00002 0 0 3 2 1 1 1
-4 -52 0.00002 1 1 4 2 32768 1 0 0
-3 -21 0.00002 1 1 4 2 256 1 0 0
-4 -21 0.00002 1 1 0
-4 -52 0.00003 0 0 4 2 256 1 1 1
-4 -901 0.00003 1 1 0
-4 -901 0.00004 0 0 0
@end example

@noindent
See the @cncp{PICL} manual, @cite{A new PICL trace file format}
(ORNL/TM-12125), for a detailed description of the various fields used
in the preceding trace file.

@cncp{ParaGraph} is a visualization tool that reads @cncp{PICL} trace
files and graphically displays/animates the corresponding execution in
a variety of formats.  Running @cncp{ParaGraph} on output from
@backend{picl} makes it easy for a @ncptl{} programmer to explain
complex communication patterns to other people.

@backend{picl} is derived from @backend{interpret} (@pxref{The
interpret backend}) and therefore supports the @backend{interpret}
backend's @copt{tasks} and @copt{mcastsync} options as well as the
standard options described in @ref{Running coNCePTuaL programs}.
However, because @backend{picl} does not produce log files, the
@copt{logfile} option is absent.  @backend{picl} additionally supports
the following two command-line options:

@cartouche
@example
  -A, --all-events=<number>     0=include only communication events;
                                1=include all events  [default: 0]
  -F, --frequency=<number>      PICL event frequency (Hz) [default: 100000]
@end example
@end cartouche

By default, only communication events are written to the trace file.
If @copt{all-events} is set to @samp{1} then all events are written to
the trace file.  Events not related to communication are defined to
take unit time.  Regardless of the setting of @copt{all-events}, the
@keyw{OUTPUTS} statement (@pxref{Writing to standard output}) writes a
@cncp{PICL} @samp{tracemsg} event to the trace file.  A user can tell
@cncp{ParaGraph} to pause visualization at @samp{tracemsg} events,
making it possible to isolate key components of a @ncptl{} program's
execution.

Because @cncp{PICL} events are marked with physical time (a
floating-point number of seconds) but @backend{picl} uses exclusively
logical time, @backend{picl} needs to associate a (fabricated)
physical time with each logical time.  The @copt{frequency} option
specifies that mapping.  By default, @backend{picl} pretends that each
unit of logical time corresponds to 1/100000 of a second @w{(i.e, 10
microseconds)} of physical time.  As an example, the default time step
in @cncp{ParaGraph} is @w{1 microsecond}; this can be specified to
@backend{picl} with @coptargs{frequency, 1E6}.

One of the goals of @ncptl{} is to facilitate the explanation of
network performance tests.  The @backend{picl} backend aids in the
explanation by making it easy to show graphically how tasks
communicate with each other in an arbitrary @ncptl{} program.


@node The paraver backend, The latex_vis backend, The picl backend, Supplied backends
@subsection The @code{paraver} backend

The @cncp{Paraver} trace visualizer accepts a trace file format that
records an execution trace of a message-passing (or other) application
and uses that to display application timelines and statistical data.
Normally, one uses an application-instrumentation tool such as
@cncp{Extrae} to generate @cncp{Paraver} traces, and @cncp{Extrae} is,
in fact, compatible with programs generated using the @ncptl{}
@backend{c_mpi} backend (@pxref{The c_mpi backend}).  However, the
@backend{paraver} backend produces @cncp{Paraver} files directly.  The
intention is to use the @cncp{Paraver} format to represent an
idealized view of a communication pattern rather than to store a
time-sensitive execution trace.  For example, timing events recorded
by @backend{paraver} occur at logical times instead of physical times
and statements such as @keyw{COMPUTES}/@keyw{SLEEPS} (@pxref{Delaying
execution}) and @keyw{TOUCHES} (@pxref{Touching memory}) take either
zero time or unit time, depending upon a command-line option.  By
providing an idealized view of a communication pattern,
@backend{paraver} abstracts away timing artifacts so events that one
would expect to occur simultaneously are written to the trace file as
being exactly simultaneous.

As an example, the following is the @cncp{Paraver} output produced by
passing the @backend{paraver} backend the @ncptl{} program, @samp{TASK
0 SENDS A 32 KILOBYTE MESSAGE TO TASK 1 THEN TASK 1 SENDS A 256 BYTE
MESSAGE TO TASK 0.}:

@example
#Paraver (06/01/2011 at 11:22):2001_ns:2(1,1):1:2(1:1,1:2),0
3:1:1:1:1:0:0:2:1:2:1:1000:1000:32768:0
2:1:1:1:1:0:1000000:6
2:1:1:1:1:0:1000000:13
2:2:1:2:1:0:1000000:6
2:2:1:2:1:0:1000000:9
1:1:1:1:1:0:1000:4
1:2:1:2:1:0:1000:3
3:2:1:2:1:1000:1000:1:1:1:1:2000:2000:256:0
2:1:1:1:1:1000:1000000:9
2:2:1:2:1:1000:1000000:13
1:1:1:1:1:1000:2000:3
1:2:1:2:1:1000:2000:4
@end example

@noindent
The @backend{paraver} backend also generates an associated
configuration file that maps program state and event numbers to names
and colors.  For example, @w{state 4} represents ``blocking send'' and
is colored a neon fuchsia in @cncp{Paraver}'s graphical interface;
@w{event 1000000} represents ``@ncptl{},'' and @w{event 1000000},
@w{value 13} represents a @ncptl{} @samp{SEND} event.  See the manual,
@cite{Paraver Parallel Program Visualization and Analysis Tool:
Tracefile Description}, for a detailed description of the various
fields used in the preceding trace file.

@backend{paraver} is derived from @backend{interpret} (@pxref{The
interpret backend}) and therefore supports the @backend{interpret}
backend's @copt{tasks} and @copt{mcastsync} options as well as the
standard options described in @ref{Running coNCePTuaL programs}.
However, because @backend{paraver} does not produce log files, the
@copt{logfile} option is absent.  @backend{paraver} additionally supports
the following two command-line options:

@cartouche
@example
  -D, --dimemas-events=<number> 0=no Dimemas events; 1=extra events for
                                Dimemas simulator [default: 0]
  -E, --conc-events=<number>    0=exclude names of coNCePTuaL event types;
                                1=include them [default: 0]
  -O, --comp-time=<number>      Time spent in each non-communication event (ns)
                                [default: 0]
  -P, --event-time=<number>     Paraver event time (ns) [default: 1000]
  -R, --conc-source=<number>    0=exclude references to coNCePTuaL source
                                lines; 1=include them [default: 1]
@end example
@end cartouche

By default, only @ncptl{} communication events are written to the
trace file.  If @copt{comp-time} is set to a positive integer then all
events are written to the trace file, and all non-communication events
take the specified amount of time.  Because @cncp{Paraver} events are
marked with physical time (a integral number of nanoseconds) but
@backend{paraver} uses exclusively logical time, @backend{paraver}
needs to associate a (fabricated) physical time with each logical
time.  The @copt{event-time} option specifies that mapping.  By
default, @backend{paraver} pretends that each unit of logical time
corresponds to @w{1 microsecond} @w{(i.e, 1000 nanoseconds)} of
physical time.  In addition to @ncptl{}, @cncp{Paraver} also has a
notion of an ``event.''  The @copt{conc-source} and @copt{conc-events}
options tell the @backend{paraver} backend which Paraver events to
include in the trace file.  If @copt{conc-source} is @samp{1} (the
default), Paraver will display text like the following in its Info
panel:

@example
User Event at 529,000 ns  myfile.ncptl source line Unknown value 203
@end example

@noindent
which indicates that the most recently clicked time in the
@cncp{Paraver} timeline represents logical @w{time 529} and
corresponds to @w{line 203} of @file{myfile.ncptl}.  If
@copt{conc-events} is @samp{1}, Paraver will display text like the
following in its Info panel:

@example
User Event at 529,000 ns  coNCePTuaL event RECEIVE
@end example

@noindent
which indicates that the most recently clicked time in the
@cncp{Paraver} timeline represents logical @w{time 529} and represents
a @ncptl{} interpreter @samp{RECEIVE} event (@pxref{The interpret
backend}).  The @cncp{Dimemas} network simulator accepts the same
traces as the @cncp{Paraver} visualizer but expects to see a number of
additional events in the trace file.  If @copt{dimemas-events} is
@samp{1}, the @backend{paraver} backend will generate those extra
events.

One of the goals of @ncptl{} is to facilitate the explanation of
network performance tests.  The @backend{paraver} backend aids in the
explanation by making it easy to show graphically how tasks
communicate with each other in an arbitrary @ncptl{} program.


@node The latex_vis backend, The dot_ast backend, The paraver backend, Supplied backends
@subsection The @code{latex_vis} backend
@cindex communication diagrams
@cindex diagrams, communication
@cindex illustrations of communication patterns
@cindex graphical view of communication
@cindex pictures of communication patterns

The @backend{latex_vis} backend visualizes a program's communication
pattern as an Encapsulated @cncp{PostScript} time-space diagram.  The
backend thereby provides a static counterpart to the animated
visualizations made possible by the @backend{picl} and
@backend{paraver} backends and the @cncp{ParaGraph} and @cncp{Paraver}
trace visualizers (@pxref{The picl backend}, and @ref{The paraver
backend}).  @backend{latex_vis} outputs @latex{} code with calls to
the @cncp{PSTricks} package (available from
@uref{http://www.tug.org/applications/PSTricks/} but shipped with most
@latex{} distributions) to draw the figure, then runs @kcmd{latex} (or
whatever the @envvar{LATEX} environment variable is set to) to convert
the @file{.tex} file to DVI format and @kcmd{dvips} (or whatever the
@envvar{DVIPS} environment variable is set to) to convert the
@file{.dvi} file into EPS format.  Finally, @backend{latex_vis} runs
the graphic through @cncp{Ghostscript} (@kcmd{gs} or whatever the
@envvar{GS} environment variable is set to) to tighten the graphic's
@cncp{bounding box}.@footnote{If @cncp{Ghostscript} is not installed
or fails to run, @backend{latex_vis} issues a warning message, not an
error message.  The figure is still usable without a tight bounding
box and a loose @cncp{bounding box} can be corrected manually by
editing the @samp{%%BoundingBox:} line in the generated EPS file.}
@backend{latex_vis} requires that @latex{} and @cncp{PSTricks} be
installed in order to produce its visualizations.  However, it can
still run with @copt{no-compile} (@pxref{Compiling coNCePTuaL
programs}) to produce a @file{.tex} file that can later be run
manually through @kcmd{latex}.

As an example, the following is the default @backend{latex_vis} output
from the @ncptl{} program @samp{TASK 0 SENDS A 1 MEGABYTE MESSAGE TO
TASK 1 THEN ALL TASKS SYNCHRONIZE THEN TASK 1 SENDS A 3 KILOBYTE
MESSAGE TO TASK 0} when run with three tasks:

@sp 1
@center @image{latex_vis}
@sp 1

@noindent
Currently, the output diagram does not indicate message size but this
may change in a future release of @backend{latex_vis}.

The @backend{latex_vis} backend has a number of uses.  First, it can
be used to illustrate a nontraditional communication pattern for a
presentation, research paper, or technical report.  Second, it can be
used as a teaching aid to demonstrate common communication patterns
@w{(e.g., a} butterfly pattern) to students.  Third, it can be used as
a debugging aid to ensure that a @ncptl{} program is, in fact,
performing the expected communication operations.

@backend{latex_vis} is derived from @backend{interpret} (@pxref{The
interpret backend}) and therefore supports the @backend{interpret}
backend's @copt{tasks} and @copt{mcastsync} options as well as the
standard options described in @ref{Running coNCePTuaL programs}.  (The
@backend{interpret} backend's @copt{kill-reps} option can be handy for
reducing the picture's size by showing only a single iteration of each
loop.)  Because @backend{latex_vis} does not produce log files, the
@copt{logfile} option is absent.  @backend{latex_vis} additionally
supports the following command-line options:

@cartouche
@example
  -A, --annotate=<string>         Annotation level (0=no annotations;
                                  1=annotate communication events;
                                  2=annotate all events;
                                  "<event>..."=annotate only the
                                  specified events) [default: "0"]
  -B, --binary-tasks=<number>     Display task numbers in binary rather
                                  than decimal (0=decimal; 1=binary)
                                  [default: 0]
  -E, --every-event=<number>      Events requiring nonzero time to complete
                                  (0=only communication events;
                                  1=every event) [default: 0]
  -G, --stagger=<number>          Number of points by which to stagger
                                  overlapping arrows [default: 2]
  -L, --source-lines=<number>     Associate source-code line numbers with
                                  each event annotation (0=no; 1=yes)
                                  [default: 0]
  -R, --arrow-width=<string>      Python expression to map m, representing
                                  a message size in bytes, to an arrow
                                  width in points [default: "1"]
  -Z, --zero-latency=<number>     Depict communication as having zero
                                  latency (0=unit latency; 1=zero
                                  latency) [default: 0]
@end example
@end cartouche

In the preceding list a ``point'' refers to a @cncp{PostScript} point.
@TEX{} calls these ``big points'' and defines @w{1@dmn{bp}
@texmath{\equiv, =}} 1/72")

The @copt{annotate} option places adjacent to appropriate nodes in the
output diagram a list of textual annotations that indicate the
communication operations that were posted or completed and the
non-communication operations that were executed by the corresponding
task at the corresponding time.  Some sample annotations are
@samp{Post SEND}, @samp{Complete SEND}, and @samp{Execute OUTPUT}.
With @coptargs{annotate, 1}, only communication events are annotated;
with @coptargs{annotate, 2}, all events are annotated;@footnote{To
avoid the confusion of annotating what is essentially a ``do nothing''
event, @backend{latex_vis} does not annotate the @samp{NEWSTMT} event,
which is injected at the beginning of each top-level statement.};
otherwise, a list of specific events can be annotated.  For example,
@coptargs{annotate, SYNC@comma{}MCAST} causes only the @samp{SYNC} and
@samp{MCAST} events to be annotated.  Compiling a @ncptl{} program
with the @backend{latex_vis} backend and the @copt{keep-ints} options
(@pxref{Compiling coNCePTuaL programs}) produces a @file{.tex} file
that contains in the prologue comments a list of all events used by a
program that were and were not annotated.

Task numbers are normally shown in @w{base ten.}  The
@copt{binary-tasks} option causes task numbers to be output in @w{base
two} and using the same number of bits for each task.  For example, a
3-task visualization with @copt{binary-tasks} would number the tasks
@samp{00}, @samp{01}, and @samp{11}.

Because @backend{latex_vis} is intended primarily for visualizing
communication patterns, by default only communication operations take
nonzero time to complete.  The @copt{every-event} option indicates
that all events---including local events such as @samp{SLEEP},
@samp{COMPUTE}, @samp{LOG}, and @samp{OUTPUT}---should be deemed to
complete in unit time.

@backend{latex_vis} output distinguishes coincident arrows (consider
the phrase @samp{TASK 0 ASYNCHRONOUSLY SENDS 5 MESSAGES TO TASK 1}) by
staggering them slightly.  The @copt{stagger} option specifies the
number of @cncp{PostScript} points by which to stagger each
overlapping arrow with a default of @w{2 points}.  Large stagger
values are more visually distinctive while small stagger values allow
arrows to drift less from their associated nodes.

The @copt{source-lines} option, when used with @copt{annotate},
augments each event annotation with the corresponding line(s) of
source code that produced that event.  This feature improves the
utility of @backend{latex_vis} as a debugging aid for @ncptl{}
programs.

By default, all arrows that indicate message transmissions are drawn
with equally thick line widths.  The @copt{arrow-width} option lets
you specify a @cncp{Python} function to map a message size in bytes,
@math{m}, to a line width in @cncp{PostScript} points, with the
default being @w{1 point.}  As a simple example,
@coptargs{arrow-width, 2} doubles the arrow width for all message
@w{(i.e., it} represents the constant function @texmath{f: m \mapsto
2, f: m --> 2}).  A more typical example would be
@coptargs{arrow-width, "log10(m)"} (representing @texmath{f: m \mapsto
\log_{10}(m), f: m --> log10(m)}), which causes a tenfold increase in
message size to yield a unit increase in line width.  The argument to
@copt{arrow-width} can be any @cncp{Python} expression using either
built-in functions or functions from the @cncp{Python} @ocode{math}
module.  See the @uref{http://docs.python.org/lib/lib.html, Python
library reference} for details.

Normally, messages are considered to require one time unit to travel
from source to destination.  The @copt{zero-latency} option shows
messages as being received in the same timestep as they were sent.
Some communication patterns are more aesthetically pleasing when drawn
this way.

@menu
* Further customizations::      Exploting ncptl's --filter option
@end menu


@node Further customizations,  , The latex_vis backend, The latex_vis backend
@subsubheading Further customizations

In addition to the options described above, the @w{front end's}
@copt{filter} option (@pxref{Compiling coNCePTuaL programs}) is a
useful mechanism for customizing the formatting of the communication
diagram.  For example, specifying @coptargs{filter,
"s/rowsep=30bp/rowsep=1.5in/g"} increases the separation between rows
from 30@dmn{bp} (where @w{1@dmn{bp} @texmath{\equiv, =}} 1/72") to
1.5".  See the @uref{http://www.tug.org/applications/PSTricks/,
PSTricks documentation} for more information about the @cncp{PSTricks}
commands used in the generated @file{.tex} files.

To facilitate the use of @copt{filter}, the @backend{latex_vis}
backend uses a helper macro (@code{\viscolor}) to define colors.
@code{\viscolor} takes an argument of the form
@samp{@var{name}=@var{color}} and defines a macro
@code{\}@var{name}@code{color} that expands to @var{color}.  To
further facilitate the use of @copt{filter}, the @latex{} code
generated by the @backend{latex_vis} backend contains a number of
strategically placed placeholder comments of the form @samp{%
PLACEHOLDER: @var{tag}}.  A @copt{filter} command can thereby insert
code into the document by replacing an appropriate @samp{PLACEHOLDER}
line.  In alphabetical order, the currently defined placeholder tags
are
@include placeholders.texi
Look through any @backend{latex_vis}-generated @file{.tex} file to see
where these are situated.  As an example, the following command-line
options define a ``chartreuse'' color then change the color used to
indicate point-to-point messages from blue to chartreuse:

@example
--filter="s/% PLACEHOLDER: COLORS/\\newrgbcolor@{chartreuse@}@{0.5 1 0@}/"
--filter="s/sendrecv=blue/sendrecv=chartreuse/"
@end example

@noindent
(According to the @uref{http://www.tug.org/applications/PSTricks/,
PSTricks documentation}, the predefined colors are @code{red},
@code{green}, @code{blue}, @code{cyan}, @code{magenta}, and
@code{yellow}, and the predefined grayscales are @code{black},
@code{darkgray}, @code{gray}, @code{lightgray}, and @code{white}.)

Tasks that are active at a given time are drawn using the @code{\task}
macro, which takes the task number as an argument.  Tasks that are
idle at a given time are drawn using the @code{\idle} macro, which is
initially defined to be the same as @code{\task}.  The following
``cookbook'' examples showcase some of the ways that the power of
@latex{} and @cncp{PSTricks} can be exploited to display idle tasks in
a variety of different styles (best used with @kbd{--annotate=2}):

@table @asis
@item omitting idle tasks
@code{--filter="s/\\let\\idle=\\task/\\newcommand*@{\\idle@}[1]@{[mnode=R]@}/"}

@item showing each idle task as a gray dot
@code{--filter="s/\\let\\idle=\\task/\\newcommand*@{\\idle@}[1]@{[mnode=dot,
linecolor=gray]@}/"}

@item drawing idle tasks with a dotted circle instead of a solid circle
@code{--filter="s/\\let\\idle=\\task/\\newcommand*@{\\idle@}[1]
@{[linestyle=dotted]\\task@{#1@}@}/"}
@end table

@noindent
As an alternative to replacing the @samp{\let\idle=\task} binding, the
preceding substitutions can be expressed as the insertion of a
@latex{} @code{\renewcommand}.  That is, idle tasks can also be
omitted by specifying @samp{--filter="s/% PLACEHOLDER:
NODESHAPE/\\renewcommand*@{\\idle@}[1]@{[mnode=R]@}/"}.

In short, the @backend{latex_vis} backend produces highly customizable
illustrations of communication patterns.  Because @backend{latex_vis}
produces commented @latex{} code, any customization not provided
through the use of @copt{filter} or one of the backend-specific
command-line options is easily performed by compiling with
@copt{keep-ints} (@pxref{Compiling coNCePTuaL programs}) and editing
the generated @latex{} code.


@node The dot_ast backend, The libsea_ast backend, The latex_vis backend, Supplied backends
@subsection The @code{dot_ast} backend

@cncp{dot} is a format for describing graphs in terms of their edges
and vertices.  The tools in the @cncp{Graphviz} suite typeset
@cncp{dot} files in a variety of output formats and using a variety of
graph-layout algorithms.  @ncptl{}'s @backend{dot_ast} backend outputs
in @cncp{dot} format the abstract-syntax tree corresponding to a given
@ncptl{} program.  As an example, @backend{dot_ast} renders the
one-line @ncptl{} program @samp{TASK 0 SLEEPS FOR 10 SECONDS} as
follows:

@sp 1
@center @image{sample-AST}
@sp 1

@backend{dot_ast} is expected to be of particular use to backend
developers, who can use it to help prioritize the methods that need to
be implemented (i.e., implementing first the @AST{} node types needed
by in a trivial program, then those needed by successively more
complex programs).

The @backend{dot_ast} backend accepts the following options from the
@filespec{ncptl} command line:

@table @asis
@item @kbd{@copt{format}=@var{dot_format}}
The programs in the @cncp{Graphviz} suite can output graphs in a
variety of formats such as @cncp{PostScript}, SVG, and PNG.  By
default, the @backend{dot_ast} backend outputs @cncp{PostScript}.  The
@copt{format} option specifies an alternate format to use.  At the
time of this writing, the @cncp{Graphviz} programs support the
following formats: @code{canon}, @code{cmap}, @code{dot}, @code{fig},
@code{gd}, @code{gd2}, @code{gif}, @code{hpgl}, @code{imap},
@code{ismap}, @code{jpeg}, @code{jpg}, @code{mif}, @code{mp},
@code{pcl}, @code{pic}, @code{plain}, @code{plain-ext}, @code{png},
@code{ps}, @code{ps2}, @code{svg}, @code{svgz}, @code{vrml},
@code{vtx}, @code{wbmp}, and @code{xdot}.  See the @cncp{Graphviz}
documentation for more information about these formats.

@item @kbd{@copt{node-code}=@var{characters}}
To facilitate associating nodes in the @AST{} with fragments of the
@ncptl{} program being graphed, the @backend{dot_ast} backend provides
a @copt{node-code} option that labels each node with the fragment of
code to which it corresponds.  The argument to @copt{node-code} is a
number of characters at which to truncate the code fragment or
@samp{-1} to inhibit truncation.  The purpose of truncation is to
prevent excessively large nodes from disturbing the graph layout.  The
@nonterm{program} node (@pxref{Complete programs}), for example,
includes the complete program source code if not truncated.

@item @kbd{@copt{extra-dot}=@var{dot_code}}
The @backend{dot_ast} backend's @copt{extra-dot} option enables the
user to inject arbitrary @cncp{dot} code into the generated file.  For
example, specifying @kbd{--extra-dot="node
[shape=Mrecord]"}@footnote{@backend{dot_ast} automatically places a
semicolon after the extra @cncp{dot} code.} tells @cncp{dot} to use
draw nodes as rounded rectangles and specifying @kbd{--extra-dot='edge
[color="green"]'} colors all edges green.  @copt{extra-dot} can be
specified repeatedly on the command line; @backend{dot_ast}
concatenates all of the extra @cncp{dot} code with intervening
semicolons.

@item @copt{compress}
Normally, every node of the @AST{} is drawn.  The @copt{compress}
option makes the resulting @cncp{dot} graph more readable by eliding
chains of single-child nodes.  For example, @copt{compress} reduces
the previous graph of @samp{TASK 0 SLEEPS FOR 10 SECONDS} to the
following:

@sp 1
@center @image{compressed-AST}
@sp 1

@item @copt{no-lines}
By default, each @AST{} node indicates the lines in the program's
source code to which it corresponds.  The @copt{no-lines} option
suppresses the outputting of source-code line numbers.

@item @copt{no-attrs}
Every node in the @AST{} has a type.  Some nodes additionally have an
attribute.  @backend{dot_ast} normally outputs attributes but
@copt{no-attrs} prevents @backend{dot_ast} from doing so.

@item @copt{no-source}
The complete source code corresponding to the @AST{} is included in
the generated @cncp{dot} graph unless @copt{no-source}
is specified on the command line.
@end table

The @envvar{DOT} environment variable names the @cncp{Graphviz}
program that @backend{dot_ast} should run on the generated code.  If
@envvar{DOT} is not set, @backend{dot_ast} uses whatever value was
specified/discovered at configuration time (@pxref{configure}), with
the default being @filespec{dot}.  By default, @backend{dot_ast}
produces @cncp{dot} code and runs this through the designated
@cncp{Graphviz} program to produce a @cncp{PostScript} file (or
whatever format is named by the @copt{format} option).  If
@filespec{ncptl} is run with either the @copt{no-link} or
@copt{no-compile} options, it produces a @cncp{dot} file that should
be run manually through @filespec{dot} or another @cncp{Graphviz}
tool.


@node The libsea_ast backend,  , The dot_ast backend, Supplied backends
@subsection The @code{libsea_ast} backend

Like the @backend{dot_ast} backend (@pxref{The dot_ast backend}), the
@backend{libsea_ast} backend visualizes a @ncptl{} parse tree.  This
capability is primarily useful to backend developers to help
prioritize the methods that need to be implemented (i.e., implementing
first the @AST{} node types needed by in a trivial program, then those
needed by successively more complex programs).

The @backend{libsea_ast} backend specifies a @ncptl{} program's parse
tree in the @cncp{LibSea} graph file format, which can then be
visualized and manipulated interactively using the @cncp{Walrus}
visualization tool.  The primary advantage of @backend{libsea_ast}
over @backend{dot_ast} is that @backend{libsea_ast} can handle much
larger parse trees than @backend{dot_ast}.  For example, the following
image illustrates the @cncp{Walrus} GUI displaying a 702,985-node
@ncptl{} parse tree:@footnote{The original source program contained
over 6000 lines of @ncptl{} code.}

@vskip 2ex

@c The following TeX trickery is needed because of the way epsf.tex
@c operates differently in DVI and PDF modes.
@iftex
@tex
\ifpdf
  @center @image{walrus, @pagewidth}
\else
  @center @image{walrus, 6in}
\fi
@end tex
@end iftex
@ifnottex
@center @image{walrus, , , Image of the Walrus GUI displaying a large coNCePTuaL parse tree}
@end ifnottex

@noindent
A secondary advantage of @backend{libsea_ast} is that @cncp{Walrus}
lets a user selectively view information.  For example, in the
preceding image, only @nonterm{simple_stmt} nodes (@pxref{Complex
statements}) are highlighted; the source code for only certain nodes
is displayed; and all node type and node attribute information is
hidden.

The @backend{libsea_ast} backend accepts the following option from the
@filespec{ncptl} command line:

@table @asis
@item @kbd{@copt{node-code}=@var{characters}}
Every node in the generated @cncp{LibSea} graph lists the fragment of
@ncptl{} code to which it corresponds.  For large @ncptl{} programs,
these strings can get large.  The @nonterm{program} node
(@pxref{Complete programs}), for example, includes the complete
program source code.  Because the @cncp{Walrus} visualizer does not
currently wrap long lines, most of a long string is never even
presented to the user and therefore serves no practical purpose.  The
argument to @copt{node-code} is a number of characters at which to
truncate the code fragment or @samp{-1} to inhibit truncation.
@end table


@node Running coNCePTuaL programs, Interpreting coNCePTuaL log files, Supplied backends, Usage
@section Running coNCePTuaL programs
@cindex running programs

@ncptl{} programs can be run like any other program built with the
same compiler and communication library.  For example if a program
@file{myprog} was built with @ncptl{}'s C+@MPI{} backend, the program
might be run with a command like @kbd{mpirun -np @var{nodes} myprog}
or @kbd{prun -N@var{nodes} myprog} or @kbd{pdsh -w @var{node_list}
myprog}.  The important point is that job launching is external to
@ncptl{}@.  A @ncptl{} program is oblivious to whether it is being run
with a single thread on each multiprocessor node or with one thread on
each CPU, for example.  However, @ncptl{} log files do include the
host name in the prologue comments (@pxref{Log-file format}) so
job-launching parameters can potentially be inferred from those.

@ncptl{} programs automatically support a ``help'' option.  This is
usually specified as @copt{help} or @copts{?}, depending on which
option-parsing library @filespec{configure} configured in.
(@xref{configure}.)  The output of running @w{@kbd{myprog --help}}
most likely looks something like this:

@opindex -C
@opindex -L
@opindex -S
@opindex -W
@opindex -?
@opindex --comment
@opindex --logfile
@opindex --no-trap
@opindex --seed
@opindex --help
@opindex --usage
@cartouche
@example
Usage: myprog [OPTION...]
  -C, --comment=<string>      Additional commentary to write to the log
                              file, @@FILE to import commentary from FILE,
                              or !COMMAND to import commentary from COMMAND
                              (may be specified repeatedly)
  -L, --logfile=<string>      Log-file template [default: "a.out-%p.log"]
  -N, --no-trap=<string>      List of signals that should not be trapped
                              [default: ""]
  -S, --seed=<number>         Seed for the random-number generator
                              [default: 0]

Help options:
  -?, --help                  Show this help message
  --usage                     Display brief usage message
@end example
@end cartouche

Although a @ncptl{} program can specify its own command-line options
(@pxref{Command-line arguments}), a few are provided by default.  In
addition to @copt{help} these include @copt{comment}, @copt{logfile},
@copt{no-trap}, and @copt{seed}.

@table @copt
@item comment
@copt{comment} makes it possible to add arbitrary commentary to a log
file.  This is useful for incorporating information that @ncptl{}
would be unable to (or simply does not currently) determine on its
own, for example, @kbd{@w{--comment=}"Last experiment before upgrading
the network device driver"}.  Two special cases are supported:

@enumerate
@item
If the comment string begins with @samp{@@} then the remainder of the
string is treated as a filename.  Each line of the corresponding file
is treated as a separate comment string.  Hence, if the file
@file{sysdesc.txt} contains the lines @samp{Using FooBarNet} and
@samp{Quux is enabled}, then specifying
@kbd{@w{--comment=}sysdesc.txt} is similar to specifying both
@kbd{@w{--comment=}"Using FooBarNet"} and @kbd{@w{--comment=}"Quux is
enabled"}.

@item
If the comment string begins with @samp{!} then the remainder of the
string is treated as a shell command.  The command is executed and
each line of its output is treated as a separate comment string.  For
example, @kbd{@w{--comment=}'!lspci | grep -i net'} executes
@filespec{lspci}, extracts only those lines containing the string
@samp{net}, and makes log-file comments out of the result.  Note that
@kbd{@w{--comment=}'!@var{command}'} differs from
@kbd{@w{--comment=}"`@var{command}`"} in that the former causes
@var{command} to be executed individually by each process in the
program while the latter executes @var{command} only once and only
before launching the program.  Also note that @samp{!} must be escaped
in @filespec{csh} and derivitive shells (i.e.,
@kbd{@w{--comment=}'\!@var{command}'}).
@end enumerate

As an example, the command line arguments @kbd{--comment="This is a
simple comment." --comment=!lspci --comment=@@/proc/version
--comment="This is another simple comment.@:"} produce log-file lines
like the following:

@smallexample
# User comment 1: This is a simple comment.
# Output of 'lspci', line 1: 00:00.0 Host bridge: Intel Corp. 82860 860 (Wombat) Chipset Host Bridge (MCH) (rev 04)
# Output of 'lspci', line 2: 00:01.0 PCI bridge: Intel Corp. 82850 850 (Tehama) Chipset AGP Bridge (rev 04)
# Output of 'lspci', line 3: 00:02.0 PCI bridge: Intel Corp. 82860 860 (Wombat) Chipset AGP Bridge (rev 04)
# Output of 'lspci', line 4: 00:1e.0 PCI bridge: Intel Corp. 82801BA/CA/DB PCI Bridge (rev 04)
# Output of 'lspci', line 5: 00:1f.0 ISA bridge: Intel Corp. 82801BA ISA Bridge (LPC) (rev 04)
# Output of 'lspci', line 6: 00:1f.1 IDE interface: Intel Corp. 82801BA IDE U100 (rev 04)
# Output of 'lspci', line 7: 00:1f.2 USB Controller: Intel Corp. 82801BA/BAM USB (Hub  (rev 04)
# Output of 'lspci', line 8: 00:1f.3 SMBus: Intel Corp. 82801BA/BAM SMBus (rev 04)
# Output of 'lspci', line 9: 00:1f.4 USB Controller: Intel Corp. 82801BA/BAM USB (Hub  (rev 04)
# Output of 'lspci', line 10: 00:1f.5 Multimedia audio controller: Intel Corp. 82801BA/BAM AC'97 Audio (rev 04)
# Output of 'lspci', line 11: 01:00.0 VGA compatible controller: nVidia Corporation NV11 [GeForce2 MXR] (rev b2)
# Output of 'lspci', line 12: 02:1f.0 PCI bridge: Intel Corp. 82806AA PCI64 Hub PCI Bridge (rev 03)
# Output of 'lspci', line 13: 03:00.0 PIC: Intel Corp. 82806AA PCI64 Hub Advanced Programmable Interrupt Controller (rev 01)
# Output of 'lspci', line 14: 04:0b.0 Ethernet controller: 3Com Corporation 3c905C-TX/TX-M [Tornado] (rev 78)
# Output of 'lspci', line 15: 04:0d.0 Multimedia audio controller: Creative Labs SB Live! EMU10k1 (rev 08)
# Output of 'lspci', line 16: 04:0d.1 Input device controller: Creative Labs SB Live! MIDI/Game Port (rev 08)
# Contents of /proc/version, line 1: Linux version 2.4.20-28.7 (bhcompile@@porky.devel.redhat.com) (gcc version 2.96 20000731 (Red Hat Linux 7.3 2.96-126)) #1 Thu Dec 18 11:31:59 EST 2003
# User comment 2: This is another simple comment.
@end smallexample

To facilitate log-file parsing, all colons in the name of an
@samp{@@}-file or @samp{!}-command are written as periods.  This
affects only the display, not the file to read or command to execute.

@cindex backquoted commands
@cindex newlines in backquoted commands
@cindex quotes
@iindent
Be careful when using shell backquotes with @copt{comment} (e.g., as
in @coptargs{comment, "`who`"}).  Different shells have different ways
of handling newlines output by a backquoted command.  In some shells
@w{(e.g., @filespec{bash}),} the @ncptl{} program sees the entire
output with embedded newlines as a single argument; in others
@w{(e.g., @filespec{tcsh}),} each line of output constitutes a
separate command-line argument.  Because @ncptl{} programs currently
ignore arguments that do not begin with @samp{-@w{}-}, the comment
written to the log file in the latter case terminates at the first
newline.  In virtually all shells, the double quotes around the
backquoted command are needed to prevent the shell from splitting
arguments at word boundaries.  As a consequence, @coptargs{comment,
`who`} logs only the first word output by the @kbd{who} command.

@item logfile
@copt{logfile} specifies a template for naming log files.  Each task
maintains a log file based on the template name but with @samp{%p}
replaced with the processor number, @samp{%r} replaced with the run
number (the smallest nonnegative integer that produces a filename
that does not already exist), and @samp{%%} replaced with a literal
``%'' character.  The program outputs an error message and aborts if
the log-file template does not contain at least one @samp{%p}.  The
only exception is that an empty template @w{(i.e.,
@kbd{--logfile=""})} inhibits the production of log files entirely.

@iindent
Like C's @ocodecf{printf} function, a numeric field width can occur
between the @samp{%} and the conversion specifier (the @samp{p} or
@samp{r} in the case of @copt{logfile}).  The field is padded on the
left with spaces to the given width.  More practically, if the field
width begins with the @w{number @samp{0}} the field is padded on the
left with zeroes to the given width.  For example, specifying
@w{@kbd{--logfile="mydata-%03p.log"}} on the command line produces log
files named @file{mydata-000.log}, @file{mydata-001.log},
@file{mydata-002.log}, @file{mydata-003.log}, and so forth.

@item no-trap
@copt{no-trap} specifies a list of signals or ranges of signals that
should not be trapped.  For example, @kbd{@w{--no-trap=}10-12,17}
prevents signals 10, 11, 12, and 17 from being trapped.@footnote{On
some platforms, these signals correspond to @code{SIGUSR1},
@code{SIGSEGV}, @code{SIGUSR2}, and @code{SIGCHLD}, respectively.}
Signals can also be referred to by name, with or without a @samp{SIG}
prefix.  Also, names and numbers can be freely mixed.  Hence,
@kbd{@w{--no-trap=}10-12,INT,17,SIGSTOP,SIGCONT} is a valid argument
to a @ncptl{} program.  Because signal reception can adversely affect
performance, @ncptl{}'s default behavior is to terminate the program
on receipt of a signal.  However, some signals may be necessary for
the underlying communication layer's proper operation.  @copt{no-trap}
enables such signals to pass through @ncptl{} untouched.  (Some
signals, however, are needed by @ncptl{} or by a particular backend
and are always trapped.)

@item seed
@copt{seed} (which selects a different default value on each run) is
used in any program that utilizes the @keyw{RANDOM TASK} construct
(@pxref{Binding variables}) or that sends message
@keyw{WITH VERIFICATION} (@pxref{Message specifications}).
@end table

If the @keyw{LOGS} statement (@pxref{Writing to a log file}) is used
anywhere in a @ncptl{} program, then @emph{all} processes write a log
file.  This is done because @ncptl{} log files---even those that
contain no measurement data---include a wealth of important
information in prologue comments, as described @ref{Interpreting
coNCePTuaL log files}.  As a consequence, a program run with thousands
of processes produces thousands of log files.  If @w{process 0} is the
only process that logs actual data, the @filespec{ncptl-logmerge}
script (@pxref{ncptl-logmerge}) can merge these log files into a
single, more manageable, file.  For situations in which it is
unreasonable for every process to write a log file @w{(e.g., if} the
filesystem is unable to handle large numbers of simultaneous file
creations, the @envvar{NCPTL_LOG_ONLY} environment variable lets the
user limit the set of processes that produce log files.
@envvar{NCPTL_LOG_ONLY} accepts a comma-separated list of
dash-separated process ranges such as @samp{0-3,12-16,24,25,32-48}.
Only processes included in the list produce log files.


@node Interpreting coNCePTuaL log files,  , Running coNCePTuaL programs, Usage
@section Interpreting coNCePTuaL log files
@cindex log files

Any @ncptl{} program that uses the @keyw{LOGS} keyword (@pxref{Writing
to a log file}) will produce a log file as it runs.  The @ncptl{}
run-time library writes log files in a simple, plain-text format.  In
addition to measurement data, a wealth of information is stored within
log-file comments.  @ncptl{} comes with a tool, @filespec{ncptl-logextract},
which can extract data and other information from a log file and
convert it into any of a variety of other formats.

@menu
* Log-file format::             Syntax and semantics of program log files
* ncptl-logextract::            A tool for extracting log-file information
* ncptl-logmerge::              A tool for merging and comparing log files
* ncptl-logunmerge::            A tool for undoing the effects of ncptl-logmerge
@end menu


@node Log-file format, ncptl-logextract, Interpreting coNCePTuaL log files, Interpreting coNCePTuaL log files
@subsection Log-file format
@cindex log files

The @ncptl{} run-time library writes log files in the following
(textual) format:

@itemize @bullet
@item
Lines beginning with @samp{#} are comments.

@item
Columns are separated by commas.

@cindex quotes
@item
Strings are output between double quotes.  Literal double-quotes are
output as @samp{\"} and literal backslashes are output as @samp{\\}.
@end itemize

@noindent
A sample log file is listed below.  The log file is presented in its
entirety.

@smallexample
###########################################################################
# ===================
# coNCePTuaL log file
# ===================
# coNCePTuaL version: 0.6.4a
# coNCePTuaL backend: c_mpi (C + MPI)
# Executable name: /home/pakin/src/coNCePTuaL/example
# Working directory: /home/pakin/src/coNCePTuaL
# Command line: ./example
# Number of tasks: 2
# Processor (0<=P<tasks): 0
# Host name: a1
# Operating system: Linux version 2.4.21-3.5qsnet (root@@a31) (gcc version 2.96 20000731 (Red Hat Linux 7.2 2.96-108.1)) #2 SMP Thu Aug 7 10:51:04 MDT 2003
# CPU vendor: GenuineIntel
# CPU architecture: ia64
# CPU count: 2
# CPU frequency: 1300000000 Hz (1.3 GHz)
# Cycle-counter frequency: 1300000000 Hz (1.3 GHz)
# OS page size: 16384 bytes
# Physical memory: 2047901696 bytes (1.9 GB)
# Elan capability: [1965771c.6213bf5d.3a26411c.5b4c5d58] Version 10002 Type a001 Context 640.640.640 Node 1.2
# coNCePTuaL configuration: ./configure '--prefix=/tmp/ncptl' 'MPICPPFLAGS=-I/usr/local/include' 'CFLAGS=-g -O3 -ansi_alias -ansi' 'MPICC=/usr/lib/mpi/mpi_intel/bin/mpicc' '--enable-maintainer-mode' 'CC=ecc' '--disable-shared'
# Library compiler+linker: /opt/intel-7.1.033/compiler70/ia64/bin/ecc
# Library compiler version: Intel(R) C++ gcc 3.0 mode [7.1]
# Library compiler options: -g -O3 -ansi_alias -ansi
# Library linker options: -lrmscall -lelan -lpopt
# Library compiler mode: LP64
# Dynamic libraries used: /usr/lib/qsnet/elan3/lib/librmscall.so.1 /usr/lib/qsnet/elan3/lib/libelan.so.1 /usr/lib/libpopt.so.0.0.0 /usr/lib/mpi/mpi_intel/lib/libmpi.so.1.0 /lib/libm-2.2.4.so /opt/intel-7.1.033/compiler70/ia64/lib/libcxa.so.4 /lib/libc-2.2.4.so /usr/lib/qsnet/elan3/lib/libelan3.so.1 /usr/lib/qsnet/elan/lib/libelanctrl.so.2 /lib/ld-2.2.4.so
# Microsecond timer type: gettimeofday()
# Average microsecond timer overhead: <1 microsecond
# Microsecond timer increment: 1.00466 +/- 0.123576 microseconds (ideal: 1 +/- 0)
# Minimum sleep time: 1946.6 +/- 31.5872 microseconds (ideal: 1 +/- 0)
# WARNING: Sleeping exhibits poor granularity (not a serious problem).
# WARNING: Sleeping has a large error component (not a serious problem).
# Process CPU timer: getrusage()
# Process CPU-time increment: 976.59 +/- 0.494311 microseconds (ideal: 1 +/- 0)
# WARNING: Process timer exhibits poor granularity (not a serious problem).
# Log-file template: example-%p.log
# Number of minutes after which to kill the job (-1=never): -1
# List of signals which should not be trapped: 14
# Log-file checkpointing interval: 60 seconds (i.e., 1 minute)
# MPI send routine: MPI_Send()
# MPI error checking: off
# Front-end compilation command line: ncptl --backend=c_mpi example.ncptl
# Back-end compilation command line: /usr/lib/mpi/mpi_intel/bin/mpicc -I/tmp/ncptl/include  -I/usr/local/include -g -O3 -ansi_alias -ansi tmppG76Fv.c  -L/tmp/ncptl/lib   -lncptl -lrmscall -lelan -lpopt -o example
# Log creator: Scott Pakin
# Log creation time: Mon Dec 19 12:02:18 2005
#
# Environment variables
# ---------------------
# CVS_RSH: /usr/bin/ssh
# DISPLAY: localhost:19.0
# DYNINSTAPI_RT_LIB: /home/pakin/dyninstAPI-3.0/lib/i386-unknown-linux2.2/libdyninstAPI_RT.so.1
# DYNINST_ROOT: /home/pakin/dyninstAPI-3.0
# EDITOR: /usr/bin/emacs
# GROUP: CCS3
# HOME: /home/pakin
# HOST: a0
# HOSTNAME: a0
# HOSTTYPE: unknown
# KDEDIR: /usr
# LANG: en_US
# LD_LIBRARY_PATH: /opt/intel-7.1.033/compiler70/ia64/lib:/users/pakin/lib:/usr/lib:/usr/ccs/lib:/opt/SUNWspro/lib:/usr/dt/lib:/usr/openwin/lib:/usr/X11R6/lib:/usr/local/gnu/lib:/usr/local/lib:/usr/ucblib:/users/pakin/dyninstAPI-3.0/lib/i386-unknown-linux2.2
# LESSOPEN: |/usr/bin/lesspipe.sh %s
# LOGNAME: pakin
# LPDEST: lwy
# LS_COLORS: no=00:fi=00:di=01;34:ln=01;36:pi=40;33:so=01;35:bd=40;33;01:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:ex=01;32:*.cmd=01;32:*.exe=01;32:*.com=01;32:*.btm=01;32:*.bat=01;32:*.sh=01;32:*.csh=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.gz=01;31:*.bz2=01;31:*.bz=01;31:*.tz=01;31:*.rpm=01;31:*.cpio=01;31:*.jpg=01;35:*.gif=01;35:*.bmp=01;35:*.xbm=01;35:*.xpm=01;35:*.png=01;35:*.tif=01;35:
# MACHTYPE: unknown
# MAIL: /var/mail/pakin
# MANPATH: /opt/intel-7.1.033/compiler70/man:/home/pakin/man:/usr/man:/opt/SUNWspro/man:/usr/dt/man:/usr/openwin/man:/usr/X11R6/man:/usr/local/gnu/man:/usr/local/man:/usr/share/man:/usr/lanl/man
# MOZILLA_HOME: /usr/local/netscape/java
# NAME: Scott Pakin
# ORGANIZATION: Los Alamos National Lab
# OSTYPE: linux
# PATH: /opt/intel-7.1.033/compiler70/ia64/bin:.:/home/pakin/bin:/usr/local/bin:/usr/dt/bin:/usr/openwin/bin:/usr/X11R6/bin:/usr/local/gnu/bin:/usr/local/bin:/sbin:/bin:/opt/SUNWspro/bin:/usr/sbin:/usr/bin:/usr/ccs/bin:/usr/ucb:/usr/local/teTeX/bin:.:/usr/lanl/bin
# PRINTER: lwy
# PVM_ROOT: /usr/share/pvm3
# PVM_RSH: /usr/bin/rsh
# PWD: /home/pakin/src/coNCePTuaL
# QTDIR: /usr/lib/qt-2.3.1
# REMOTEHOST: antero.c3.lanl.gov
# RMS_JOBID: 308
# RMS_MACHINE: a
# RMS_NNODES: 2
# RMS_NODEID: 0
# RMS_NPROCS: 2
# RMS_PROCID: 0
# RMS_RANK: 0
# RMS_RESOURCEID: parallel.318
# RMS_STOPONELANINIT: 0
# SHELL: /bin/tcsh
# SHLVL: 2
# SSH_AGENT_PID: 8586
# SSH_ASKPASS: /usr/libexec/openssh/gnome-ssh-askpass
# SSH_AUTH_SOCK: /tmp/ssh-XXfG457q/agent.8562
# SSH_CLIENT: 128.165.20.177 47456 22
# SSH_TTY: /dev/pts/10
# SUPPORTED: en_US:en
# TERM: xterm
# TZ: MST7MDT
# USER: pakin
# VENDOR: unknown
#
# coNCePTuaL source code
# ----------------------
#     FOR 10 REPETITIONS @{
#       TASK 0 RESETS ITS COUNTERS THEN
#       TASK 0 SENDS A 0 BYTE MESSAGE TO TASK 1 THEN
#       TASK 1 SENDS A 0 BYTE MESSAGE TO TASK 0 THEN
#       TASK 0 LOGS EACH elapsed_usecs/2 AS "Latency (usecs)"
#     @}
#
###########################################################################
"Latency (usecs)"
"(all data)"
192.5
7
5.5
5.5
5
5
5
5.5
5
5.5
###########################################################################
# Program exited normally.
# Log completion time: Mon Dec 19 12:02:18 2005
# Elapsed time: 0 seconds
# Process CPU usage (user+system): 0 seconds
# Number of interrupts received (all CPUs): 22
# Peak memory allocation: 1072987 bytes (1.0 MB)
###########################################################################
@end smallexample

@sp 1

As the preceding example indicates, a log file's comment block can be
divided into multiple stanzas:

@itemize @bullet
@item
a list of @texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} pairs that describe various characteristics
of the run-time environment, including hardware and software
identification, timer quality, values of command-line arguments, and a
timestamp

@item
a dump of the environment variables active when the program ran

@item
the complete @ncptl{} source program
@end itemize

@noindent
Two rows of column headers and the measurement data follow the
prologue comment block.  A set of epilogue comments completes the log
file.

The motivation for writing so much information to the log file is to
facilitate reproduction of the experiment.  The ideal situation is for
a third party to be able to look at a @ncptl{} log file and from that,
recreate the original experiment and get identical results.

@sp 1

Some of the comments that may benefit from additional explanation
include the following:

@table @samp
@item Library compiler mode
@samp{LP64} means ``@strong{L}ong integers and @strong{P}ointers
contain exactly @strong{64} bits while ordinary integers contain
exactly 32 bits''.  @samp{ILP32} means ``ordinary @strong{I}ntegers,
@strong{L}ong integers, and @strong{P}ointers all contain exactly
@strong{32} bits''.  The library compiler mode will be
@samp{nonstandard} for any other combination of datatype sizes.

@item Average timer overhead
During initialization, the @ncptl{} run-time library performs some
calibration routines.  Among these routines is a measurement of the
quality of whatever mechanisms the library is using to measure elapsed
time.  In the sample log file presented above, the mechanism used was
@samp{inline assembly code}, meaning the run-time library reads the
hardware cycle counter without going through a standard library or
system call.  The complete set of timer mechanisms and selection
criteria is presented in @ref{Time-related functions}, in the
documentation for the @ocodecf{ncptl_time} function.

@iindent
The log file then reports ``average timer overhead'' as the mean time
between back-to-back invocations of whichever timer routine is being
used.  Ideally, the mean should be @w{@samp{<1 microsecond}} but this
is not the case on all systems.  Large values indicate that a
performance penalty is charged every time a @ncptl{} program reads the
timer.

@item Timer increment
In addition to measuring the overhead of reading the timer, the
@ncptl{} run-time library also measures timer accuracy.  The library
expects to be able to read the timer with microsecond accuracy.  That
is, the time reported should not increase by more than a microsecond
between successive readings of the timer.  To gauge timer accuracy,
the library's initialization routine performs a number of back-to-back
invocations of the timer routine and reports the mean and standard
deviation of the number of microseconds that elapsed between readings,
discarding any deltas of zero microseconds.  Ideally, the microsecond
timer, when read multiple times in rapid succession, should report
nonzero increments of exactly one microsecond with no variation.  The
log file will contain warning messages if the increment or standard
deviation are excessively large, as this may indicate a large margin
of error in the measurement data.

@item Process CPU-time increment
@itemx Process CPU usage (user+system)
Log files end with an epilogue section that includes @samp{Process
CPU usage (user+system)}, which indicates the subset of total
wall-clock time for which the program was running (@samp{user}) or for
which the operating system was running on the program's behalf
(@samp{system}).  The log-file prologue reports as @samp{Process
CPU-time increment} the resolution of the timer user to report process
CPU time.  Note that process CPU time is not exported to @ncptl{}
programs; it is therefore much less critical than the wall-clock timer
and is reported primarily for informational purposes.

@item Number of interrupts received (all CPUs)
On certain platforms, @ncptl{} can tally the number of CPU interrupts
that were processed during the run of the program.  Because a
multiprocessor may migrate tasks among CPUs during their execution, a
per-CPU interrupt count may have little merit.  Consequently, the
number reported represents the sum across all CPUs in the same node
(but not across nodes).  @ncptl{} attempts to read interrupt
information from the @filespec{/proc/interrupts} file if no
alternative mechanism is available.  In case having a large number of
processes accessing @filespec{/proc/interrupts} poses a problem the
@copt{disable-proc-interrupts} configuration option prevents programs
from accessing that file.

@item Peak memory allocation
@ncptl{} programs heap-allocate memory for a variety of purposes:
message buffers, event lists (@pxref{Generated code}), unaggregated
performance data (@pxref{Computing aggregates}), etc.  Allocated
memory that is no longer needed is returned to the heap.  The total
amount of allocated memory the program is holding therefore increases
and decreases over time.  The @samp{Peak memory allocation} comment
reports the maximum amount of memory the program held at any given
time.  If this value nears or exceeds the value reported for
@samp{Physical memory}, it is possible that paging overheads may be
negatively impacting some of the program's timing measurements.  On
systems without demand paging, exceeding @samp{Physical memory} is
likely to crash the program; a large @samp{Peak memory allocation} on
a smaller run can therefore help explain why a larger run is crashing.
@samp{Peak memory allocation} includes only memory allocated using the
memory-allocation functions described in @ref{Memory-allocation
functions}.
@end table


@node ncptl-logextract, ncptl-logmerge, Log-file format, Interpreting coNCePTuaL log files
@subsection @file{ncptl-logextract}
@cindex log files

To facilitate converting @ncptl{} log files into input data for other
applications, @ncptl{} provides a Perl script called
@filespec{ncptl-logextract}.  @filespec{ncptl-logextract} can extract
the data from a log file---as well as various information that appears
in the log file's comments---into a variety of formats suitable for
graphing or typesetting.

Running @w{@kbd{ncptl-logextract @copt{usage}}} causes
@filespec{ncptl-logextract} to list a synopsis of its core
command-line options to the standard output device; running
@w{@kbd{ncptl-logextract @copt{help}}} produces basic usage
information; and, running @w{@kbd{ncptl-logextract @copt{man}}}
outputs a complete manual page.  @xref{ncptl-logextract manual page},
shows the @filespec{ncptl-logextract} documentation as produced by
@w{@kbd{ncptl-logextract @copt{man}}.}

@page
@include ncptl-logextract-man.texi
@page


@node ncptl-logmerge, ncptl-logunmerge, ncptl-logextract, Interpreting coNCePTuaL log files
@subsection @file{ncptl-logmerge}
@cindex log files

@ncptl{} programs produce one log file per process.  An unwieldy
number of files can therefore be generated on large-scale computer
systems.  For the case in which only a single log file contains
measurement data, @filespec{ncptl-logmerge} can merge a number of log
files into a single file.  Only lines that differ across log files are
repeated, making the result fairly space-efficient.  The primary
advantage of @filespec{ncptl-logmerge} over an archiving program such
as @file{tar} or @file{zip} is that the output of
@filespec{ncptl-logmerge} is designed to be human-readable---in fact,
easily readable.

@filespec{ncptl-logmerge} can also be used to highlight differences in
log files.  It is therefore an important diagnostic tool for
unearthing subtle configuration discrepancies across nodes in a
large-scale computer system.

Running @w{@kbd{ncptl-logmerge @copt{usage}}} causes
@filespec{ncptl-logmerge} to list a synopsis of its core command-line
options to the standard output device; running @w{@kbd{ncptl-logmerge
@copt{help}}} produces basic usage information; and, running
@w{@kbd{ncptl-logmerge @copt{man}}} outputs a complete manual page.
@xref{ncptl-logmerge manual page}, shows the @filespec{ncptl-logmerge}
documentation as produced by @w{@kbd{ncptl-logmerge @copt{man}}.}

@page
@include ncptl-logmerge-man.texi
@page


@node ncptl-logunmerge,  , ncptl-logmerge, Interpreting coNCePTuaL log files
@subsection @file{ncptl-logunmerge}
@cindex log files

The primary capability of @filespec{ncptl-logmerge}
(@pxref{ncptl-logmerge}) is to merge multiple @ncptl{} log files into
a more maintainable single file.  @filespec{ncptl-logunmerge} performs
the complementary operation of splitting that merged file back into
the original set of @ncptl{} log files.

Running @w{@kbd{ncptl-logunmerge @copt{usage}}} causes
@filespec{ncptl-logunmerge} to list a synopsis of its core
command-line options to the standard output device; running
@w{@kbd{ncptl-logunmerge @copt{help}}} produces basic usage
information; and, running @w{@kbd{ncptl-logunmerge @copt{man}}}
outputs a complete manual page.  @xref{ncptl-logunmerge manual page},
shows the @filespec{ncptl-logunmerge} documentation as produced by
@w{@kbd{ncptl-logunmerge @copt{man}}.}

@page
@include ncptl-logunmerge-man.texi
@page


@node Grammar, Examples, Usage, Top
@chapter Grammar
@cindex grammar

The @ncptl{} language was designed to produce precise specifications
of network correctness and performance tests yet read like an
English-language document that contains a hint of mathematical
notation.  Unlike more traditional programming languages, @ncptl{} is
more descriptive than imperative.  There are no classes, functions,
arrays, pointers, or even variable assignments (although expressions
can be let-bound to identifiers).@footnote{@ncptl{} is not even
Turing-complete.  That is, it cannot perform arbitrary computations.}
The language operates primarily on integers, with support for string
constants and floating-point numbers in only a few constructs.  A
@ncptl{} program merely describes a communication pattern and the
@ncptl{} compiler generates code to implement that pattern.

As a domain-specific language, @ncptl{} contains primitives to send
and receive messages.  It is capable of measuring time, computing
statistics, and logging results.  It knows that it will be run in a
shared-nothing SPMD@footnote{Single Program, Multiple Data} style with
explicit message-passing.  As a result of its special-purpose design
@ncptl{} can express communication patterns in a clearer and terser
style than is possible using a general-purpose programming language.

The @ncptl{} language is case-insensitive.  @code{Hello} is the same
as @code{HELLO} or @code{hello}.  Furthermore, whitespace is
insignificant; one space has the same meaning as multiple spaces.
Comments are designated with a @samp{#} character and extend to the
end of the line.

We now describe the @ncptl{} grammar in a bottom-up manner, i.e.,
starting from primitives and working up to complete programs.  Note
that many of the sections in this chapter use the following syntax to
formally describe language elements:

@cartouche
@table @asis
@item @nonterm{nonterminal}
a placeholder for a list of language primitives and additional
placeholders

@item ::=
``is defined as''

@item @keyw{KEYWORD}
a primitive with special meaning to the language

@item [@dots{}]
optional items

@item (@dots{})
grouping of multiple items into one

@item *
zero or more occurrences of the preceding item

@item +
one or more occurrences of the preceding item

@item |
either the item to the left or the item to the right but not both
@end table
@end cartouche


@menu
* Primitives::                  Identifiers, strings, and integers
* Expressions::                 Ways to combine primitives
* Task descriptions::           Selecting groups of tasks at once
* Communication statements::    Sending and receiving messages
* I/O statements::              Relaying status and logging results
* Counter and timer statements::  
* Complex statements::          Combining statements into larger entities
* Other statements::            Statements for neither communication nor I/O
* Header declarations::         Language versioning and command-line parsing
* Complete programs::           Arguments + complex statements = programs
* Summary of the grammar::      Repeat of the EBNF rules that appeared above
@end menu


@node Primitives, Expressions, Grammar, Grammar
@section Primitives
@cindex primitives, language
@cindex constants, language

At the lowest level, @ncptl{} programs are composed of identifiers,
strings, and integers (and a modicum of punctuation).  Identifiers
consist of a letter followed by zero or more alphanumerics or
underscores.  @samp{potato}, @samp{x}, and @samp{This_is_program_123}
are all examples of valid identifiers.  Identifiers are used for two
purposes: variables and keywords.  Variables---referred to in the
formal grammar as @nonterm{ident}s---can be bound but not assigned.
That is, once a variable is given a value it retains that value for
the entire scope although it may be given a different value within a
subordinate scope for the duration of that scope.  All variables are
of integer type.  There are a number of variables that are predeclared
and maintained automatically by @ncptl{}@.  These are listed and
described in @ref{Predeclared variables}.  Predeclared variables can
be used by @ncptl{} programs but cannot be redeclared; an attempt to
do so will result in a compile-time error message.

@cindex keywords
Keywords introduce actions.  For example, @keyw{SEND} and
@keyw{RECEIVE} are keywords.  (A complete list of @ncptl{} keywords is
presented in @ref{Keywords}.)  Most keywords can appear in multiple
forms.  For example, @keyw{OUTPUT} and @keyw{OUTPUTS} are synonymous,
as are @keyw{COMPUTE} and @keyw{COMPUTES}, @keyw{A} and @keyw{AN}, and
@keyw{TASK} and @keyw{TASKS}.  The intention is for programs to use
whichever sounds better in an English-language sentence.  Keywords may
not be used as variable names; an attempt to do so will cause the
compiler to output a parse error.

@cindex whitespace
@cindex space
As a special case to increase program readability, a single @samp{-}
preceding a keyword is treated as a whitespace character.  Hence,
@samp{INTEGER-SIZED PAGE-ALIGNED MESSAGE} is equivalent to
@samp{INTEGER SIZED PAGE ALIGNED MESSAGE} and @samp{10 64-BYTE
MESSAGES} is equivalent to @samp{10 64 BYTE MESSAGES}.  However,
@samp{x-3} and @samp{3-x} still represent subtraction operations.

@cindex case sensitivity
Although identifiers are case insensitive---@samp{SEND} is the same as
@samp{send} is the same as @samp{sENd}---to increase clarity, this
manual presents keywords in uppercase and variables in lowercase.

@cindex strings
@cindex whitespace
@cindex space
@cindex case sensitivity
@cindex escape character
@cindex backslash
@cindex newline
@cindex quotes
Strings consist of double-quoted text.  Within a string---and only
within a string---whitespace and case are significant.  In particular,
a literal newline is honored but can be suppressed by preceding it
with a backslash as in the following example:

@example
@group
"This string\
contains some
newline characters."
@end group
@end example
@result{} This string contains some@*newline characters.

Use @samp{\"} for a double-quote character, @samp{\\} for a backslash,
and @samp{\n} for a newline character.  All other escape sequences
produce a warning message and are discarded.  As examples of valid
escape-sequence usage, the string @code{"@value{UPDATED-MONTH}"}
represents the text ``@value{UPDATED-MONTH}'' and @code{"I store
\"stuff\" in C:\\MyStuff."} represents the text ``I store "stuff" in
C:\MyStuff.''

@cindex integers
@cindex multipliers
Integers consist of an optional @samp{+} or @samp{-}@footnote{From the
lexer's perspective, integers are always unsigned and @samp{+} or
@samp{-} are merely operators (@pxref{Arithmetic expressions}).  The
parser, however, applies unary operators to integer literals.  This
alteration is evident in the output of the @backend{dot_ast} backend
(@pxref{The dot_ast backend}).} followed by one or more digits
followed by an optional multiplier.  This multiplier is unique to
@ncptl{} and consists of one of the following four letters:

@table @asis
@item @samp{K} (kilo)
multiplies the integer by 1,024

@item @samp{M} (mega)
multiplies the integer by 1,048,576

@item @samp{G} (giga)
multiplies the integer by 1,073,741,824

@item @samp{T} (tera)
multiplies the integer by 1,099,511,627,776
@end table

@cindex multipliers
@noindent
In addition, a multiplier can be @samp{E} (exponent) followed by a
positive integer.  An @samp{E} multiplier multiplies the base integer
by 10 raised to the power of the alternate integer.

Some examples of valid integers include @samp{2010}, @samp{-42},
@samp{64K} @w{(@math{=} 65,536),} and @samp{8E3} @w{(@math{=} 8,000).}


@node Expressions, Task descriptions, Primitives, Grammar
@section Expressions

Expressions, as in any language, are a combination of primitives and
other expressions in a semantically meaningful juxtaposition.
@ncptl{} provides arithmetic expressions, which evaluate to a number,
and relational expressions, which evaluate to either @sc{true} or
@sc{false}.  In addition, @ncptl{} provides the notion of an
@dfn{aggregate expression}, which represents a function (e.g.,
statistical mean) applied to every value taken on by an arithmetic
expression during the run of a program.

@menu
* Arithmetic expressions::      Arithmetic expressions
* Built-in functions::          List of additional arithmetics
* Aggregate expressions::       Expressions with a function applied
                                to all instances
* Aggregate functions::         List of functions allowed in the above
* Relational expressions::      Relating one expression to another
* Range expressions::           Expression lists
@end menu


@node Arithmetic expressions, Built-in functions, Expressions, Expressions
@subsection Arithmetic expressions
@cindex arithmetic expressions
@cindex expressions, arithmetic

@ncptl{} supports a variety of arithmetic expressions.  The following
is the language's order of operations from highest to lowest
precedence:

@multitable {multiplicative} {@samp{+}, @samp{-}, @keyw{NOT}, @samp{@nonterm{function}(@nonterm{expr}, @dots{})}, @samp{REAL(@nonterm{expr})}}
@kwindex REAL
@item unary
@tab @samp{+}, @samp{-}, @keyw{NOT}, @samp{@nonterm{function}(@nonterm{expr}, @dots{})}, @samp{REAL(@nonterm{expr})}

@item power
@tab @samp{**}

@item multiplicative
@tab @samp{*}, @samp{/}, @keyw{MOD}, @samp{<<}, @samp{>>}, @samp{&}

@item additive
@tab @samp{+}, @samp{-}, @samp{|}, @keyw{XOR}

@item conditional
@tab @samp{@nonterm{expr} @keyw{IF} @nonterm{rel_expr} @keyw{OTHERWISE} @nonterm{expr}}
@end multitable

@noindent
In addition, as in most programming languages, parentheses can be used
to group subexpressions.

The @samp{&} (``and''), @samp{|} (``or''), @keyw{XOR}, and @keyw{NOT}
operators perform bitwise, not logical, operations.  That is, they
accept numerical arguments, not truth-value arguments.  Hence, for
example, @samp{3 | 5} is equal @w{to @samp{7}.}

@samp{<<} and @samp{>>} are bit-shift operators.  That is, @samp{a <<
b} is the @ncptl{} equivalent of the mathematical expression
@texmath{a \times 2^b, a * 2^b} and @samp{a >> b} is the @ncptl{}
equivalent of the mathematical expression @texmath{a \div 2^b, a /
2^b}.  Consequently, negative values of @math{b} are valid and
correspond to a shift in the opposite direction.  (In contrast, C and
Perl treat a negative shift amount as a---usually large---unsigned
number and @cncp{Python} raises a @code{ValueError} exception on negative
shifts.)

@keyw{MOD} is a modulo @w{(i.e., remainder)} operator: @samp{10 MOD 3}
returns @samp{1}.  @samp{MOD} is guaranteed to return a nonnegative
remainder.  Hence, @samp{16 MOD 7} and @samp{16 MOD -7} both return
@samp{2} even though @samp{-5} is also mathematically valid.
Similarly, @samp{-16 MOD 7} and @samp{-16 MOD -7} both return @samp{5}
even though @samp{-2} is also mathematically valid.

The function calls allowed in @samp{@nonterm{function}(@nonterm{expr},
@dots{})} are listed and described in @ref{Built-in functions}.  All
functions take one or more arithmetic expressions as an argument.  The
operator @samp{*} represents multiplication; @samp{/} represents
division; and @samp{**} represents exponentiation (i.e., @samp{x ** y}
@iftex
@texmath{\equiv \lfloor x^y \rfloor, ==}).
@end iftex
@ifnottex
@math{== x^y}, rounded towards zero).
@end ifnottex
Note that @math{0^y} generates a run-time error for @texmath{y \leq 0,
y <= 0}.

A conditional expression @samp{@nonterm{expr1} @keyw{IF}
@nonterm{rel_expr} @keyw{OTHERWISE} @nonterm{expr2}} evaluates to
@nonterm{expr1} if the relational expression @nonterm{rel_expr}
evaluates to @sc{true} and @nonterm{expr2} if @nonterm{rel_expr}
evaluates to @sc{false}.@footnote{It is therefore analogous to
@samp{@nonterm{rel_expr} ? @nonterm{expr1} : @nonterm{expr2}} in the C
programming language.}  Relational expressions are described in
@ref{Relational expressions}.  As some examples of conditional
expressions, @samp{666 IF 2+2=5 OTHERWISE 777} returns @samp{777}
while @samp{666 IF 2+2=4 OTHERWISE 777} returns @samp{666}.

All operations proceed left-to-right except power and conditional
expressions, which proceed right-to-left.  That is, @samp{4-3-2} means
@math{(4-3)-2} but @samp{4**3**2} means @texmath{4^{(3^2)}, 4^(3^2)}.
Similarly, @samp{2 IF p=0 OTHERWISE 1 IF p=1 OTHERWISE 0} associates
like @samp{2 IF p=0 OTHERWISE (1 IF p=1 OTHERWISE 0)}, not like
@samp{(2 IF p=0 OTHERWISE 1) IF p=1 OTHERWISE 0}.

@menu
* Evaluation contexts::         Integer context vs. floating-point context
* Formal grammar for arithmetic expressions::  EBNF version of the preceding
                                               prose
@end menu


@node Evaluation contexts, Formal grammar for arithmetic expressions, Arithmetic expressions, Arithmetic expressions
@subsubheading Evaluation contexts
@cindex evaluation contexts

@ncptl{} normally evaluates arithmetic expressions in ``integer
context'', meaning that each subexpression is truncated to the nearest
integer after being evaluated.  Hence, @samp{24/5*5} is @samp{20}, not
@samp{24}, because @w{@samp{24/5*5} =}
@iftex
@tex
$\left\lfloor 24\div 5\right\rfloor \times 5 =
4 \times 5 =
20$.
@end tex
@end iftex
@ifnottex
@w{@samp{(24/5)*5} =}
@w{@samp{4*5} =}
@samp{20}.
@end ifnottex
There are a few situations, however, in which @ncptl{} evaluates
expressions in ``floating-point context'', meaning that no truncation
occurs:

@itemize @bullet
@item
within an @keyw{OUTPUTS} statement (@pxref{Writing to standard output})

@item
within a @keyw{LOGS} statement (@pxref{Writing to a log file})

@item
within a @keyw{BACKEND EXECUTES} statement (@pxref{Injecting arbitrary code})

@item
within a range in a @keyw{FOR EACH} statement (@pxref{Range loops})
when @ncptl{} is unable to find an arithmetic or geometric progression
by evaluating the component @nonterm{expr}s in integer context

@end itemize

@noindent
Within any of the preceding statements, the expression @samp{24/5*5}
evaluates @w{to 24.}  Furthermore, the expression @samp{24/5}
evaluates to 4.8, which is a number that can't be entered directly in
a @ncptl{} program.  (The language supports only integral constants,
as mentioned in @ref{Primitives}.)

The @ncptl{} language provides a special form called @keyw{REAL},
which resembles a single-argument function.  When evaluated in
floating-point context, @keyw{REAL} returns its argument evaluated
normally, as if @samp{REAL} were absent.  When evaluated in integer
context, however, @keyw{REAL} evalutes its argument in floating-point
context and then rounds the result to the nearest integer.
@iftex
As an example, @samp{9/2 + 1/2} is @samp{4} in integer context because
@w{@samp{9/2 + 1/2} =} @texmath{\lfloor 9/2 \rfloor + \lfloor 1/2
\rfloor = 4+0 = 4, N/A}.  However, @samp{REAL(9/2 + 1/2)} is @samp{5}
in integer context because @w{@samp{REAL(9/2 + 1/2)} =}
@texmath{\lfloor 9/2 + 1/2 + 0.5 \rfloor = \lfloor 5 + 0.5 \rfloor =
5, N/A}.
@end iftex
@ifnottex
For example, in integer context, @samp{9/2 + 1/2} is @samp{4} while
@samp{REAL(9/2 + 1/2)} is @samp{5}.
@end ifnottex


@node Formal grammar for arithmetic expressions,  , Evaluation contexts, Arithmetic expressions
@subsubheading Formal grammar for arithmetic expressions

For completeness, the following productions formalize the process by
which @ncptl{} parses arithmetic expressions:

@multitable {@nonterm{expr}} {::=} {@nonterm{cond_expr}}
@item @nonterm{expr}
@tab ::=
@tab @nonterm{cond_expr}
@end multitable

@multitable {@nonterm{cond_expr}} {::=} {@nonterm{add_expr} @keyw{IF} @nonterm{rel_expr} @keyw{OTHERWISE} @nonterm{add_expr}}
@item @nonterm{cond_expr}
@tab ::=
@tab @nonterm{add_expr} @keyw{IF} @nonterm{rel_expr} @keyw{OTHERWISE} @nonterm{add_expr}
@end multitable

@multitable {@nonterm{add_expr}} {::=} {@nonterm{add_expr} @keyw{XOR} @nonterm{mult_expr}}
@item @nonterm{add_expr}
@tab ::=
@tab @nonterm{mult_expr}
@item
@tab |
@tab @nonterm{add_expr} @samp{+} @nonterm{mult_expr}
@item
@tab |
@tab @nonterm{add_expr} @samp{-} @nonterm{mult_expr}
@item
@tab |
@tab @nonterm{add_expr} @samp{|} @nonterm{mult_expr}
@item
@tab |
@tab @nonterm{add_expr} @keyw{XOR} @nonterm{mult_expr}
@end multitable

@multitable {@nonterm{mult_expr}} {::=} {@nonterm{mult_expr} @keyw{MOD} @nonterm{unary_expr}}
@item @nonterm{mult_expr}
@tab ::=
@tab @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @samp{*} @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @samp{/} @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @keyw{MOD} @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @samp{>>} @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @samp{<<} @nonterm{unary_expr}
@item
@tab |
@tab @nonterm{mult_expr} @samp{&} @nonterm{unary_expr}
@end multitable

@multitable {@nonterm{power_expr}} {::=} {@nonterm{primary_expr} [@samp{**} @nonterm{unary_expr}]}
@item @nonterm{power_expr}
@tab ::=
@tab @nonterm{primary_expr} [@samp{**} @nonterm{unary_expr}]
@end multitable

@multitable {@nonterm{unary_expr}} {::=} {@nonterm{unary_operator} @nonterm{unary_expr}}
@item @nonterm{unary_expr}
@tab ::=
@tab @nonterm{power_expr}
@item
@tab |
@tab @nonterm{unary_operator} @nonterm{unary_expr}
@end multitable

@multitable {@nonterm{unary_operator}} {::=} {@samp{+} | @samp{-} | @keyw{NOT}}
@item @nonterm{unary_operator}
@tab ::=
@tab @samp{+} | @samp{-} | @keyw{NOT}
@end multitable

@multitable {@nonterm{primary_expr}} {::=} {@nonterm{func_name} @samp{(} @nonterm{enumerated_exprs} @samp{)}}
@item @nonterm{primary_expr}
@tab ::=
@tab @samp{(} @nonterm{expr} @samp{)}
@item
@tab |
@tab @nonterm{ident}
@item
@tab |
@tab @nonterm{integer}
@item
@tab |
@tab @nonterm{func_name} @samp{(} @nonterm{enumerated_exprs} @samp{)}
@item
@tab |
@tab @keyw{REAL} @samp{(} @nonterm{expr} @samp{)}
@end multitable

@multitable {@nonterm{enumerated_exprs}} {::=} {@nonterm{expr} [@samp{,} @nonterm{expr}]*}
@item @nonterm{enumerated_exprs}
@tab ::=
@tab @nonterm{expr} [@samp{,} @nonterm{expr}]*
@end multitable


@node Built-in functions, Aggregate expressions, Arithmetic expressions, Expressions
@subsection Built-in functions
@cindex built-in functions
@cindex functions, built-in

In addition to the operators described in @ref{Arithmetic
expressions}, @ncptl{} contains a number of built-in functions that
perform a variety of arithmetic operations that are often found to be
useful in network correctness and performance testing codes.  These
include simple functions that map one number to another as well as a
set of topology-specific functions that help implement communication
across various topologies, specifically @var{n}-ary trees, meshes,
tori, and @var{k}-nomial trees.  @ncptl{} currently supports the
following functions:

@multitable {@nonterm{func_name}} {::=} {@keyw{ABS} | @keyw{BITS} | @keyw{CBRT} | @keyw{FACTOR10} | @keyw{LOG10} | @keyw{MAX} | @keyw{MIN} | @keyw{ROOT} | @keyw{SQRT}}
@item @nonterm{func_name}
@tab ::=
@tab @keyw{ABS} | @keyw{BITS} | @keyw{CBRT} | @keyw{FACTOR10} | @keyw{LOG10} |
     @keyw{MAX} | @keyw{MIN} | @keyw{ROOT} | @keyw{SQRT}
@item
@tab |
@tab @keyw{CEILING} | @keyw{FLOOR} | @keyw{ROUND}
@item
@tab |
@tab @keyw{TREE_PARENT} | @keyw{TREE_CHILD}
@item
@tab |
@tab @keyw{KNOMIAL_PARENT} | @keyw{KNOMIAL_CHILD} | @keyw{KNOMIAL_CHILDREN}
@item
@tab |
@tab @keyw{MESH_NEIGHBOR} | @keyw{MESH_COORDINATE} | @keyw{MESH_DISTANCE}
@item
@tab |
@tab @keyw{RANDOM_UNIFORM} | @keyw{RANDOM_GAUSSIAN}
@item
@tab |
@tab @keyw{RANDOM_POISSON} | @keyw{RANDOM_PARETO}
@end multitable

All of the above take as an argument one or more numeric values (which
may be the result of an arithmetic expression).  The following
sections describe each function in turn.

@menu
* Integer functions::           Map one integer to another
* Floating-point functions::    Map one floating-point value to another
* n-ary tree functions::        Find parents and children in n-ary trees
* k-nomial tree functions::     Find parents and children in k-nomial trees
* Mesh/torus functions::        Find neighbors in 1-D, 2-D, and 3-D meshes/tori
* Random-number functions::     Generate unsynchronized pseudorandom numbers
@end menu


@node Integer functions, Floating-point functions, Built-in functions, Built-in functions
@subsubheading Integer functions
@cindex integer functions
@cindex functions, integer

@keyw{ABS} returns the absolute value of its argument.  For example,
@samp{ABS(99)} and @samp{ABS(-99)} are both @samp{99}.

@keyw{BITS} returns the minimum number of bits needed to store its
argument.  For example, @samp{BITS(12345)} is @samp{14} because
@texmath{2^{14}, 2^14} is 16,384, which is larger than 12,345, while
@texmath{2^{13}, 2^13} is 8,192, which is too small.  @samp{BITS(0)}
is defined to @w{be @samp{0}.}  Essentially, @samp{BITS(@math{x})}
represents
@iftex
@texmath{@lceil @log_2 x @rceil, ???}, i.e.,
@end iftex
the ceiling of the base-2 logarithm of @math{x}.  Negative numbers are
treated as their two's-complement equivalent.  For example,
@samp{BITS(-1)} returns @samp{32} on a 32-bit system and @samp{64} on
a 64-bit system.

@keyw{CBRT} is an integer cube root function.  It is essentially just
syntactic sugar for the more general @keyw{ROOT} function:
@w{@samp{CBRT(@var{x})} @texmath{\equiv, =}} @w{@samp{ROOT(3,
@var{x})}}.

@keyw{FACTOR10} rounds its argument down (more precisely, towards
zero) to the largest single-digit factor of an integral power @w{of
10.}  @samp{FACTOR10(4975)} is therefore @samp{4000}.  Similarly,
@samp{FACTOR10(-4975)} @w{is @samp{-4000}.}

@kwindex LOG10
@samp{LOG10(@math{x})} is
@iftex
@texmath{@lfloor @log x @rfloor,}, i.e.,
@end iftex
the floor of the base-10 logarithm of @math{x}.  For instance,
@w{@samp{LOG10(12345)}} is @samp{4} because @math{10^4} is the largest
integral power of 10 that does not exceed 12,345.

@keyw{MIN} and @keyw{MAX} return, respectively, the minimum and
maximum value in a list of numbers.  Unlike the other built-in
functions, @keyw{MIN} and @keyw{MAX} accept an arbitrary number of
arguments (but at least one).  For example, @samp{MIN(8,6,7,5,3,0,9)}
@w{is @samp{0}} and @samp{MAX(8,6,7,5,3,0,9)} @w{is @samp{9}.}

@kwindex ROOT
@samp{ROOT(@math{n}, @math{x})} returns
@iftex
@texmath{\root n \of x, N/A}, i.e.,
@end iftex
the @math{n}th root of @math{x}.  More precisely, it returns the
largest integer @math{r} such that @texmath{r^n \leq x, r^n <= x}.
@keyw{ROOT} is not currently defined on negative values of @math{x}.
As an example of @keyw{ROOT} usage, @samp{ROOT(5, 245)} is @samp{3}
because @texmath{3^5 = 243 \leq 245, 3^5 = 243 <= 245} while @math{4^5
= 1024 > 245}.  Similarly, @w{@samp{ROOT(2, 16)} =} @samp{4};
@w{@samp{ROOT(3, 27)} =} @samp{3}; @samp{ROOT(0, 0)} and @samp{ROOT(4,
-245)} each return a run-time error; and, @w{@samp{ROOT(-3, 8)} =}
@samp{0} (because @w{@samp{ROOT(-3, 8)} =} @w{@samp{1/ROOT(3, 8)} =}
@w{@samp{1/2} = @samp{0}).}

@keyw{SQRT} is an integer square root function.  It is essentially
just syntactic sugar for the more general @keyw{ROOT} function:
@w{@samp{SQRT(@var{x})} @texmath{\equiv, =}} @w{@samp{ROOT(2,
@var{x})}}.


@node Floating-point functions, n-ary tree functions, Integer functions, Built-in functions
@subsubheading Floating-point functions
@cindex floating-point functions
@cindex functions, floating-point

As stated in @ref{Arithmetic expressions}, there are certain
constructs in which expressions are evaluated in floating-point
context instead of integer context.  In such constructs, all of
@ncptl{}'s built-in functions accept and return floating-point values.
Furthermore, the @keyw{CBRT}, @keyw{LOG10}, @keyw{ROOT}, and
@keyw{SQRT} functions (@pxref{Integer functions}) compute
floating-point results, not integer results that are coerced into
floating-point format.

The following functions are not meaningful in integer context but are
in floating-point context:

@itemize @bullet
@item
@keyw{CEILING}

@item
@keyw{FLOOR}

@item
@keyw{ROUND}
@end itemize

@keyw{CEILING} returns the smallest integer not less than its
argument.  For example, @samp{CEILING(-7777/10)} is @samp{-777}.
(-778 is less than -777.7 while -777 is not less than -777.7.)

@keyw{FLOOR} returns the largest integer not greater than its
argument.  For example, @samp{FLOOR(-7777/10)} is @samp{-778}.
(-778 is not greater than -777.7 while -777 is greater than -777.7.)

@keyw{ROUND} rounds its argument to the nearest integer.  For example,
@samp{ROUND(-7777/10)} is @samp{-778}.

It is not an error to use @keyw{CEILING}, @keyw{FLOOR}, and
@keyw{ROUND} in an integer context; each function merely return its
argument unmodified.


@node n-ary tree functions, k-nomial tree functions, Floating-point functions, Built-in functions
@subsubheading @math{n}-ary tree functions
@cindex tree functions
@cindex functions, tree

@var{n}-ary trees are used quite frequently in communication patterns
because they require only logarithmic time (in the number of tasks)
for a message to propagate from the root to a leaf.  @ncptl{} supports
@var{n}-ary trees in the form of the @keyw{TREE_PARENT} and
@keyw{TREE_CHILD} functions.

@defun TREE_PARENT (@var{task_ID} @w{[, @var{fan-out}])}
@keyw{TREE_PARENT} takes a task number and an optional tree fan-out
(@math{n}) and returns the task's parent in an @var{n}-ary tree.
@math{n} defaults to @samp{2}, i.e., a binary tree.  Taking the
@keyw{TREE_PARENT} of any task less than 1 returns the value
@samp{-1}.
@end defun

@defun TREE_CHILD (@var{task_ID}, @var{child} @w{[, @var{fan-out}])}
@keyw{TREE_CHILD} takes a task number, a child number
(@texmath{0 \leq i < N, 0 <= i < N}), and an optional tree fan-out
(@math{n}), which again defaults to @samp{2}.  It returns the task
number corresponding to the given task's @math{child}th child.
@end defun

The following illustrations show how tasks are numbered in,
respectively, a 2-ary and a 3-ary tree:

@sp 1
@center @image{tree2}
@sp 1
@center @image{tree3}
@sp 1

As shown by the 2-ary tree, @w{task 1}'s children are @w{task 3} and
@w{task 4.}  Therefore, @samp{TREE_PARENT(3)} and
@samp{TREE_PARENT(4)} are both @samp{1}; @samp{TREE_CHILD(1, 0)} is
@samp{3}; and, @samp{TREE_CHILD(1, 1)} is @samp{4}.  In a 3-ary tree,
each task has three children.  Hence, the following expressions hold:

@itemize @bullet
@item @samp{TREE_PARENT(7, 3)} @result{} @samp{2}
@item @samp{TREE_PARENT(8, 3)} @result{} @samp{2}
@item @samp{TREE_PARENT(9, 3)} @result{} @samp{2}
@item @samp{TREE_CHILD(2, 0, 3)} @result{} @samp{7}
@item @samp{TREE_CHILD(2, 1, 3)} @result{} @samp{8}
@item @samp{TREE_CHILD(2, 2, 3)} @result{} @samp{9}
@end itemize


@node k-nomial tree functions, Mesh/torus functions, n-ary tree functions, Built-in functions
@subsubheading @var{k}-nomial tree functions
@cindex tree functions
@cindex functions, tree

@var{k}-nomial trees are an efficient way to implement
collective-communication operations in software.  Unlike in an
@var{n}-ary tree, the number of children in a @var{k}-nomial tree
decreases with increasing task depth (i.e., no task has more children
than the root).  The advantage is that the tasks that start
communicating earlier perform more work, which reduces the total
latency of the collective operation.  In contrast, in an @var{n}-ary
tree, the tasks that start communicating earlier finish earlier, at
the expense of increased total latency.  @ncptl{} supports
@var{k}-nomial trees via the @keyw{KNOMIAL_PARENT},
@keyw{KNOMIAL_CHILDREN}, and @keyw{KNOMIAL_CHILD} functions, as
described below.

@defun KNOMIAL_PARENT (@var{task_ID} @w{[, @var{fan_out}} @w{[, @var{num_tasks}]])}
@keyw{KNOMIAL_PARENT} takes a task number, the tree fan-out factor
(the ``@var{k}'' in ``@var{k}-ary''), and the number of tasks in the
tree.  It returns the task ID of the given task's parent.
@var{fan_out} defaults to @samp{2} and the number of tasks defaults to
@keyw{num_tasks} (@pxref{Predeclared variables}).
@end defun

@defun KNOMIAL_CHILDREN (@var{task_ID} @w{[, @var{fan_out}} @w{[, @var{num_tasks}]])}
@keyw{KNOMIAL_CHILDREN} takes the same arguments as
@keyw{KNOMIAL_PARENT} but returns the number of immediate descendents
the given task has.
@end defun

@defun KNOMIAL_CHILD (@var{task_ID}, @var{child} @w{[, @var{fan_out}} @w{[, @var{num_tasks}]])}
@keyw{KNOMIAL_CHILD} takes a task number, a child number (@texmath{0
\leq i <, 0 <= i <} @samp{KNOMIAL_CHILDREN(@dots{})}), the tree
fan-out factor, and the number of tasks in the tree.  It returns the
task number corresponding to the given task's @math{i}th child.  As in
@keyw{KNOMIAL_PARENT} and @keyw{KNOMIAL_CHILDREN}, @var{fan_out}
defaults to @samp{2} and the number of tasks defaults to
@keyw{num_tasks} (@pxref{Predeclared variables}).
@end defun

The following figure shows how @ncptl{} numbers tasks in a
@var{k}-nomial tree with @math{k=2} (a.k.a. a 2-nomial or binomial
tree).

@sp 1
@center @image{2nomial}
@sp 1

@noindent
The figure is structured with time flowing downwards.  That is, for a
multicast operation expressed over a 2-nomial tree, @w{task 0} sends a
message to @w{task 1} in the first time step.  Then, @w{task 0} sends
to @w{task 2} while @w{task 1} sends to @w{task 3}.  In the final
step, @w{task 0} sends to @w{task 4}, @w{task 1} sends to @w{task 5},
@w{task 2} sends to @w{task 6}, and @w{task 3} sends to @w{task
7}---all concurrently.  The following expressions also
hold, assuming there are a total of eight tasks in the computation:

@itemize @bullet
@item @samp{KNOMIAL_PARENT(0)} @result{} @samp{-1}
@item @samp{KNOMIAL_PARENT(1)} @result{} @samp{0}
@item @samp{KNOMIAL_CHILDREN(1)} @result{} @samp{2}
@item @samp{KNOMIAL_CHILD(1, 0)} @result{} @samp{3}
@item @samp{KNOMIAL_CHILD(1, 1)} @result{} @samp{5}
@item @samp{KNOMIAL_CHILDREN(7)} @result{} @samp{0}
@item @samp{KNOMIAL_CHILD(7, 0)} @result{} @samp{-1}
@end itemize

@var{k}-nomial trees for @math{k>2} are much less common in practice
than 2-nomial trees.  However, they may perform well when a task has
sufficient bandwidth to support multiple, simultaneous, outgoing
messages.  For example, a trinomial tree (i.e., a @var{k}-nomial tree
with @math{k=3}) should exhibit good performance if there is enough
bandwidth to send two messages simultaneously.  The following
illustration shows how @ncptl{} constructs a 27-task trinomial tree:

@sp 1
@center @image{3nomial,6in}
@sp 1

@noindent
As before, time flows downward (assuming a multicast operation) and
tasks are expected to communicate with their children in order.  The
following are some @ncptl{} @var{k}-nomial tree expressions and their
evaluations, assuming @keyw{num_tasks} is @samp{27}:

@itemize @bullet
@item @samp{KNOMIAL_PARENT(0, 3)} @result{} @samp{-1}
@item @samp{KNOMIAL_PARENT(2, 3)} @result{} @samp{0}
@item @samp{KNOMIAL_CHILDREN(2, 3)} @result{} @samp{4}
@item @samp{KNOMIAL_CHILD(2, 0, 3)} @result{} @samp{5}
@item @samp{KNOMIAL_CHILD(2, 1, 3)} @result{} @samp{8}
@item @samp{KNOMIAL_CHILD(2, 2, 3)} @result{} @samp{11}
@item @samp{KNOMIAL_CHILD(2, 3, 3)} @result{} @samp{20}
@item @samp{KNOMIAL_CHILD(2, 4, 3)} @result{} @samp{-1}
@item @samp{KNOMIAL_CHILDREN(8, 3)} @result{} @samp{2}
@item @samp{KNOMIAL_CHILDREN(8, 3, 26)} @result{} @samp{1}
@item @samp{KNOMIAL_CHILDREN(8, 3, 10)} @result{} @samp{0}
@end itemize


@node Mesh/torus functions, Random-number functions, k-nomial tree functions, Built-in functions
@subsubheading Mesh/torus functions
@cindex mesh functions
@cindex functions, mesh
@cindex torus functions
@cindex functions, torus

@ncptl{} provides three functions---@keyw{MESH_NEIGHBOR},
@keyw{MESH_COORDINATE}, and @keyw{MESH_DISTANCE}---that help treat
(linear) @w{task IDs} as positions on a multidimensional mesh or
torus.  Each of these functions takes a variable number of arguments,
determined by the dimensionality of the mesh (1-D, 2-D, or 3-D).

@quotation
@emph{Terminology note}: In the context of network topologies in
general and @keyw{MESH_NEIGHBOR}, @keyw{MESH_COORDINATE}, and
@keyw{MESH_DISTANCE} in particular, ``torus'' refers to a mesh
topology, of any number of dimensions, that contains wraparound links.
That is, nodes on the right side of the mesh are directly connected to
nodes on the left side of the mesh, nodes on the top of the mesh are
directly connected to nodes on the bottom of the mesh, and so forth.
A ``partial torus'' refers to a mesh topology of two or more
dimensions in which at least one dimension contains wraparound links
and at least one dimension does not.
@end quotation

@defun MESH_NEIGHBOR (@samp{(} @var{width} @samp{*}? @w{[, @var{height} @samp{*}?} @w{[, @var{depth} @samp{*}?]]} @samp{)}, @var{task_ID}, @samp{(} @var{x_offset} @w{[, @var{y_offset}} @w{[, @var{z_offset}]]} @samp{)})
@keyw{MESH_NEIGHBOR} returns a task's neighbor on a 1-D, 2-D, or 3-D
mesh or torus.  It takes exactly three arguments: a list of the
mesh/torus's dimensions, a task number, and a list of the neighbor's
offset in each dimension from the given task.  The two list arguments
must be parenthesized, even if they contain only a single element.
Each dimension in the dimension list may be followed by an asterisk to
indicate that the mesh wraps around in that dimension.  If not
specified, @var{height} and @var{depth} default to @samp{1}, and
@var{y_offset} and @var{z_offset} default to @samp{0}.  In the absence
of wraparound links, offsets that move off the mesh cause
@keyw{MESH_NEIGHBOR} to return the value @samp{-1}.
@end defun

@defun MESH_COORDINATE (@samp{(} @var{width} @samp{*}? @w{[, @var{height} @samp{*}?} @w{[, @var{depth} @samp{*}?]]} @samp{)}, @var{task_ID}, @var{coordinate})
@keyw{MESH_COORDINATE} returns a task's @var{x}, @var{y}, or @var{z}
coordinate on a 1-D, 2-D, or 3-D mesh/torus.  The first argument to
@keyw{MESH_COORDINATE} is a list of the mesh/torus's dimensions.  The
second argument is a task number.  The third argument should be
@samp{0} to calculate an @var{x} coordinate, @samp{1} to calculate a
@var{y} coordinate, or @samp{2} to calculate a @var{z} coordinate.
Coordinates are zero-origined.  Each dimension in the dimension list
may be followed by an asterisk to indicate that the mesh wraps around
in that dimension, but this has no impact on the result.  (Asterisks
are allowed solely for consistency with the other mesh functions.)
@end defun

@defun MESH_DISTANCE (@samp{(} @var{width} @samp{*}? @w{[, @var{height} @samp{*}?} @w{[, @var{depth} @samp{*}?]]} @samp{)}, @var{task_ID_1}, @var{task_ID_2})
@keyw{MESH_DISTANCE} returns the shortest Manhattan distance between
two tasks on a 1-D, 2-D, or 3-D mesh or torus.  It takes exactly three
arguments: a list of the mesh/torus's dimensions and two task numbers.
The list argument must be parenthesized, even if it contains only a
single element.  Each dimension in the dimension list may be followed
by an asterisk to indicate that the mesh wraps around in that
dimension.  If not specified, @var{height} and @var{depth} default to
@samp{1}.
@end defun

@keyw{MESH_NEIGHBOR}, @keyw{MESH_COORDINATE}, and @keyw{MESH_DISTANCE}
number tasks following the right-hand rule: left-to-right, then
top-to-bottom, and finally back-to-front, as shown in the following
illustrations of a 4-element (1-D) mesh, a @texmath{4 \times 3, 4x3}
(2-D) mesh, and a @texmath{4 \times 3 \times 2, 4x3x2} (3-D) mesh.
Examples of @keyw{MESH_NEIGHBOR}, @keyw{MESH_COORDINATE}, and
@keyw{MESH_DISTANCE} for 1-D, 2-D, and 3-D meshes follow the
corresponding illustration.

@sp 1
@center @image{mesh1D}
@sp 1

The following examples show how to use @keyw{MESH_NEIGHBOR} and
@keyw{MESH_COORDINATE} to calculate neighbors and coordinates on the
1-D mesh shown above:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4), 0, (-1))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4), 0, (+1))} @result{} @samp{1}
@item @samp{MESH_NEIGHBOR((4), 1, (-1))} @result{} @samp{0}
@item @samp{MESH_NEIGHBOR((4), 1, (+1))} @result{} @samp{2}
@item @samp{MESH_NEIGHBOR((4), 2, (-1))} @result{} @samp{1}
@item @samp{MESH_NEIGHBOR((4), 2, (+1))} @result{} @samp{3}
@item @samp{MESH_NEIGHBOR((4), 3, (-1))} @result{} @samp{2}
@item @samp{MESH_NEIGHBOR((4), 3, (+1))} @result{} @samp{-1}

@sp 1

@item @samp{MESH_COORDINATE((4), -1, 0)} @result{} @samp{-1}
@item @samp{MESH_COORDINATE((4), 0, 0)} @result{} @samp{0}
@item @samp{MESH_COORDINATE((4), 1, 0)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4), 2, 0)} @result{} @samp{2}
@item @samp{MESH_COORDINATE((4), 3, 0)} @result{} @samp{3}
@item @samp{MESH_COORDINATE((4), 4, 0)} @result{} @samp{-1}
@item @samp{MESH_COORDINATE((4), 2, 1)} @result{} @samp{0}
@item @samp{MESH_COORDINATE((4), 2, 2)} @result{} @samp{0}

@sp 1

@item @samp{MESH_DISTANCE((4), -1, 0)} @result{} @samp{-1}
@item @samp{MESH_DISTANCE((4), 1, 2)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4), 0, 3)} @result{} @samp{3}
@end itemize

We can treat the 1-D mesh as a 1-D torus (a ring) by putting a
@samp{*} after the length of the @math{x} dimension:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4*), 0, (-1))} @result{} @samp{3}
@item @samp{MESH_NEIGHBOR((4*), 3, (+1))} @result{} @samp{0}
@sp 1

@item @samp{MESH_DISTANCE((4*), -1, 0)} @result{} @samp{-1}
@item @samp{MESH_DISTANCE((4*), 1, 2)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4*), 0, 3)} @result{} @samp{1}
@end itemize

@noindent
The remaining @keyw{MESH_NEIGHBOR} examples return the same value as
before.  @keyw{MESH_COORDINATE} @emph{always} returns the same value
regardless of the presence or absence of wraparound links.

@sp 1
@center @image{mesh2D}
@sp 1

The next set of examples shows how to use @keyw{MESH_NEIGHBOR},
@keyw{MESH_COORDINATE}, and @keyw{MESH_DISTANCE} to calculate
neighbors, coordinates, and distances on the 2-D mesh shown above:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4, 3), 5, (-1, -1))} @result{} @samp{0}
@item @samp{MESH_NEIGHBOR((4, 3), 5, ( 0, -1))} @result{} @samp{1}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (+1, -1))} @result{} @samp{2}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (-1,  0))} @result{} @samp{4}
@item @samp{MESH_NEIGHBOR((4, 3), 5, ( 0,  0))} @result{} @samp{5}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (+1,  0))} @result{} @samp{6}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (-1, +1))} @result{} @samp{8}
@item @samp{MESH_NEIGHBOR((4, 3), 5, ( 0, +1))} @result{} @samp{9}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (+1, +1))} @result{} @samp{10}

@sp 1

@item @samp{MESH_COORDINATE((4, 3), 1, 0)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3), 6, 0)} @result{} @samp{2}
@item @samp{MESH_COORDINATE((4, 3), 6, 1)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3), 6, 2)} @result{} @samp{0}
@item @samp{MESH_COORDINATE((4, 3), 8, 0)} @result{} @samp{0}
@item @samp{MESH_COORDINATE((4, 3), 8, 1)} @result{} @samp{2}
@item @samp{MESH_COORDINATE((4, 3), 12, 0)} @result{} @samp{-1}

@sp 1

@item @samp{MESH_DISTANCE((4, 3),  1, 2)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4, 3),  2, 6)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4, 3),  0, 5)} @result{} @samp{2}
@item @samp{MESH_DISTANCE((4, 3),  3, 9)} @result{} @samp{4}
@item @samp{MESH_DISTANCE((4, 3), 11, 0)} @result{} @samp{5}
@end itemize

Wraparound links turn some out-of-bounds (@samp{-1}) neighbor values
into in-bounds values and reduce some of the shortest-path distances
between tasks:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4, 3), 5, (-2,  0))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4, 3), 5, (-2, -2))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4, 3*), 5, (-2,  0))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4, 3*), 5, (-2, -2))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4*, 3), 5, (-2,  0))} @result{} @samp{7}
@item @samp{MESH_NEIGHBOR((4*, 3), 5, (-2, -2))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4*, 3*), 5, (-2,  0))} @result{} @samp{7}
@item @samp{MESH_NEIGHBOR((4*, 3*), 5, (-2, -2))} @result{} @samp{11}

@sp 1

@item @samp{MESH_DISTANCE((4*, 3*),  1, 2)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4*, 3*),  2, 6)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4*, 3*),  0, 5)} @result{} @samp{2}
@item @samp{MESH_DISTANCE((4*, 3*),  3, 9)} @result{} @samp{3}
@item @samp{MESH_DISTANCE((4*, 3*), 11, 0)} @result{} @samp{2}
@end itemize

@sp 1
@center @image{mesh3D}
@sp 1

The final set of examples in this section shows how to use
@keyw{MESH_NEIGHBOR}, @keyw{MESH_COORDINATE}, and @keyw{MESH_DISTANCE}
to calculate neighbors, coordinates, and distances on the 3-D mesh
shown above:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4, 3, 2),  0, (0, 0, +1))} @result{} @samp{12}
@item @samp{MESH_NEIGHBOR((4, 3, 2),  0, (0, +1, 0))} @result{} @samp{4}
@item @samp{MESH_NEIGHBOR((4, 3, 2),  0, (+1, 0, 0))} @result{} @samp{1}
@item @samp{MESH_NEIGHBOR((4, 3, 2),  0, (+1, +1, +1))} @result{} @samp{17}
@item @samp{MESH_NEIGHBOR((4, 3, 2), 17, (+2, -1, -1))} @result{} @samp{3}
@item @samp{MESH_NEIGHBOR((4, 3, 2), 23, (+1, +1, +1))} @result{} @samp{-1}
@item @samp{MESH_NEIGHBOR((4, 3, 2),  7, (+100, -200, +300))} @result{} @samp{-1}

@sp 1

@item @samp{MESH_COORDINATE((4, 3, 2), -5, 0)} @result{} @samp{-1}
@item @samp{MESH_COORDINATE((4, 3, 2),  1, 0)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3, 2),  6, 0)} @result{} @samp{2}
@item @samp{MESH_COORDINATE((4, 3, 2),  6, 1)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3, 2),  6, 2)} @result{} @samp{0}
@item @samp{MESH_COORDINATE((4, 3, 2), 18, 0)} @result{} @samp{2}
@item @samp{MESH_COORDINATE((4, 3, 2), 18, 1)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3, 2), 18, 2)} @result{} @samp{1}
@item @samp{MESH_COORDINATE((4, 3, 2), 18, 3)} @result{} @error{} Invalid coordinate

@sp 1

@item @samp{MESH_DISTANCE((4, 3, 2), 23, 24)} @result{} @samp{-1}
@item @samp{MESH_DISTANCE((4, 3, 2),  5, 17)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4, 3, 2),  1, 16)} @result{} @samp{3}
@item @samp{MESH_DISTANCE((4, 3, 2), 14,  8)} @result{} @samp{5}
@item @samp{MESH_DISTANCE((4, 3, 2),  0, 23)} @result{} @samp{6}
@end itemize

As before, wraparound links affect some of the return values:

@itemize @bullet
@item @samp{MESH_NEIGHBOR((4*, 3*, 2*), 23, (+1, +1, +1))} @result{} @samp{0}
@item @samp{MESH_NEIGHBOR((4*, 3*, 2*),  7, (+100, -200, +300))} @result{} @samp{11}

@sp 1

@item @samp{MESH_DISTANCE((4*, 3*, 2*), 23, 24)} @result{} @samp{-1}
@item @samp{MESH_DISTANCE((4*, 3*, 2*),  5, 17)} @result{} @samp{1}
@item @samp{MESH_DISTANCE((4*, 3*, 2*),  1, 16)} @result{} @samp{3}
@item @samp{MESH_DISTANCE((4*, 3*, 2*), 14,  8)} @result{} @samp{4}
@item @samp{MESH_DISTANCE((4*, 3*, 2*),  0, 23)} @result{} @samp{3}
@end itemize


@node Random-number functions,  , Mesh/torus functions, Built-in functions
@subsubheading Random-number functions
@cindex random numbers
@cindex functions, random-number

@ncptl{} programs can utilize randomness in one of two ways.  The
functions described below are @emph{unsynchronized} across tasks.
That is, they can---and usually do---return a different value to each
task on each invocation.  One consequence is that these functions are
not permitted within a task expression (@pxref{Task descriptions})
because randomness would cause the tasks to disagree about who the
sources and targets of an operation are.  In contrast, the
@keyw{A RANDOM TASK} construct described in @ref{Binding variables}
returns a value guaranteed to be synchronized across tasks and thereby
enables random-task selection.

@defun RANDOM_UNIFORM (@var{lower_bound}, @var{upper_bound})
@kwindex RANDOM_UNIFORM
Return a number selected at random from a uniform distribution over
the range [@var{lower_bound}, @var{upper_bound}).
@end defun

@defun RANDOM_GAUSSIAN (@var{mean}, @var{stddev})
@kwindex RANDOM_GAUSSIAN
Return a number selected at random from a Gaussian distribution with
mean @var{mean} and standard deviation @var{stddev}.
@end defun

@defun RANDOM_POISSON (@var{mean})
@kwindex RANDOM_POISSON
Return an integer selected at random from a Poisson distribution with
mean @var{mean} and standard deviation @texmath{\sqrt{@var{mean}},
sqrt(@var{mean})}.
@end defun

@defun RANDOM_PARETO (@var{shape}, @var{scale})
@defunx RANDOM_PARETO (@var{shape}, @var{lower_bound}, @var{upper_bound})
@kwindex RANDOM_PARETO
With the two-argument form, return an integer selected at random from
a Pareto distribution with shape @var{shape} and scale @var{scale}.
With the three-argument form, return an integer selected at random
from a bounded Pareto distribution with shape @var{shape} and bounded
by the range [@var{lower_bound}, @var{upper_bound}].
@end defun


@node Aggregate expressions, Aggregate functions, Built-in functions, Expressions
@subsection Aggregate expressions
@cindex aggregate expressions
@cindex expressions, aggregate

Aggregate expressions (@nonterm{aggr_expr}s) are currently used
exclusively by the @keyw{LOGS} statement.  They represent an
expression with a given function applied to the aggregate of all
(dynamic) instances of that expression.  @nonterm{aggr_expr}s take one
of four forms:

@multitable {@nonterm{aggr_expr}} {::=} {@keyw{THE} [@nonterm{aggr_func} [@keyw{OF} [@keyw{THE}]]] @nonterm{expr}}
@item @nonterm{aggr_expr}
@tab ::=
@tab [@keyw{EACH}] @nonterm{expr}
@item
@tab |
@tab @keyw{THE} @nonterm{expr}
@item
@tab |
@tab @keyw{THE} @nonterm{aggr_func} [@keyw{OF} [@keyw{THE}]] @nonterm{expr}
@item
@tab |
@tab @keyw{A HISTOGRAM OF} [@keyw{THE}] @nonterm{expr}
@end multitable

@noindent
(In the above, @nonterm{expr} refers to an arithmetic expression
defined in @ref{Arithmetic expressions} and @nonterm{aggr_func} refers
to one of the functions defined in @ref{Aggregate functions}.)

The first form does not summarize @nonterm{expr}; every individual
instance of @nonterm{expr} is utilized.  The second form asserts that
@nonterm{expr} is a constant (i.e., all values are identical) and
utilizes that constant.@footnote{The program aborts with a run-time
error if @nonterm{expr} is not a constant.}  The third form applies
@nonterm{aggr_func} to the set of all values of @nonterm{expr} and
utilizes the result of that function.  The fourth form produces a
histogram of all values of @nonterm{expr}, i.e., a list of
@{@var{unique value}, @var{tally}@} pairs, sorted by @var{unique
value}.


@node Aggregate functions, Relational expressions, Aggregate expressions, Expressions
@subsection Aggregate functions
@cindex aggregate functions
@cindex functions, aggregate

The following functions, referred to collectively as
@nonterm{aggr_func}s, may be used in an aggregate expression
(@pxref{Aggregate expressions}):

@multitable {@nonterm{aggr_func}} {::=} {[@keyw{ARITHMETIC}] @keyw{MEAN} | @keyw{HARMONIC MEAN} | @keyw{GEOMETRIC MEAN} | @keyw{MEDIAN} |}
@item @nonterm{aggr_func}
@tab ::=
@tab [@keyw{ARITHMETIC}] @keyw{MEAN} | @keyw{HARMONIC MEAN} | @keyw{GEOMETRIC MEAN} |
     @keyw{MEDIAN} | @keyw{STANDARD DEVIATION} | @keyw{VARIANCE} | 
     @keyw{MEDIAN ABSOLUTE DEVIATION} | @keyw{SUM} | @keyw{MINIMUM} |
     @keyw{MAXIMUM} | @keyw{FINAL}
@end multitable

@keyw{MEAN} and @keyw{ARITHMETIC MEAN} are equivalent.  @keyw{MEDIAN}
is the value such that there are as many larger as smaller values.  If
there are an even number of values, @keyw{MEDIAN} is the arithmetic
mean of the two medians.  @keyw{FINAL} returns only the final value
measured.  The interpretation of the remaining functions should be
unambiguous.


@node Relational expressions, Range expressions, Aggregate functions, Expressions
@subsection Relational expressions
@cindex relational expressions
@cindex expressions, relational

Relational expressions (@nonterm{rel_expr}s) compare two arithmetic
expressions (@pxref{Arithmetic expressions}) or test an arithmetic
expression for a property.  A relational expression can be either
@sc{true} or @sc{false}.

@ncptl{} supports a variety of relational expressions.  The following
is the language's order of operations from highest to lowest
precedence:

@multitable {conjunctive} {@samp{=}, @samp{<}, @samp{>}, @samp{<=}, @samp{>=}, @samp{<>}, @keyw{DIVIDES}, @keyw{IS IN}, @keyw{IS NOT IN}}
@item unary/ @* binary/
@tab @keyw{IS EVEN}, @keyw{IS ODD} @*
     @samp{=}, @samp{<}, @samp{>}, @samp{<=}, @samp{>=}, @samp{<>}, @keyw{DIVIDES}, @keyw{IS IN}, @keyw{IS NOT IN}

@item conjunctive
@tab @samp{/\}

@item disjunctive
@tab @samp{\/}
@end multitable

@noindent
In addition, as in most programming languages, parentheses can be used
to group subexpressions.

The unary relation @keyw{IS EVEN} is @sc{true} if a given arithmetic
expression represents an even number and the unary relation
@keyw{IS ODD} is @sc{true} if a given arithmetic expression represents
an odd number.  For example, @w{@samp{456 IS EVEN}} is @sc{true} and
@w{@samp{64 MOD 6 IS ODD}} is @sc{false}.

The @ncptl{} operators @samp{=}, @samp{<}, @samp{>}, @samp{<=},
@samp{>=}, and @samp{<>} represent, respectively, the mathematical
relations @math{=}, @math{<}, @math{>}, @texmath{@leq, <=},
@texmath{@geq, >=}, and @texmath{@neq, <>}@c
@ifnottex
 @w{(i.e., not equal)}@c
@end ifnottex
.  These are all binary relations that operate on arithmetic
expressions (@pxref{Arithmetic expressions}).  For example,
@w{@samp{2+2 = 4}} is @sc{true} and @w{@samp{2**3 > 2**4}} is
@sc{false}. The @keyw{DIVIDES} relation is @sc{true} if the first
expression evenly divides the second, @w{i.e., that} @texmath{e_2
\equiv 0 \pmod{e_1}, e2 = 0 (mod e1)}.  Hence, @samp{2 DIVIDES 1234}
(equivalent to @w{@samp{1234 MOD 2 = 0}}) is @sc{true} while @samp{2
DIVIDES 4321} (equivalent to @w{@samp{4321 MOD 2 = 0}}) is @sc{false}.

The binary relation @keyw{IS IN} has the form

@multitable {MMMMM} {@nonterm{expr} @keyw{IS IN} @nonterm{range} [@code{,} @nonterm{range}]*}
@item @tab @nonterm{expr} @keyw{IS IN} @nonterm{range} [@code{,} @nonterm{range}]*
@end multitable

A @nonterm{range} represents a range expression.  Range expressions
are described in @ref{Range expressions}.  In short, a range
expression specifies a list of values by explicit enumeration, numeric
progression, or predicated combinations of other range expressions.
As an example, the relational expression @samp{x @keyw{IS IN} @w{@{1,
..., 5@}}} is @sc{true} if and only if @math{x} is one of 1, 2, 3, 4,
or 5.  As a more complex example, @samp{p*2 @keyw{IS IN} @w{@{0@},
@{1, 2, 4, ..., num_tasks*2@}}} is @sc{true} if and only if twice
@math{p} is either zero or a power of two less than or equal to twice
the number of tasks being used.

The complementary operation to @keyw{IS IN} is the binary relation
@keyw{IS NOT IN}.  Hence, @samp{4 IS NOT IN @w{@{3, ..., 5@}}} is @sc{false}
while  @samp{6 IS NOT IN @w{@{3, ..., 5@}}} is @sc{true}.

@w{Conjunction (@texmath{@wedge, ``and''})} and @w{disjunction
(@texmath{@vee, ``or''})} combine multiple relational expressions.
@w{@nonterm{rel_expr} @samp{/\}} @nonterm{rel_expr} is @sc{true} if
and only if both @nonterm{rel_expr}s are @sc{true}, and
@w{@nonterm{rel_expr} @samp{\/}} @nonterm{rel_expr} is @sc{true} if
and only if either @nonterm{rel_expr} is @sc{true}.  For example,
@samp{456 IS EVEN \/ 2**3 > 2**4} is @sc{true} and @samp{456 IS EVEN
/\ 2**3 > 2**4} is @sc{false}.  Conjunction and disjunction are both
short-circuiting operations.  Evaluation proceeds left-to-right.
Expressions such as @samp{x<>0 /\ 1/x=1} will therefore not result in
a divide-by-zero error.

@ncptl{} does not currently have a logical negation operator.

@menu
* Formal grammar for relational expressions::  EBNF version of the preceding
                                               prose
@end menu


@node Formal grammar for relational expressions,  , Relational expressions, Relational expressions
@subsubheading Formal grammar for relational expressions

For completeness, the following productions formalize the process by
which @ncptl{} parses relational expressions:

@multitable {@nonterm{rel_expr}} {::=} {@nonterm{rel_disj_expr}}
@item @nonterm{rel_expr}
@tab ::=
@tab @nonterm{rel_disj_expr}
@end multitable

@multitable {@nonterm{rel_disj_expr}} {::=} {[@nonterm{rel_disj_expr} @samp{\/}] @nonterm{rel_conj_expr}}
@item @nonterm{rel_disj_expr}
@tab ::=
@tab [@nonterm{rel_disj_expr} @samp{\/}] @nonterm{rel_conj_expr}
@end multitable

@multitable {@nonterm{rel_conj_expr}} {::=} {[@nonterm{rel_conj_expr} @samp{\/}] @nonterm{rel_primary_expr}}
@item @nonterm{rel_conj_expr}
@tab ::=
@tab [@nonterm{rel_conj_expr} @samp{/\}] @nonterm{rel_primary_expr}
@end multitable

@multitable {@nonterm{rel_primary_expr}} {::=} {@samp{(} @nonterm{rel_expr} @samp{)}}
@item @nonterm{rel_primary_expr}
@tab ::=
@tab @nonterm{eq_expr}
@item
@tab |
@tab @samp{(} @nonterm{rel_expr} @samp{)}
@end multitable

@multitable {@nonterm{eq_expr}} {::=} {@nonterm{expr} @keyw{IS NOT IN} @nonterm{range} [@code{,} @nonterm{range}]*}
@item @nonterm{eq_expr}
@tab ::=
@tab @nonterm{expr} @samp{=} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @samp{<} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @samp{>} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @samp{<=} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @samp{>=} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @samp{<>} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @keyw{DIVIDES} @nonterm{expr}
@item
@tab |
@tab @nonterm{expr} @keyw{IS EVEN}
@item
@tab |
@tab @nonterm{expr} @keyw{IS ODD}
@item
@tab |
@tab @nonterm{expr} @keyw{IS IN} @nonterm{range} [@code{,} @nonterm{range}]*
@item
@tab |
@tab @nonterm{expr} @keyw{IS NOT IN} @nonterm{range} [@code{,} @nonterm{range}]*
@end multitable


@node Range expressions,  , Relational expressions, Expressions
@subsection Range expressions
@cindex range expressions
@cindex expressions, range

Ranges are a powerful way of describing an ordered list of tasks.
Ranges come in three forms:

@enumerate
@item
Enumerated lists

@item
Arithmetic and geometric sequences

@item
List comprehensions
@end enumerate

@noindent
These are described with the following syntax:

@multitable {@nonterm{range}} {::=} {@samp{@{} @nonterm{expr} [@keyw{FOR EACH} @nonterm{ident} @keyw{IN} @nonterm{range} [@samp{,} @nonterm{range}]* ]+}
@item @nonterm{range}
@tab ::=
@tab @samp{@{} @nonterm{expr} [@samp{,} @nonterm{expr}]* [@samp{, ... ,} @nonterm{expr}] @samp{@}}
@item
@tab |
@tab @samp{@{} @nonterm{expr} [@keyw{FOR EACH} @nonterm{ident} @keyw{IN} @nonterm{range} [@samp{,} @nonterm{range}]* ]+
@item
@tab @tab @ @ @ @ [@keyw{WHERE} @nonterm{rel_expr}] @samp{@}}
@end multitable

Enumerated lists are the simplest type of range.  They represent a
list of explicitly specified values.  For example, the range
@samp{@{2**3, 2+4, 14/2, 8-3, 1+1+1, 0, 5*2-1@}} represents each of
the seven numbers 8, 6, 7, 5, 3, 0, and 9 in turn.  Duplicate values
are allowed in enumerated lists so @samp{@{9, 3, 9, 5, 5, 5, 0, 1, 1,
3@}} represents ten numbers even though not all of them are unique.

Arithmetic and geometric progressions are specified by including the
first few values of the progression, followed by an ellipsis, followed
by the final value of the progression.  A single initial value implies
an arithmetic progression with increment of @texmath{\pm 1, +/- 1},
depending on whether the final value is greater or less than the
initial value.  Two initial values imply an arithmetic progression
with an increment of @var{second}@math{-}@var{first}.  If three or
more initial values are provided, @ncptl{} first looks for an
arithmetic progression, then a geometric progression.  If @ncptl{}
finds neither an arithmetic nor a geometric progression, it
re-evaluates all of the @nonterm{expr}s in floating-point context
(@pxref{Arithmetic expressions}) and tries once again to find a
geometric progression.  If a pattern is still not found, a run-time
error message is generated.  As some examples of arithmetic and
geometric range expressions, the range @samp{@{10, ..., 1E6@}}
represents the values 10, 11, 12, 13, 14, 15, and so forth by ones up
to 1,000,000; the range @samp{@{10, 12, ..., 1E6@}} represents the
values 10, 12, 14, 16, and so forth by twos up to 1,000,000; and the
range @samp{@{10, 100, 1000, ..., 1E6@}} represents the values 10,
100, 1000, 10000, 100000, and 1000000.

Arithmetic and geometric progressions do not necessarily include the
final value.  For example, the range @samp{@{1, 4, ..., 15@}}
represents the values 1, 4, 7, 10, and 13 but not 15, even though 15
is specified as the final value of the range.  Similarly, @samp{@{15,
12, ..., 1@}} represents the values 15, 12, 9, 6, and 3 but not 1,
even though 1 is specified as the final value of the range.
Progressions stop at or before the final value, never after.  If the
number following the ellipsis is less than (respectively, greater
than) the first number in an increasing (respectively, decreasing)
range (as in @samp{@{15, 25, ..., 5@}}), then the range represents an
empty list of values.

List comprehensions provide a way to combine and filter ranges to
describe complex sequences of values with comparatively little
code.@footnote{Readers unfamilier with the concept of a list
comprehension may want to consult
@uref{http://en.wikipedia.org/wiki/List_comprehension, the Wikipedia
article on list comprehensions} for more information.}  A simple
example is @samp{@{n FOR EACH n IN @{1, ..., 10@}@}}, but this is not
particularly useful, as the range @samp{@{1, ..., 10@}} represents the
same list of values.  However, replacing the expression @samp{n} with
@samp{n/2} to get @samp{@{n/2 FOR EACH n IN @{1, ..., 10@}@}} returns
the values 0, 1, 1, 2, 2, 3, 3, 4, 4, and 5, which would be more
difficult to express without a list comprehension.  We can even
utilize only a subset of those values by applying a filter.  For
example, @samp{@{n/2 FOR EACH n IN @{1, ..., 10@} WHERE n/2 IS ODD@}}
represents the values 1, 1, 3, 3, and 5.  List comprehensions can be
multivariate, as in the following example:

@example
@{diag+ofs
  FOR EACH diag IN @{0, 11, ..., 99@}
    FOR EACH ofs IN @{-1, 0, 1@}
      WHERE diag+ofs IS IN @{0, ..., 99@}@}
@end example

That single range expression represents all cells on the tridiagonal
of a @texmath{10{\times}10, 10x10} matrix, with @w{cell 0} in the
upper left and @w{cell 99} in the lower right.  The first @keyw{FOR
EACH} generator binds @samp{diag} to each cell on the diagonal: 0, 11,
22, 33, and so forth.  The second @keyw{FOR EACH} generator binds
@samp{ofs} to each of -1, 0, and 1.  The @samp{WHERE} predicate, which
itself uses a range expression, selects only those values of
@samp{diag} and @samp{ofs} which which @w{0 @texmath{\leq, <=}
@t{diag+ofs} @texmath{\leq, <=} 99}.  The value @samp{diag+ofs} is
returned for all values for which the predicate is true.  The
following figure illustrates the values described by the preceding
range expression:

@sp 1
@center @image{tridiagonal}
@sp 1

Here are a number of additional examples of range expressions and the
values they represent:

@table @samp
@item @{2, 2, 2, 2, 2, 2@}
@result{} 2, 2, 2, 2, 2, 2

@item @{2, 2, ..., 2@}
@result{} 2

@item @{2, 2, ..., 1000@}
@result{} 2

@item @{20, 30, 40, ..., 55@}
@result{} 20, 30, 40, 50

@item @{20, 30, 40, ..., 30@}
@result{} 20, 30

@item @{20, 30, 40, ..., 20@}
@result{} 20

@item @{20, 30, 40, ..., 10@}
@result{} @texmath{\emptyset, [empty]}

@item @{2, ..., 50@}
@result{} 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,
19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50

@item @{2, 4, ..., 50@}
@result{} 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,
34, 36, 38, 40, 42, 44, 46, 48, 50

@item @{2, 4, 4, ..., 50@}
@result{} @error{Unable to find either an arithmetic or geometric pattern}

@item @{2, 4, 6, ..., 50@}
@result{} 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,
34, 36, 38, 40, 42, 44, 46, 48, 50

@item @{2, 4, 8, ..., 50@}
@result{} 2, 4, 8, 16, 32

@item @{1, 3, ..., 25@}
@result{} 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25

@item @{1, 3, 5, 7, 9, 11, 13, ..., 25@}
@result{} 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25

@item @{6561, 2187, 729, ..., 1@}
@result{} 6561, 2187, 729, 243, 81, 27, 9, 3, 1

@item @{100, 150, 225, ..., 10000@}
@result{} 100, 150, 225, 337, 506, 759, 1139, 1708, 2562, 3844, 5766, 8649

@item @{1, 4, 9, ..., 81@}
@result{} @error{Unable to find either an arithmetic or geometric pattern}

@item @{sqrt(s)**2 FOR EACH s IN @{1, ..., 16@}@}
@result{} 1, 1, 1, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 16

@item @{y*10+x @* @ @ FOR EACH y IN @{0, ..., 6@} @* @ @ @ @ FOR EACH x IN @{0, ..., 6@} @* @ @ @ @ @ @ WHERE (x IS EVEN /\ y IS ODD) \/ (y IS EVEN /\ x IS ODD)@}
@result{} 1, 3, 5, 10, 12, 14, 16, 21, 23, 25, 30, 32, 34, 36, 41, 43,
45, 50, 52, 54, 56, 61, 63, 65
@end table

The preceding examples used exclusively constant expressions.
However, as indicated by the definition of @nonterm{range} above, any
arbitrary arithmetic expression (@pxref{Arithmetic expressions}) is
valid.  Assuming that @samp{x} is currently bound to 123, the
following expansion holds:

@table @samp
@item @{x*10, x*9, x*8, ..., x*3@}
@result{} 1230, 1107, 984, 861, 738, 615, 492
@end table


@node Task descriptions, Communication statements, Expressions, Grammar
@section Task descriptions
@cindex tasks

@dfn{Task descriptions} are a powerful way of tersely describing the
sources and targets of @ncptl{} operations.  Task IDs range @w{from 0}
to @samp{num_tasks-1} (@pxref{Predeclared variables}).  Operations
involving out-of-bound task IDs are silently ignored.

As a side effect, a task description can declare a variable that can
be used in subsequent expressions.  (@xref{Expressions}.)  There are
two types of task descriptions: one for ``source'' tasks and one for
``target'' tasks.  The two are syntactically similar but semantically
different.  Specifically, the scope of a variable declared in a
@nonterm{target_tasks} specification is more limited than one declared
in a @nonterm{source_task} specification.

Before introducing @nonterm{source_task} and @nonterm{target_tasks}
specifications we first introduce the notion of a
@nonterm{restricted_ident}, which is a variable declaration that can
be used to define a set of tasks.  We then present @ncptl{}'s complete
set of mechanisms for describing sets of source and target tasks.

@menu
* Restricted identifiers::      Task specifications with constraints
* Source tasks::                Who performs an operation
* Target tasks::                Whom an operation is performed upon
@end menu


@node Restricted identifiers, Source tasks, Task descriptions, Task descriptions
@subsection Restricted identifiers
@cindex restricted identifiers
@cindex identifiers, restricted

A @dfn{restricted identifier} declares a variable, restricting it to
the set of tasks that satisfy a given relational expression
(@pxref{Relational expressions}).  The syntax, shown below, represents
the mathematical notion of
@iftex
@tex
\def\nonterm#1{\langle\var{#1}\rangle}   % Locally redefine.
``$\forall \nonterm{ident} |
(\nonterm{rel\_expr} \wedge (0 \leq \nonterm{ident} < \nonterm{\#tasks}))$''.
That is,
@end tex
@end iftex
``for all @nonterm{ident} such that @nonterm{rel_expr} is @sc{true}
and @nonterm{ident} is between zero and the number of tasks@dots{}''.

@multitable {@nonterm{restricted_ident}} {::=} {@nonterm{ident} @keyw{SUCH THAT} @nonterm{rel_expr}}
@item @nonterm{restricted_ident}
@tab ::=
@tab @nonterm{ident} @keyw{SUCH THAT} @nonterm{rel_expr}
@end multitable

As an example, @samp{evno SUCH THAT evno IS EVEN} describes all
even-numbered tasks.  On each such task, the variable @samp{evno}
takes on that task's ID@.  Similarly, @samp{thr SUCH THAT 3 DIVIDES
thr-1} describes tasks 1, 4, 7, 10, @w{13@enddots{}}.  On each of
those tasks, @samp{thr} will be bound to the task ID@.  On all other
tasks, @samp{thr} will be undefined.  When order matters (as in the
cases described in @ref{Sending} and @ref{Reordering task IDs}),
@nonterm{ident} takes on @w{task IDs} in increasing order.


@node Source tasks, Target tasks, Restricted identifiers, Task descriptions
@subsection Source tasks
@cindex tasks

A @nonterm{source_task} specification takes one of five forms:

@multitable {@nonterm{source_task}} {::=} {@keyw{TASKS} @nonterm{restricted_ident}}
@item @nonterm{source_task}
@tab ::=
@tab @keyw{ALL TASKS}
@item
@tab |
@tab @keyw{ALL TASKS} @nonterm{ident}
@item
@tab |
@tab @keyw{TASK} @nonterm{expr}
@item
@tab |
@tab @keyw{TASKS} @nonterm{restricted_ident}
@item
@tab |
@tab @keyw{TASK} @keyw{GROUP} @nonterm{ident}
@end multitable

@keyw{ALL TASKS} specifies that each task will perform a given
operation.  If followed by a variable name (@nonterm{ident}), each
task will individually bind @nonterm{ident} to its task ID---a number
from zero to one less than the total number of tasks.  That is,
@samp{ALL TASKS me} will bind @samp{me} to @samp{0} on @w{task 0},
@samp{1} on @w{task 1}, and so forth.

@samp{TASK @nonterm{expr}} specifies that only the task described by
arithmetic expression @nonterm{expr} will perform the given operation.
For example, @samp{TASK 2*3+1} says that only @w{task 7} will act; the
other tasks will do nothing.

@samp{TASKS @nonterm{restricted_ident}} describes a set of tasks that
will perform a given operation.  For instance, @samp{TASKS x SUCH THAT
x>0 /\ x<num_tasks-1}---read as ``tasks @math{x} such that @math{x} is
greater than zero and @math{x} is less than @i{num_tasks} minus
one''---expresses that a given operation should be performed on all
tasks except the first and last in the computation.  On each task that
satisfies the relational expression, @samp{x} will be bound to the
task ID as in @keyw{ALL TASKS} above.  Hence, @samp{x} will be
undefined on @w{task 0}, @samp{1} on @w{task 1}, @samp{2} on @w{task
2}, and so forth up to task @samp{num_tasks-1}, on which @samp{x} will
again be undefined.

@samp{@keyw{TASK GROUP} @nonterm{ident}} specifies that a previously
defined group of tasks will perform a given operation.  This form of
@nonterm{source_task} is described further in @ref{Binding variables}.

As per the definitions in @ref{Primitives} and @ref{Restricted
identifiers}, respectively, @nonterm{ident}s and
@nonterm{restricted_ident}s do not accept parentheses.  Hence,
@samp{TASKS (bad SUCH THAT bad IS EVEN)} and @samp{ALL TASKS
(no_good)} result in parse errors while @samp{TASKS fine SUCH THAT
fine IS EVEN} and @samp{ALL TASKS dandy} are acceptable constructs.
As an analogy, @samp{x = 3} is valid in many general-purpose
programming languages while @samp{(x) = 3} is not.

Variables declared in a @samp{source_task} specification are limited
in scope to the surrounding statement.


@node Target tasks,  , Source tasks, Task descriptions
@subsection Target tasks
@cindex tasks

A @nonterm{target_tasks} specification takes one of four forms:

@multitable {@nonterm{target_tasks}} {::=} {@keyw{TASKS} @nonterm{restricted_ident}}
@item @nonterm{target_tasks}
@tab ::=
@tab @keyw{ALL OTHER TASKS}
@item
@tab |
@tab @keyw{TASK} @nonterm{expr}
@item
@tab |
@tab @keyw{TASKS} @nonterm{restricted_ident}
@item
@tab |
@tab @keyw{TASK} @keyw{GROUP} @nonterm{ident}
@end multitable

@keyw{ALL OTHER TASKS} is just like @keyw{ALL TASKS} in a
@nonterm{source_task} specification (@pxref{Source tasks}) but applies
to all tasks @emph{except} the source task.  Also, unlike
@keyw{ALL TASKS}, @keyw{ALL OTHER TASKS} does not accept an
@nonterm{ident} term.

@samp{TASK @nonterm{expr}} specifies that only the task described by
arithmetic expression @nonterm{expr} is the target of the given
operation.  @nonterm{expr} can use a variable declared as a
@nonterm{source_task}.  For example, if @nonterm{source_task} is
@samp{ALL TASKS x}, then a @nonterm{target_tasks} of @samp{TASK (x+1)
MOD num_tasks} refers to each task's right neighbor (with wraparound
from @keyw{num_tasks} to @samp{0}).

@samp{TASKS @nonterm{restricted_ident}} describes a set of tasks that
will perform a given operation.  As with its @samp{source_task}
counterpart, a @nonterm{restricted_ident} declares a variable.
However, in a @nonterm{target_tasks} specification the variable's
scope is limited to the relational expression within the
@nonterm{restricted_ident}.  As an example, @samp{TASKS dst SUCH THAT
dst>src} refers to all tasks @samp{dst} with a greater ID than a
(previously declared) task @samp{src}.

@samp{TASK GROUP @nonterm{ident}} specifies that a previously defined
group of tasks will perform a given operation.  This form of
@nonterm{target_tasks} is described further in @ref{Binding
variables}.


@node Communication statements, I/O statements, Task descriptions, Grammar
@section Communication statements
@cindex communication statements
@cindex statements, communication

Communication statements are the core of any @ncptl{} program.  The
@ncptl{} language makes it easy to express a variety of communication
features:

@itemize @bullet
@item
synchronous or asynchronous communication

@item
unaligned, aligned (to arbitrary byte boundaries), or misaligned (from
a page boundary) message buffers

@item
ignored, touched, or verified message contents

@item
unique or recycled message buffers

@item
point-to-point or collective operations
@end itemize

Communication statements are performed by an arbitrary
@nonterm{source_task} (@pxref{Source tasks}) and may involve arbitrary
@nonterm{target_tasks} (@pxref{Target tasks}).  After explaining how
to describe a message to @ncptl{} (@pxref{Message specifications})
this section presents each communication statement in turn and
explains its purpose, syntax, and semantics.

@menu
* Message specifications::      Describing message parameters
* Sending::                     Sending and implicitly receiving messages
* Receiving::                   Explicitly receiving messages
* Awaiting completion::         Completing asynchronous sends/receives
* Multicasting::                One-to-many communication
* Reducing::                    Many-to-many communication
* Synchronizing::               Barrier synchronization
@end menu

@node Message specifications, Sending, Communication statements, Communication statements
@subsection Message specifications
@cindex messages

A @dfn{message specification} describes a set of messages.  The
following is a formal definition:

@multitable {@nonterm{recv_message_spec}} {::=} {@ @keyw{WITHOUT VERIFICATION} | @keyw{WITHOUT DATA TOUCHING}]}
@item @nonterm{message_spec}
@tab ::=
@tab @nonterm{item_count}
@item @tab @tab [@keyw{NONUNIQUE} | @keyw{UNIQUE}]
@item @tab @tab @nonterm{item_size}
@item @tab @tab [@keyw{UNALIGNED} |
@item @tab @tab @ @nonterm{message_alignment} @keyw{ALIGNED} |
@item @tab @tab @ @nonterm{message_alignment} @keyw{MISALIGNED}]
@item @tab @tab @keyw{MESSAGES}
@item @tab @tab [@keyw{WITH VERIFICATION} | @keyw{WITH DATA TOUCHING} |
@item @tab @tab @ @keyw{WITHOUT VERIFICATION} | @keyw{WITHOUT DATA TOUCHING}]
@item @tab @tab [@keyw{USING TAG}
@item @tab @tab @ @nonterm{expr} | @nonterm{string}]
@item @tab @tab [@keyw{FROM} [@nonterm{expr} @nonterm{data_multiplier} @keyw{INTO}]
@item @tab @tab @ @keyw{BUFFER} @nonterm{expr} | @keyw{THE DEFAULT BUFFER}]
@end multitable

Within a @keyw{RECEIVE} statement (@pxref{Receiving}), a
@nonterm{message_spec}'s @keyw{FROM} keyword must be replaced with
@keyw{INTO}.

A @keyw{SEND} statement's @keyw{WHO RECEIVES IT} clause
(@pxref{Sending}) utilizes a slightly different message specification,
which is referred to here as a @nonterm{recv_message_spec}:

@multitable {@nonterm{recv_message_spec}} {::=} {@ @keyw{WITHOUT VERIFICATION} | @keyw{WITHOUT DATA TOUCHING}]}
@item @nonterm{recv_message_spec}
@tab ::=
@tab [@keyw{SYNCHRONOUSLY} | @keyw{ASYNCHRONOUSLY}]
@item @tab @tab [@keyw{AS} [@keyw{A}|@keyw{AN}]
@item @tab @tab @ [@keyw{NONUNIQUE} | @keyw{UNIQUE}]
@item @tab @tab @ [@keyw{UNALIGNED} |
@item @tab @tab @ @ @nonterm{message_alignment} @keyw{ALIGNED} |
@item @tab @tab @ @ @nonterm{message_alignment} @keyw{MISALIGNED}]
@item @tab @tab @ @keyw{MESSAGES}]
@item @tab @tab [@keyw{WITH VERIFICATION} | @keyw{WITH DATA TOUCHING} |
@item @tab @tab @ @keyw{WITHOUT VERIFICATION} | @keyw{WITHOUT DATA TOUCHING}]
@item @tab @tab [@keyw{USING TAG}
@item @tab @tab @ @nonterm{expr} | @nonterm{string}]
@item @tab @tab [@keyw{INTO} [@nonterm{expr} @nonterm{data_multiplier} @keyw{INTO}]
@item @tab @tab @ @keyw{BUFFER} @nonterm{expr} | @keyw{THE DEFAULT BUFFER}]
@end multitable

Although not indicated by the preceding grammatical rule, a
@nonterm{recv_message_spec} is not allowed to be empty.  That is, at
least one of the optional clauses must be specified.

A @keyw{REDUCE} statement (@pxref{Reducing}) utilizes the following
variations of @nonterm{message_spec} and @nonterm{recv_message_spec},
respectively:

@multitable {@nonterm{reduce_message_spec}} {::=} {[@keyw{WITH DATA TOUCHING} | @keyw{WITHOUT DATA TOUCHING}]}
@item @nonterm{reduce_message_spec}
@tab ::=
@tab @nonterm{item_count}
@item @tab @tab [@keyw{NONUNIQUE} | @keyw{UNIQUE}]
@item @tab @tab [@keyw{UNALIGNED} |
@item @tab @tab @ @nonterm{message_alignment} @keyw{ALIGNED} |
@item @tab @tab @ @nonterm{message_alignment} @keyw{MISALIGNED}]
@item @tab @tab @keyw{INTEGERS} | @keyw{DOUBLEWORDS}
@item @tab @tab [@keyw{WITH DATA TOUCHING} | @keyw{WITHOUT DATA TOUCHING}]
@item @tab @tab [@keyw{USING TAG}
@item @tab @tab @ @nonterm{expr} | @nonterm{string}]
@item @tab @tab [@keyw{FROM} [@nonterm{expr} @nonterm{data_multiplier} @keyw{INTO}]
@item @tab @tab @ @keyw{BUFFER} @nonterm{expr} | @keyw{THE DEFAULT BUFFER}]
@end multitable

@multitable {@nonterm{reduce_target_message_spec}} {::=} {[@keyw{WITH DATA TOUCHING} | @keyw{WITHOUT DATA TOUCHING}]}
@item @nonterm{reduce_target_message_spec}
@tab ::=
@tab [@keyw{AS} @nonterm{item_count}
@item @tab @tab @ [@keyw{NONUNIQUE} | @keyw{UNIQUE}]
@item @tab @tab @ [@nonterm{message_alignment} @keyw{ALIGNED} |
@item @tab @tab @ @ @nonterm{message_alignment} @keyw{MISALIGNED}]
@item @tab @tab @ @keyw{INTEGERS} | @keyw{DOUBLEWORDS}]
@item @tab @tab [@keyw{WITH DATA TOUCHING} | @keyw{WITHOUT DATA TOUCHING}]
@item @tab @tab [@keyw{USING TAG}
@item @tab @tab @ @nonterm{expr} | @nonterm{string}]
@item @tab @tab [@keyw{INTO} [@nonterm{expr} @nonterm{data_multiplier} @keyw{INTO}]
@item @tab @tab @ @keyw{BUFFER} @nonterm{expr} | @keyw{THE DEFAULT BUFFER}]
@end multitable

@sp 1

We now describe in turn each component of a @nonterm{message_spec},
@nonterm{recv_message_spec}, @nonterm{reduce_message_spec}, and
@nonterm{reduce_target_message_spec}.

@menu
* Item count::                  How many messages should be sent?
* Unique messages::             Should messages recycle memory or not?
* Item size::                   How big is each message?
* Message alignment::           How should messages be aligned in memory?
* Data touching::               Should message contents be accessed explcitly?
* Tag matching::                In what order should messages be received?
* Buffer control::              What buffer should be used for each message?
* Blocking semantics::          Should the sender/receiver wait before proceeding?
@end menu


@node Item count, Unique messages, Message specifications, Message specifications
@subsubheading Item count

The @nonterm{item_count} says how many messages the
@nonterm{message_spec} represents:

@multitable {@nonterm{item_count}} {::=} {@keyw{A} | @keyw{AN} | @nonterm{expr}}
@item @nonterm{item_count}
@tab ::=
@tab @keyw{A} | @keyw{AN} | @nonterm{expr}
@end multitable

@noindent
@keyw{A} and @keyw{AN} are synonyms for the value @samp{1}.


@node Unique messages, Item size, Item count, Message specifications
@subsubheading Unique messages

Normally, the @ncptl{} backends recycle message memory to reduce the
program's memory requirements and improve performance.  By adding the
keyword @keyw{UNIQUE}, every message buffer will reside in a unique
memory region.  @keyw{NONUNIQUE} explicitly specifies the default,
buffer-recycling behavior.

@node Item size, Message alignment, Unique messages, Message specifications
@subsubheading Item size

The message size is represented by the @nonterm{item_size} nonterminal.
It can be empty or expressed in one of two other ways:

@multitable {@nonterm{item_size}} {::=} {@nonterm{expr} @nonterm{data_multiplier}}
@item @nonterm{item_size}
@tab ::=
@tab @texmath{\varepsilon, <empty>}
@item
@tab |
@tab @nonterm{expr} @nonterm{data_multiplier}
@item @tab | @tab @nonterm{data_type} @keyw{SIZED}
@end multitable

A @nonterm{data_multiplier} is a scaling factor that converts a
unitless number into a number of bytes.  The following are the valid
possibilities for @nonterm{data_multiplier} and the number of bytes by
which they multiply @nonterm{expr}:

@multitable {@nonterm{data_multiplier}} {::=} {@keyw{BIT} | @keyw{BYTE} | @keyw{HALFWORD} | @keyw{WORD} | @keyw{INTEGER} | @keyw{DOUBLEWORD} |}
@item @nonterm{data_multiplier}
@tab ::=
@tab @keyw{BIT} | @keyw{BYTE} | @keyw{HALFWORD} | @keyw{WORD} |
     @keyw{INTEGER} | @keyw{DOUBLEWORD} | @keyw{QUADWORD} | @keyw{PAGE} |
     @keyw{KILOBYTE} | @keyw{MEGABYTE} | @keyw{GIGABYTE}
@end multitable

@table @keyw
@item BIT
1/8 bytes, rounded up to the nearest integral number of bytes

@item BYTE
1 byte

@item HALFWORD
2 bytes

@item WORD
4 bytes

@item INTEGER
the number of bytes in the backend's fundamental integer type

@item DOUBLEWORD
8 bytes

@item QUADWORD
16 bytes

@item PAGE
the number of bytes in an operating-system page

@item KILOBYTE
1,024 bytes

@item MEGABYTE
1,048,576 bytes

@item GIGABYTE
1,073,741,824 bytes
@end table

@sp 1

A @nonterm{data_type} is an ``atomic'' unit of data.  It can be any of
the following:

@multitable {@nonterm{data_type}} {::=} {@keyw{BYTE} | @keyw{HALFWORD} | @keyw{WORD} | @keyw{INTEGER} | @keyw{DOUBLEWORD} |}
@item @nonterm{data_type}
@tab ::=
@tab @keyw{BYTE} | @keyw{HALFWORD} | @keyw{WORD} |
     @keyw{INTEGER} | @keyw{DOUBLEWORD} | @keyw{QUADWORD} | @keyw{PAGE}
@end multitable

@table @keyw
@item BYTE
1 byte

@item HALFWORD
2 bytes

@item WORD
4 bytes

@item INTEGER
the number of bytes in the backend's fundamental integer type

@item DOUBLEWORD
8 bytes

@item QUADWORD
16 bytes

@item PAGE
the number of bytes in an operating-system page
@end table

Hence, valid @nonterm{item_size}s include, for example, @samp{16
MEGABYTE} or @samp{PAGE SIZED}.   Empty
 @nonterm{item_size}s
@iftex
(shown in the grammar as @texmath{\varepsilon, N/A})
@end iftex
are equivalent to @samp{0 BYTE}.  Note that @keyw{INTEGER} varies in
size based on the backend, backend compiler, and CPU architecture but
is commonly @w{either 4} or @w{8 bytes}; @keyw{PAGE} varies in size
from operating system to operating system; each of the other
@nonterm{data_type}s has a fixed size, as indicated above.


@node Message alignment, Data touching, Item size, Message specifications
@subsubheading Message alignment
@cindex message alignment
@cindex alignment, message

Messages are normally allocated with arbitrary alignment in memory.
However, @ncptl{} can force a specific alignment relative to the
operating-system page size (commonly 4@dmn{KB} or 8@dmn{KB}, but
significantly larger sizes are gaining popularity).  A
@nonterm{message_alignment} is represented as follows:

@multitable {@nonterm{message_alignment}} {::=} {@nonterm{expr} @nonterm{data_multiplier}}
@item @nonterm{message_alignment}
@tab ::=
@tab @nonterm{data_type}
@item
@tab |
@tab @nonterm{expr} @nonterm{data_multiplier}
@end multitable

@samp{64 BYTE}, @samp{3 MEGABYTE}, and @samp{QUADWORD} are therefore
all valid examples of @nonterm{message_alignment}s.  Bit counts are
rounded up to the nearest byte count, so @samp{27 BITS} is in fact
equivalent to @samp{4 BYTES}.

The @keyw{ALIGNED} keyword forces @ncptl{} to align messages on
@emph{exactly} the specified alignment.  Hence, a @samp{HALFWORD ALIGNED}
message can begin at memory locations 0, 2, 4, 6, @w{8, @dots{},}
@iftex
@tex
\font\mathbb=msbm10
\hbox{$2k$} \quad \hbox{$(k \in \hbox{\mathbb Z}^+)$.}
@end tex
@end iftex
@ifnottex
@w{@math{2k}} (where @math{k} is a positive integer).
@end ifnottex
In contrast, the @keyw{MISALIGNED} keyword forces @ncptl{} to align
messages the given number of bytes (positive or negative) past a page
boundary.  For example, if pages are 8192 bytes in size then a message
described as @samp{HALFWORD MISALIGNED} can begin at memory locations
2, 8194, 16386, @w{24578, @dots{},}
@iftex
@tex
\font\mathbb=msbm10
\hbox{$\hbox{8192}k+2$} \quad \hbox{$(k \in \hbox{\mathbb Z}^+)$.}
@end tex
@end iftex
@ifnottex
@w{@math{8192k+2}} (where @math{k} is a positive integer).
@end ifnottex
Unlike @keyw{ALIGNED}, @keyw{MISALIGNED} supports negative alignments.
If the page size is 4096 bytes, then @samp{-10 BYTE MISALIGNED}
enables a message to begin at memory locations 4086, 8182, 12278, etc.
The @keyw{MISALIGNED} alignment is taken modulo the page size.
Therefore, with a 4096-byte page size, @samp{10000 BYTE MISALIGNED} is
the same as @samp{1808 BYTE MISALIGNED}.

The @keyw{UNALIGNED} keyword explicitly specifies the default
behavior, with messages aligned on arbitrary boundaries.


@node Data touching, Tag matching, Message alignment, Message specifications
@subsubheading Data touching
@cindex data touching
@cindex touching data

A @nonterm{message_spec} described as being @keyw{WITH DATA TOUCHING}
will force every word in a message to be both read and written
(``touched'').  When @nonterm{message_spec} describes an outgoing
message, the data will be touched before transmission.  When
@nonterm{message_spec} describes an incoming message, the data will be
touched after reception.  In a sense, @keyw{WITH DATA TOUCHING}
presents a more realistic assessment of network performance, as real
applications almost always access the data they send or receive.  It
also distinguishes between messaging layers that implicitly touch data
and those that can transmit data without having to touch it.  One
would expect the latter to perform better when the data is not
touched, as the former may be paying a penalty for touching the data.
However, either could perform better when messages are sent
@keyw{WITH DATA TOUCHING}, because the latter now has to pay the
penalty that the former has already paid.

Another form of data-touching supported by @ncptl{} is
@keyw{WITH VERIFICATION}.  This causes the source task to write known,
but randomly generated, data into the message before transmission and
the target task to verify that every bit was correctly received.  When
a message is received @keyw{WITH VERIFICATION}, the @code{bit_errors}
variable (@pxref{Predeclared variables}) is updated appropriately.

@keyw{WITHOUT DATA TOUCHING} and @keyw{WITHOUT VERIFICATION} are
synonymous.  Both explicitly specify the default behavior of neither
touching nor verifying message contents.


@node Tag matching, Buffer control, Data touching, Message specifications
@subsubheading Tag matching
@cindex message tags
@cindex tags, message
@cindex message ordering
@cindex ordering messages

Messages sent from @w{task @var{A}} to @w{task @var{B}} are normally
received in order.  However, the @keyw{USING TAG} clause enables a
program to enforce a particular order on message reception.
@keyw{USING TAG} takes a tag as an argument.  This tag can be either
an @nonterm{expr} or a @nonterm{string}.  In the latter case, @ncptl{}
will automatically hash the string to an @nonterm{expr}.  A message
sent with a given tag @var{tag} is received only by a @keyw{RECEIVE}
statement that also specifies tag @var{tag}.  If the @keyw{USING TAG}
clause is omitted, @var{tag} defaults @w{to @samp{0}}.

As an example of the difference @keyw{USING TAG} can make, consider
the following code that does not use tags:

@example
TASK 0 SENDS A MESSAGE TO UNSUSPECTING TASK 1 THEN
TASK 0 SLEEPS FOR 2 SECONDS THEN
TASK 0 SENDS A MESSAGE TO UNSUSPECTING TASK 1 THEN
TASK 1 RECEIVES A MESSAGE FROM TASK 0 THEN
TASK 1 SLEEPS FOR 2 SECONDS THEN
TASK 1 RECEIVES A MESSAGE FROM TASK 0
@end example

@noindent
In that example, the first send matches the first receive, then both
tasks simultaneously sleep for two seconds, and finally the second
send matches the second receive.  The total execution time should
therefore be just over two seconds.  Now consider the following
variation that uniquely tags each of the messages:

@example
TASK 0 SENDS A MESSAGE USING TAG 123 TO UNSUSPECTING TASK 1 THEN
TASK 0 SLEEPS FOR 2 SECONDS THEN
TASK 0 SENDS A MESSAGE USING TAG "stuff" TO UNSUSPECTING TASK 1 THEN
TASK 1 RECEIVES A MESSAGE USING TAG "stuff" FROM TASK 0 THEN
TASK 1 SLEEPS FOR 2 SECONDS THEN
TASK 1 RECEIVES A MESSAGE USING TAG 123 FROM TASK 0
@end example

@noindent
The first message is sent with tag @samp{123} while the second message
is sent with tag @samp{"stuff"}.  @w{Task 1} receives the messages in
the reverse order: first the @samp{"stuff"} message and then the
@samp{123} message.  Consequently, @w{task 1's} first @keyw{RECEIVE}
cannot complete until @w{task 0} has sent its first message, slept for
two seconds, and sent its second message.  @w{Task 1} can then receive
a message, sleep for two seconds, and receive its other message.  The
total execution time should therefore be just over four seconds, as
the new message ordering forces a serialization on the two
@keyw{SLEEPS}.

The following are a few things to keep in mind when using message tags:

@enumerate
@item
Using strings for tag values can benefit program readability and is
recommended for programs that utilize a small, fixed set of tags,
while using numerical expressions for tag values supports the
implementation of a variety of sophisticated communication patterns.

@item
@nonterm{string} tags are hashed, not coerced, to numerical values.
Hence, a message sent @samp{USING TAG 42} will not be matched by a
message received @samp{USING TAG "42"}.

@item
Different backends place different restrictions on the range of
accceptable tag values.  For example, the @backend{c_mpi} backend is
limited by MPI's tag values, which range @w{from 0} to at least
32,767---but usually more.  (The range @math{[0, 2^{31}-1]} is
probably typical.)  @ncptl{} will automatically map any @nonterm{expr}
or @nonterm{string} used as a tag value into whatever range the
backend supports.  One implication is that different tags in a
@ncptl{} program can map to the same tag at run time.  For example, if
a backend limits tag values to the range @math{[0, 32{,}767]}, then
@samp{USING TAG 131068} is equivalent to @samp{USING TAG 0}---or even
not using any tag at all.  Also, in that case, two arbitrary strings
have a 0.003% chance of mapping to the same tag (or 0.00000005% in the
more typical case for @backend{c_mpi}), which is unlikely but not
impossible.
@end enumerate


@node Buffer control, Blocking semantics, Tag matching, Message specifications
@subsubheading Buffer control
@cindex message buffers
@cindex buffers, message

The @ncptl{} run-time library allocates a unique message buffer for
each message sent/received with the @keyw{UNIQUE} keyword
(@pxref{Unique messages}).  The message buffers for @keyw{NONUNIQUE}
messages are recycled subject to the constraint that no two concurrent
transmissions will reference the same buffer.  For example, if a task
performs a synchronous send followed by a synchronous receive, those
operations must be executed serially and will therefore share a
message buffer.  If, instead, a task performs an asynchronous send
followed by an asynchronous receive, those operations may overlap, so
@ncptl{} will use different message buffers for the two operations.

Message specifications enable the programmer to override the default
buffer-allocation behavior.  If a message is sent @keyw{FROM BUFFER}
@nonterm{expr} or received @keyw{INTO BUFFER} @nonterm{expr}, the
message is guaranteed to be sent/received using the specified buffer
number.  For example, @keyw{FROM BUFFER} and @keyw{INTO BUFFER} can be
used to force a synchronous send and synchronous receive to use
different buffers or an asynchronous send and asynchronous receive to
use the same buffer.  If @nonterm{expr} is negative, the behavior is
the same as if @keyw{FROM BUFFER}/@keyw{INTO BUFFER} was not
specified.  @keyw{FROM THE DEFAULT BUFFER} and
@keyw{INTO THE DEFAULT BUFFER} also explicitly specify the default
buffer-allocation behavior.

It is also possible to specify byte offsets into a buffer.  For
example, a message sent @samp{FROM 4 WORDS INTO BUFFER 3} will be sent
from @w{4 words} @w{(12 bytes)} past @w{buffer 3}'s normal starting
memory address.


@node Blocking semantics,  , Buffer control, Message specifications
@subsubheading Blocking semantics
@cindex blocking
@cindex nonblocking

By default---or if @keyw{SYNCHRONOUSLY} is specified---messages are
sent synchronously.  That is, a sender blocks (i.e., waits) until the
message buffer is safe to reuse before it continues and a receiver
blocks until it actually receives the message.  The
@keyw{ASYNCHRONOUSLY} keyword specifies that messages should be sent
and received asynchronously.  That is, the program merely posts the
message (i.e., declares that it should eventually be sent and/or
received) and immediately continues executing.  Asynchronous messages
must be @dfn{completed} as described in @ref{Awaiting completion}.


@node Sending, Receiving, Message specifications, Communication statements
@subsection Sending

The @keyw{SEND} statement is fundamental to @ncptl{}@.  It is used to
send a multiple messages from multiple source tasks to multiple target
tasks.  The syntax is formally specified as follows:

@multitable {@nonterm{send_stmt}} {::=} {@keyw{TO} [@keyw{UNSUSPECTING}] @nonterm{target_tasks}}
@item @nonterm{send_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab [@keyw{ASYNCHRONOUSLY}] @keyw{SENDS}
@item @tab @tab @nonterm{message_spec}
@item @tab @tab @keyw{TO} [@keyw{UNSUSPECTING}] @nonterm{target_tasks}
@item
@tab |
@tab @nonterm{source_task}
@item @tab @tab [@keyw{ASYNCHRONOUSLY}] @keyw{SENDS}
@item @tab @tab @nonterm{message_spec}
@item @tab @tab @keyw{TO} @nonterm{target_tasks}
@item @tab @tab @keyw{WHO RECEIVE IT}
@item @tab @tab @nonterm{recv_message_spec}
@end multitable

@noindent
@nonterm{source_task} is described in @ref{Source tasks};
@nonterm{message_spec} and @nonterm{recv_message_spec} are described
in @ref{Message specifications}; and, @nonterm{target_tasks} is
described in @ref{Target tasks}.

The @keyw{SEND} statement's simplest form, ``@nonterm{source_task}
@keyw{SENDS} @nonterm{message_spec} @keyw{TO}
@nonterm{target_tasks}'', is fairly straightforward.  The following is
a example:

@example
TASK 0 SENDS A 0 BYTE MESSAGE TO TASK 1
@end example

@noindent
The only subtlety in the preceding statement is that it implicitly
causes @w{task 1} to perform a corresponding receive.  This receive
can be suppressed by adding the keyword @keyw{UNSUSPECTING} before the
@nonterm{target_tasks} description:

@example
TASK 0 SENDS A 0 BYTE MESSAGE TO UNSUSPECTING TASK 1
@end example

Here are some further examples of valid @nonterm{send_stmt}s:

@itemize @bullet
@item
@code{ALL TASKS SEND A 64 KILOBYTE MESSAGE TO TASK 0}

@item
@code{TASK num_tasks-1 SENDS 5 53 BYTE PAGE ALIGNED MESSAGES TO ALL
OTHER TASKS}

@item
@code{TASKS upper SUCH THAT upper>=num_tasks/2 ASYNCHRONOUSLY SEND A 0
BYTE MESSAGE TO TASK upper/2}

@item
@code{TASKS nonzero SUCH THAT nonzero>0 SEND nonzero 1E3 BYTE MESSAGES
TO UNSUSPECTING TASK 0}
@end itemize

There are a number of attributes associated with every message
transmission:

@itemize @bullet
@item
synchronous vs.@: asynchronous operation

@item
unique vs.@: recycled message buffers

@item
unaligned vs.@: aligned vs.@: misaligned message buffers

@item
no data touching vs.@: data touching vs.@: data verification

@item
first-in, first-out vs.@: selective message ordering based on message tags

@item
implicit vs.@: explicit message-buffer selection

@item
explicit byte offsets into message buffers
@end itemize

@noindent
A few of those appear in the preceding examples.

When @keyw{UNSUSPECTING} is omitted, the implicit @keyw{RECEIVE}
statement normally inherits all of the attributes of the corresponding
@keyw{SEND}@.  However, the second form of a @nonterm{send_stmt},
which contains a @keyw{WHO RECEIVES IT} (or @keyw{WHO RECEIVES THEM})
clause, enables the receiver's attributes to be overridden on a
per-attribute basis.  For instance, consider the following @keyw{SEND}
statement:

@example
TASK 0 SENDS A 1 MEGABYTE MESSAGE TO TASK 1 WHO RECEIVES IT
ASYNCHRONOUSLY
@end example

@noindent
The alternative sequence of statements that does not use @keyw{WHO
RECEIVES IT} is less straightforward to read because it splits a
single message transmission into two statements:

@enumerate
@item
@code{TASK 1 ASYNCHRONOUSLY RECEIVES A 1 MEGABYTE MESSAGE FROM TASK 0}

@item
@code{TASK 0 SENDS A 1 MEGABYTE MESSAGE TO UNSUSPECTING TASK 1}
@end enumerate

Some further examples of @keyw{WHO RECEIVES IT} follow:

@example
TASKS left SUCH THAT left IS EVEN SEND 5 2 KILOBYTE 64 BYTE ALIGNED
MESSAGES TO TASKS left+1 WHO RECEIVE THEM AS UNALIGNED MESSAGES WITH
DATA TOUCHING

TASK num_tasks-1 ASYNCHRONOUSLY SENDS A 1E5 BYTE MESSAGE WITH
VERIFICATION TO TASK 0 WHO RECEIVES IT SYNCHRONOUSLY

TASK leaf SUCH THAT KNOMIAL_CHILDREN(leaf,2)=0 SENDS A UNIQUE 1536
BYTE MESSAGE WITH DATA TOUCHING TO TASK KNOMIAL_PARENT(leaf,2) WHO
RECEIVES IT ASYNCHRONOUSLY AS A NONUNIQUE QUADWORD ALIGNED MESSAGE
WITHOUT DATA TOUCHING INTO BUFFER KNOMIAL_PARENT(leaf,2)
@end example

One subtlety of the @keyw{SEND} statement when used without
@keyw{UNSUSPECTING} involves the orderings of the sends and receives.
The rule is that receives are posted before sends.  Furthermore,
@nonterm{restricted_ident}s (@pxref{Restricted identifiers}) are
evaluated in order @w{from 0} @w{to @math{@var{num_tasks}-1}}.  The
implication is that a statement such as @samp{TASKS ev SUCH THAT ev IS
EVEN /\ ev<6 SEND A 4 WORD MESSAGE TO TASK ev+2} is exactly equivalent
to the following ordered sequence of statements (assuming
@w{@var{num_tasks} @texmath{\geq, >=} 5):}

@enumerate
@item @code{TASK 2 RECEIVES A 4 WORD MESSAGE FROM TASK 0}
@item @code{TASK 4 RECEIVES A 4 WORD MESSAGE FROM TASK 2}
@item @code{TASK 6 RECEIVES A 4 WORD MESSAGE FROM TASK 4}
@item @code{TASK 0 SENDS A 4 WORD MESSAGE TO UNSUSPECTING TASK 2}
@item @code{TASK 2 SENDS A 4 WORD MESSAGE TO UNSUSPECTING TASK 4}
@item @code{TASK 4 SENDS A 4 WORD MESSAGE TO UNSUSPECTING TASK 6}
@end enumerate

@noindent
(The @keyw{RECEIVE} statement is described in @ref{Receiving}.)

If the above sequence were executed, @w{tasks 2,} 4, and 6 would
immediately block on their receives @w{(steps 1--3)}.  @w{Task 0}
would awaken @w{task 2} by sending it a message @w{(step 4)}.  Then,
@w{task 2} would be able to continue to @w{step 5} at which point it
would send a message to @w{task 4}.  @w{Task 4} would then finally be
able to send a message to @w{task 6} @w{(step 6)}.  Hence, even though
the original @ncptl{} statement encapsulates multiple communication
operations, the component communications proceed sequentially because
of data dependences and because the operations are blocking.

As another example of send/receive ordering, consider the statement,
@samp{TASKS x SUCH THAT x IS IN @{1,4,5@} SEND A 768 BYTE MESSAGE FROM
4 DOUBLEWORDS INTO THE DEFAULT BUFFER TO TASKS y SUCH THAT y IS IN
@{6,2,3@}}.  This statement causes nine messages to be sent and
received and in the following order: @w{1 @result{} 2}, @w{1 @result{}
3}, @w{1 @result{} 6}, @w{4 @result{} 2}, @w{4 @result{} 3}, @w{4
@result{} 6}, @w{5 @result{} 2}, @w{5 @result{} 3}, @w{5 @result{} 6}.
The reason that @w{task 6} receives from each sender @emph{after}
@w{tasks 2} @w{and 3} relates to the comment above that
@nonterm{restricted_ident}s are evaluated in order @w{from 0} @w{to
@math{@var{num_tasks}-1}}.  One can therefore think of the preceding
@ncptl{} statement as being implemented with the following pseudocode:

@display
@b{for} s := 0 @b{to} num_tasks-1 @b{do}
@ @ @b{if} s @b{is in} @{1, 4, 5@} @b{then}
@ @ @ @ @b{for} r := 0 @b{to} num_tasks-1 @b{do}
@ @ @ @ @ @ @b{if} r @b{is in} @{6, 2, 3@} @b{then}
@ @ @ @ @ @ @ @ r @b{receives from} s
@b{for} s := 0 @b{to} num_tasks-1 @b{do}
@ @ @b{if} s @b{is in} @{1, 4, 5@} @b{then}
@ @ @ @ @b{for} r := 0 @b{to} num_tasks-1 @b{do}
@ @ @ @ @ @ @b{if} r @b{is in} @{6, 2, 3@} @b{then}
@ @ @ @ @ @ @ @ s @b{sends to} r
@end display


@node Receiving, Awaiting completion, Sending, Communication statements
@subsection Receiving

@ref{Sending}, mentioned the @nonterm{send_stmt}'s @keyw{UNSUSPECTING}
keyword, which specifies that the targets should not implicitly
perform a receive operation.  Because every send must have a matching
receive, @ncptl{} offers a @keyw{RECEIVE} statement that explicitly
receives a set of messages.  A @nonterm{receive_stmt} is much like a
@nonterm{send_stmt} (@pxref{Sending}) with the @nonterm{source_task}
and @nonterm{target_tasks} in the reverse order:

@multitable {@nonterm{receive_stmt}} {::=} {@keyw{TO} [@keyw{UNSUSPECTING}] @nonterm{target_tasks}}
@item @nonterm{receive_stmt}
@tab ::=
@tab @nonterm{target_tasks}
@item @tab @tab [@keyw{ASYNCHRONOUSLY}] @keyw{RECEIVE}
@item @tab @tab @nonterm{message_spec}
@item @tab @tab @keyw{FROM} @nonterm{source_task}
@end multitable

@noindent
@nonterm{target_tasks} is described in @ref{Target tasks};
@nonterm{message_spec} is described in @ref{Message specifications};
and, @nonterm{source_task} is described in @ref{Source tasks}.

Like other statements that contain both a @nonterm{source_task} and a
@nonterm{target_tasks}, the @keyw{RECEIVE} statement propagates all
variables declared by the @nonterm{source_task} to the
@nonterm{target_tasks}, as in

@example
TASKS src-1 RECEIVE A 1 MEGABYTE MESSAGE FROM ALL TASKS src.
@end example

@noindent
However, the @keyw{RECEIVE} statement is unique among @ncptl{}
statements in that it can alternatively propagate all variables
declared by the @nonterm{target_tasks} to the @nonterm{source_task},
as in

@example
ALL TASKS dst RECEIVE A 1 MEGABYTE MESSAGE FROM TASKS dst+1.
@end example

@cindex ambiguous @code{RECEIVE} statements
@noindent
The @keyw{RECEIVE} statement automatically determines the direction in
which variables should be propagated.  If the direction cannot
unambiguously be determined, the @ncptl{} compiler aborts with an
error message.  For example, the @keyw{RECEIVE} statement in the
following code is ambiguous because the @samp{bbb} in the expression
@w{@samp{aaa < bbb}} can refer to either the one in the @keyw{LET}
statement or the one in the @samp{TASKS bbb SUCH THAT bbb > 3}
expression:

@example
LET bbb BE 5 WHILE @{
  TASKS aaa SUCH THAT aaa < bbb RECEIVE A MESSAGE FROM TASKS bbb SUCH
  THAT bbb > 3 THEN
  TASKS ccc SUCH THAT ccc > 3 SEND A MESSAGE TO UNSUSPECTING TASKS
  ddd SUCH THAT ddd < ccc
@}
@end example

For each message sent via a @keyw{SEND}@dots{}@keyw{TO UNSUSPECTING}
statement there must be a @keyw{RECEIVE} statement that receives a
message of the same size.  The @nonterm{target_tasks}'s
@nonterm{message_spec} can, however, specify different values for
message uniqueness, message alignment, and data touching.  In
addition, the source and target do not need to agree on the use of the
@keyw{ASYNCHRONOUSLY} keyword.  The only restriction is that
@keyw{WITH VERIFICATION} will return spurious results if used by the
target but not by the source.  Hence, the following
@nonterm{send_stmt} and @nonterm{receive_stmt} correctly match each
other:

@example
TASK 0 SENDS 3 4 KILOBYTE MESSAGES TO UNSUSPECTING TASK 1

TASK 1 ASYNCHRONOUSLY RECEIVES 3 UNIQUE 4 KILOBYTE 48 BYTE ALIGNED
MESSAGES WITH DATA TOUCHING FROM TASK 0.
@end example

In general, it is better to use a single @keyw{SEND} statement with a
@keyw{WHO RECEIVES IT} clause (@pxref{Sending}) than a @keyw{RECEIVE}
plus a matching @keyw{SEND}@dots{}@keyw{TO UNSUSPECTING}; the former
is less error-prone than the latter.  However, the latter is useful
for programs in which a set of receives is posted, then the tasks
perform various communication, computation, and synchronization
operations, and---towards the end of the program---the matching sends
are posted.  That sort of split-phase structure requires separate
@keyw{SEND} and @keyw{RECEIVE} statements.


@node Awaiting completion, Multicasting, Receiving, Communication statements
@subsection Awaiting completion

When a message is sent or received asynchronously it must eventually
be @dfn{completed}.  In some messaging layers, asynchronous messages
are not even sent or received until completion time.  @ncptl{}
provides the following statement for completing messages that were
send/received asynchronously:

@multitable {@nonterm{wait_stmt}} {::=} {@keyw{AWAITS COMPLETION}}
@item @nonterm{wait_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{AWAITS COMPLETION}
@end multitable

@noindent
That is, a @nonterm{wait_stmt} simply specifies the set of tasks that
should block until all of their pending communications complete.
@nonterm{source_task} is as defined in @ref{Source tasks}.  Note that
a @nonterm{wait_stmt} blocks until @emph{all} pending communications
complete.  @ncptl{} does not provide finer-grained control over
completions.  It is safe, however, for a task to
@keyw{AWAIT COMPLETION} even if it has no asynchronous messages
pending.


@node Multicasting, Reducing, Awaiting completion, Communication statements
@subsection Multicasting

Although a single @nonterm{send_stmt} (@pxref{Sending}) can specify
multiple messages at once, these messages are sent one at a time.
@dfn{Multicasting} is a form of collective communication in which a
set of tasks collaborates to deliver a message from a source to
multiple targets.  With many messaging layers, multicasting a message
to @math{N} tasks is more efficient than sending a sequence of
@math{N} individual messages.  @ncptl{} supports multicasting as
follows:

@multitable {@nonterm{source_task}} {::=} {[@keyw{ASYNCHRONOUSLY}] @keyw{MULTICASTS}}
@item @nonterm{mcast_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab [@keyw{ASYNCHRONOUSLY}] @keyw{MULTICASTS}
@item @tab @tab @nonterm{message_spec}
@item @tab @tab @keyw{TO} @nonterm{target_tasks}
@end multitable

Unlike @nonterm{send_stmt}s, @nonterm{mcast_stmt}s do not support the
@keyw{UNSUSPECTING} keyword.  This is because @keyw{MULTICASTS} is a
collective operation: all parties are active participants in
delivering messages to the @nonterm{target_tasks}.

@nonterm{source_task} (@pxref{Source tasks}) and
@nonterm{target_tasks} (@pxref{Target tasks}) can be either disjoint
or overlapping sets.  That is, either of the following is legal:

@example
TASK 0 MULTICASTS A 16 BYTE MESSAGE TO TASKS recip SUCH THAT recip<4
TASK 0 MULTICASTS A 16 BYTE MESSAGE TO TASKS recip SUCH THAT recip>=4
@end example

@noindent
Note that in the first @nonterm{mcast_stmt}, @w{task 0} both sends and
receives a message, while in the second @nonterm{mcast_stmt}, @w{task
0} sends but does not receive.

The @keyw{MULTICASTS} statement supports not only traditional
one-to-many multicasting as shown in the preceding example but also
many-to-many multicasting---and the less interesting but still valid
many-to-one and one-to-one multicasting.  The constituent pairs of
communicating tasks are identical to those induced by the @keyw{SENDS}
statement (@pxref{Sending}).  For example, the statement

@example
TASKS s SUCH THAT s<3 MULTICAST A 1 KILOBYTE MESSAGE TO TASKS s SUCH
THAT s>6
@end example

@noindent
performs the collective analogue of

@example
TASKS s SUCH THAT s<3 SEND A 1 KILOBYTE MESSAGE TO TASKS s SUCH
THAT s>6
@end example

@noindent
Specifically, @w{task 0} will send a message to each of @w{tasks 7,}
8, @w{9, @dots{}}; @w{task 1} will send a message to each of @w{tasks
7,} 8, @w{9, @dots{}}; and @w{task 2} will send a message to each of
@w{tasks 7,} 8, @w{9, @enddots{}}


@node Reducing, Synchronizing, Multicasting, Communication statements
@subsection Reducing

A reduction operation is, in a sense, a complementary operation to a
multicast (@pxref{Multicasting}).  While a multicast delivers a
message from one source to multiple targets, a reduction combines
messages from multiple sources (by applying a commutative/associative
operator to corresponding elements) to a single target.  Reduction is
a collective operation: all parties collaborate to calculate the
reduced value(s).  As an example, if tasks 0, 1, and 2 collectively
reduce the messages @math{@{5, 1@}}, @math{@{2, 7@}}, and @math{@{3,
4@}} to @w{task 2} using the @w{``@math{+}'' operator}, then @w{task
2} will receive the message @math{@{10, 12@}}.  In fact, @ncptl{}'s
implementation of reductions also supports reductions to multiple
targets with each target receiving a copy of the reduced value.

The following grammatical rules define @ncptl{}'s many-to-many and
many-to-one reduction facilities:

@multitable {@nonterm{source_task}} {::=} {[@keyw{WHO RECEIVES THE RESULT} @nonterm{reduce_target_message_spec}]}
@item @nonterm{reduce_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{REDUCES}
@item @tab @tab @nonterm{reduce_message_spec}
@item @tab @tab @keyw{TO} @nonterm{source_task}
@item @tab @tab [@keyw{WHO RECEIVES THE RESULT} @nonterm{reduce_target_message_spec}]
@item
@tab |
@tab @nonterm{source_task}
@item @tab @tab @keyw{REDUCES}
@item @tab @tab @nonterm{reduce_message_spec}
@item @tab @tab [@keyw{TO} @nonterm{reduce_message_spec}]
@end multitable

@nonterm{reduce_message_spec} is defined in @ref{Message
specifications}.  Both the data providers and data receivers are
specified as @nonterm{source_task} nonterminals (@pxref{Source
tasks}).  This design enables any set of tasks to provide the data to
reduce and any disjoint or overlapping set of tasks to receive the
reduced data.  As with all communication in @ncptl{}, message contents
are opaque.  Furthermore, the grammar does not currently enable the
programmer to specify the commutative/associative operator to use.

A simple many-to-one reduction can be expressed in @ncptl{} with
@samp{ALL TASKS REDUCE 5 DOUBLEWORDS TO TASK 0}.  Note that the
definition of @nonterm{reduce_message_spec} and
@nonterm{reduce_target_message_spec} (@pxref{Message specifications})
supports reductions only of @keyw{INTEGER}s and @keyw{DOUBLEWORD}s,
not arbitrary @nonterm{data_type} values.  Omitting the optional
@samp{@keyw{TO} @nonterm{reduce_message_spec}}, as in @samp{TASKS rt
SUCH THAT 3 DIVIDES rt REDUCE AN INTEGER}, specifies that all tasks
performing the reduction will receive a copy of the reduced value.
The sources and targets can also be designated explicitly as in
@samp{TASKS xyz SUCH THAT xyz<num_tasks/2 REDUCE 100 DOUBLEWORDS TO
TASKS xyz+num_tasks/4}.  When that code is run with @w{8 tasks},
@w{tasks 0--3} reduce @w{100 doublewords} (800 bytes) apiece and
@w{tasks 2--5} each receive identical copies of the @w{100
doublewords} of reduced data.

Message data used with @keyw{REDUCES} can be transfered @keyw{WITH
DATA TOUCHING} (but not @keyw{WITH VERIFICATION}); data alignment can
be specified; and, messages buffers can be named explicitly.  The
following example represents fairly complex many-to-many usage of
@keyw{REDUCES}:

@example
TASKS rsrc SUCH THAT rsrc IS EVEN REDUCE 32 64-BYTE-ALIGNED INTEGERS
WITH DATA TOUCHING FROM BUFFER 2 TO TASKS rtarg SUCH THAT
rtarg<num_tasks/4 \/ rtarg>(3*num_tasks)/4 WHO RECEIVE THE RESULT AS
32 UNIQUE PAGE-ALIGNED INTEGERS WITHOUT DATA TOUCHING.
@end example



@node Synchronizing,  , Reducing, Communication statements
@subsection Synchronizing

@ncptl{} enables sets of tasks to perform @dfn{barrier
synchronization}.  The semantics are that no task can finish
synchronizing until all tasks have started synchronizing.  The syntax
is as follows:

@multitable {@nonterm{sync_stmt}} {::=} {@keyw{SYNCHRONIZES}}
@item @nonterm{sync_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{SYNCHRONIZES}
@end multitable

A @nonterm{sync_stmt} can be used to ensure that one set of statements
has completed before beginning another set.  For example, a @ncptl{}
program might have a set of tasks post a series of asynchronous
receives (@pxref{Receiving}), then make @samp{ALL TASKS SYNCHRONIZE}
before having another set of tasks perform the corresponding
@keyw{UNSUSPECTING} sends (@pxref{Sending}).  This procedure ensures
that all of the target tasks are ready to receive before the source
tasks start sending to them.


@node I/O statements, Counter and timer statements, Communication statements, Grammar
@section I/O statements

@ncptl{} provides two statements for presenting information.  One
statement writes simple messages to the standard output device and is
intended to be used for providing status information during the run of
a program.  The other statement provides a powerful mechanism for
storing performance and correctness data to a log file.

@menu
* Utilizing log-file comments::  Treating log-file comments as a database
* Writing to standard output::  Displaying status messages
* Writing to a log file::       Storing test results
@end menu


@node Utilizing log-file comments, Writing to standard output, I/O statements, I/O statements
@subsection Utilizing log-file comments
@cindex log files

@nonterm{output_stmt}s and @nonterm{log_stmt}s have limited access to
the @texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} pairs that are written as comments at the top
of every log file as shown in @ref{Log-file format}.  Given a key,
@var{key}, the string expression @samp{THE VALUE OF @var{key}}
represents the value associated with that key or the empty string if
@var{key} does not appear in the log-file comments:

@multitable {@nonterm{string_or_log_comment}} {::=} {@keyw{THE VALUE OF} @nonterm{string}}
@item @nonterm{string_or_log_comment}
@tab ::=
@tab @nonterm{string}
@item
@tab |
@tab @keyw{THE VALUE OF} @nonterm{string}
@end multitable

@noindent
That is, @samp{"CPU frequency"} means the literal string ``CPU
frequency'' while @samp{THE VALUE OF "CPU frequency"} translates to a
string like ``1300000000 Hz (1.3 GHz)''.  Environment variables are
also considered keys and are therefore acceptable input to a @keyw{THE
VALUE OF} construct.


@node Writing to standard output, Writing to a log file, Utilizing log-file comments, I/O statements
@subsection Writing to standard output
@cindex standard output

@ncptl{}'s @keyw{OUTPUT} keyword is used to write a message from one
or more source tasks (@pxref{Source tasks}) to the standard output
device.  This is useful for providing progress reports during the
execution of long-running @ncptl{} programs.  An @nonterm{output_stmt}
looks like this:

@multitable {@nonterm{output_stmt}} {::=} {[@keyw{AND} @ @ @nonterm{expr} | @nonterm{string_or_log_comment}]*}
@item @nonterm{output_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{OUTPUTS}
@item @tab @tab @nonterm{expr} | @nonterm{string_or_log_comment}
@item @tab @tab [@keyw{AND} @ @ @nonterm{expr} | @nonterm{string_or_log_comment}]*
@end multitable

The following are some sample @nonterm{output_stmt}s:

@example
TASK 0 OUTPUTS "Hello, world!"

TASKS nr SUCH THAT nr>0 OUTPUT nr AND "'s parent is " AND nr>>1 AND
" and its children are " AND nr<<1 AND " and " AND nr<<1+1

ALL TASKS me OUTPUT "Task " AND me AND " is running on host " AND THE
VALUE OF "Host name" AND " and plans to send to task " AND (me+1) MOD
num_tasks
@end example

@keyw{OUTPUT} does not implicitly output spaces between terms.  Hence,
@samp{OUTPUT "Yes" AND "No"} will output ``YesNo'', not @w{``Yes
No''.}  Although it is unlikely that a program would ever need to
output two arithmetic expressions with no intervening text, an empty
string can be used for this purpose: @samp{OUTPUT 6 AND "" AND 3}.

An @nonterm{output_stmt} implicitly outputs a newline character at the
end.  Additional newline characters can be output by embedding
@samp{\n} in a string.  (@pxref{Primitives}.)  @ncptl{} does not
provide a means for suppressing the newline, however.


@node Writing to a log file,  , Writing to standard output, I/O statements
@subsection Writing to a log file
@cindex log files

After performing a network correctness or performance test it is
almost always desirable to store the results in a file.  @ncptl{} has
language support for writing tabular data to a log file.  The
@nonterm{log_stmt} command does the bulk of the work:

@multitable {@nonterm{log_stmt}} {::=} {[@keyw{AND} @nonterm{aggr_expr} @keyw{AS} @nonterm{string_or_log_comment}]*}
@item @nonterm{log_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{LOGS}
@item @tab @tab @nonterm{aggr_expr} @keyw{AS} @nonterm{string_or_log_comment}
@item @tab @tab [@keyw{AND} @nonterm{aggr_expr} @keyw{AS} @nonterm{string_or_log_comment}]*
@end multitable

The idea behind a @nonterm{log_stmt} is that a set of source tasks
(@pxref{Source tasks}) log an aggregate expression (@pxref{Aggregate
expressions}) to a log file under the column heading
@nonterm{string_or_log_comment}.  Each task individually maintains a
separately named log file so there is no ambiguity over which task
wrote which entries.

Each (static) @keyw{LOGS} statement in a @ncptl{} program specifies
one or more columns of the log file.  Every dynamic execution of a
@keyw{LOGS} statement writes a single row to the log file.  A single
@keyw{LOGS} statement should suffice for most @ncptl{} programs.

The following are some examples of @nonterm{log_stmt}s:

@example
ALL TASKS LOG bit_errors AS "Bit errors"

TASK 0 LOGS THE msgsize AS "Bytes" AND
            THE MEDIAN OF (1E6*bytes_sent)/(1M*elapsed_usecs) AS "MB/s"
@end example

@noindent
The first example produces a log file like the following:

@cartouche
@example
"Bit errors"
"(all data)"
3
@end example
@end cartouche

@noindent
The second example produces a log file like this:

@cartouche
@example
"Bytes","MB/s"
"(only value)","(median)"
65536,179.9416266
@end example
@end cartouche

@noindent
Note that in each log file, the @ncptl{} run-time system writes two
rows of column headers for each column.  The first row contains
@nonterm{string_or_log_comment} as is.  The second row describes the
@nonterm{aggr_func} (@pxref{Aggregate functions}) used to aggregate
the data.  One or more rows of data follow.

Assume that the second @nonterm{log_stmt} presented above appears
within a loop (@pxref{Iterating}).  It is therefore important to
include the @keyw{THE} keyword before @samp{msgsize} to assert that
the expression @samp{msgsize} is constant across invocations of the
@nonterm{log_stmt} and that, consequently, only a single row of data
should be written to the log file.  Using @samp{msgsize} without the
@keyw{THE} would produce a column of data with one row per
@nonterm{log_stmt} invocation:

@cartouche
@example
"Bytes","MB/s"
"(all data)","(median)"
65536,179.9416266
65536,
65536,
65536,
65536,
     .
     .
     .
@end example
@end cartouche


The rules that determine how @keyw{LOGS} statements produce rows and
columns of a log file are presented below:

@enumerate
@item
Each @emph{static} @keyw{LOGS} statement (and @keyw{AND} clause within
a @keyw{LOGS} statement) in a program produces a unique column.

@item
Each @emph{dynamic} execution of a @keyw{LOGS} statement appends a row
to the column(s) it describes.

@item
Each top-level complex statement (@pxref{Complete programs}) produces
a new table in the log file.
@end enumerate

Note that the choice of column name is inconsequential for determining
what columns are written to the log file:

@example
TASK 0 LOGS 314/100 AS "Pi" AND 22/7 AS "Pi"
@end example

@cartouche
@example
"Pi","Pi"
"(all data)","(all data)"
3.14,3.142857143
@end example
@end cartouche

@menu
* Computing aggregates::        Forcing aggregates to compute a result
@end menu


@node Computing aggregates,  , Writing to a log file, Writing to a log file
@subsubheading Computing aggregates

What if @samp{msgsize} takes on a number of values throughout the
execution of the program and for each value a number of runs is
performed?  How would one log the median of each set of data?  Using
@samp{THE msgsize} won't work because the message size is not
constant.  Using @samp{msgsize} alone won't work either because
@ncptl{} would then take the median of the times gathered across
@emph{all} message sizes, which is undesirable.  The solution is for
the program to specify explicitly when aggregate functions
(@keyw{MEDIAN} and all of the other functions listed in @ref{Aggregate
functions}) compute a value:

@multitable {@nonterm{flush_stmt}} {::=} {@keyw{COMPUTES AGGREGATES}}
@item @nonterm{flush_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{COMPUTES AGGREGATES}
@end multitable

The intention is that an inner loop might @keyw{LOG} data after every
iteration and an outer loop would @samp{COMPUTE AGGREGATES} after each
iteration.


@node Counter and timer statements, Complex statements, I/O statements, Grammar
@section Counter and timer statements

Critical to any performance or correctness test is the ability to
specify which operations represent the test itself and should be
measured and which are setup or other uninteresting operations and
should not.  @ncptl{} automatically maintains a number of
``counters''---variables that represent message counts, byte counts,
bit-error counts, and elapsed time.  The complete list is presented in
@ref{Predeclared variables}.

Normally, a @ncptl{} program performs some setup operations,
@keyw{RESETS ITS COUNTERS} to zero, executes a communication pattern,
and logs some function of the resulting changes in counter values
(@pxref{Writing to a log file}).  If additional setup work needs to be
performed during an experiment, a program can @keyw{STORE ITS
COUNTERS}, perform any arbitrarily costly operations, @keyw{RESTORE
ITS COUNTERS}, and continue the experiment as if those operations
never happened.

Some @ncptl{} statements implicitly store and restore counters.  For
example, the @keyw{LOGS} statement @pxref{Writing to a log file})
takes up no time from the program's perspective, and counted loops
(@pxref{Counted loops}) bracket any warmup repetitions and post-warmup
synchronizations between a counter store and restore so no delays, bit
errors, or messaging operations contribute to the totals measured by
the experiment.

@menu
* Resetting counters::          Clearing message, byte, and time tallies
* Storing counter values::      Storing message, byte, and time tallies
* Restoring counter values::    Restoring stored message, byte, and time tallies
@end menu


@node Resetting counters, Storing counter values, Counter and timer statements, Counter and timer statements
@subsection Resetting counters
@cindex counters

At the start of an experiment, after all setup processing has
completed, all tasks that will eventually log measurement results
should zero out their counters:

@multitable {@nonterm{reset_stmt}} {::=} {@keyw{RESETS ITS COUNTERS}}
@item @nonterm{reset_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{RESETS ITS COUNTERS}
@end multitable

Hence, writing @samp{ALL TASKS RESET THEIR COUNTERS} causes each task
to reset all of the variables listed in @ref{Predeclared
variables}---with the exception of @keyw{num_tasks}---to zero.  Note
that @code{ITS} and @code{THEIR}, like @code{RESET} and @code{RESETS},
are considered synonyms (@pxref{Primitives}).


@node Storing counter values, Restoring counter values, Resetting counters, Counter and timer statements
@subsection Storing counter values
@cindex counters

A program can store the current values of all of the variables listed
in @ref{Predeclared variables} as follows:

@multitable {@nonterm{store_stmt}} {::=} {@keyw{STORES ITS COUNTERS}}
@item @nonterm{store_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{STORES ITS COUNTERS}
@end multitable

For example, writing @samp{TASK 0 STORES ITS COUNTERS} causes @w{task
0} to store the current values of @ocode{elapsed_usecs},
@ocode{total_msgs}, @ocode{bit_errors}, etc.  The values are not
modified.  Note that @code{ITS} and @code{THEIR}, like @code{STORE}
and @code{STORES}, are considered synonyms (@pxref{Primitives}).


@node Restoring counter values,  , Storing counter values, Counter and timer statements
@subsection Restoring counter values
@cindex counters

Counters can be restored to their most recently saved values with a
@nonterm{restore_stmt}:

@multitable {@nonterm{restore_stmt}} {::=} {@keyw{RESTORES ITS COUNTERS}}
@item @nonterm{restore_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{RESTORES ITS COUNTERS}
@end multitable

For example, writing @samp{TASKS t SUCH THAT 3 DIVIDES t RESTORE THEIR
COUNTERS} causes every third task to replace @ocode{elapsed_usecs},
@ocode{total_msgs}, @ocode{bit_errors}, etc@. with the values stored
by a corresponding @nonterm{store_stmt} (@pxref{Storing counter
values}).  Note that @code{ITS} and @code{THEIR}, like @code{RESTORE}
and @code{RESTORES}, are considered synonyms (@pxref{Primitives}).

An important feature of @keyw{STORES} and @keyw{RESTORES} is that they
can be nested.  That is, each @keyw{STORE} pushes a set of counter
values on a stack, and each @keyw{RESTORE} pops a set of counter
values from the stack.  Consequently, one can write code like the
following:

@cartouche
@example
ALL TASKS RESET THEIR COUNTERS THEN                                 #  1
ALL TASKS COMPUTE FOR 2 SECONDS THEN                                #  2
ALL TASKS STORE THEIR COUNTERS THEN                                 #  3
  ALL TASKS COMPUTE FOR 5 SECONDS THEN                              #  4
  ALL TASKS STORE THEIR COUNTERS THEN                               #  5
    ALL TASKS COMPUTE FOR 9 SECONDS THEN                            #  6
    ALL TASKS LOG ROUND(elapsed_usecs/1E6) AS "Should be 16" THEN   #  7
  ALL TASKS RESTORE THEIR COUNTERS THEN                             #  8
  ALL TASKS LOG ROUND(elapsed_usecs/1E6) AS "Should be 7" THEN      #  9
  ALL TASKS STORE THEIR COUNTERS THEN                               # 10
    ALL TASKS COMPUTE FOR 1 SECOND THEN                             # 11
    ALL TASKS LOG ROUND(elapsed_usecs/1E6) AS "Should be 8" THEN    # 12
  ALL TASKS RESTORE THEIR COUNTERS THEN                             # 13
  ALL TASKS LOG ROUND(elapsed_usecs/1E6) AS "Should be 7" THEN      # 14
  ALL TASKS RESTORE THEIR COUNTERS THEN                             # 15
ALL TASKS LOG ROUND(elapsed_usecs/1E6) AS "Should be 2".            # 16
@end example
@end cartouche

Indentation is used in the above to clarify which @keyw{RESTORE}
operations match which @keyw{STORE} operations.  The first
@keyw{STORE} statement @w{(line 3)} occurs after @w{2 seconds} have
elapsed.  The second @keyw{STORE} statement @w{(line 5)} occurs after
@w{@math{2+5=7} seconds} have elapsed.  When the @keyw{LOG} statement
in @w{line 7} is executed, it reports that @w{@math{2+5+9=16} seconds}
have elapsed.  The @keyw{RESTORE} statement in @w{line 8} then ``winds
back the clock'' to the previous @keyw{STORE} statement, the one in
@w{line 5}.  The next @keyw{LOG} statement @w{(line 9)} executes as if
@w{lines 5--8} never ran and therefore reports that only
@w{@math{2+5=7} seconds} have elapsed.  The @keyw{LOG} statement in
@w{line 12} sees an additional second of elapsed time due to @w{line
11's} @keyw{COMPUTE} statement, for a total of @w{@math{2+5+1=8}
seconds}.  However, the @keyw{RESTORE} in @w{line 13} makes it as if
that @keyw{COMPUTE} never happened.  Consequently, the @keyw{LOG}
statement in @w{line 14} reports that only @w{@math{2+5=7} seconds}
have elapsed.  Finally, the @keyw{RESTORE} in @w{line 15} sets the
timer to the value it had all the way back at @w{line 3}.  The final
@keyw{LOG} statement (@w{line 16}) therefore reports that only @w{2
seconds} have elapsed because @w{line 2} contains the only
@keyw{COMPUTE} statement whose execution time has not been discarded.

Because the @backend{interpret} backend and those derived from it use
logical time instead of physical time, the code listed above will
report all zeroes.  Replacing @samp{ROUND(elapsed_usecs/1E6)} with
just @samp{elapsed_usecs} will log the logical times
@math{@{6,5,8,7,3@}}.  That is, the @keyw{LOG} statement in @w{line 7}
sees six events after the initial @keyw{RESET};@footnote{Each
statement in the example corresponds to a single event and therefore
counts as one unit of time.} the @keyw{LOG} statement in @w{line 9}
sees only five events after the @keyw{RESET} (corresponding to
@w{lines 2}, 3, 4, 5, @w{and 9}); and so forth up to the final
@keyw{LOG} statement, which sees only three events: those produced by
@w{lines 2}, 3, @w{and 16}.

A program that calls @keyw{RESTORE} more times than it calls
@keyw{STORE} will abort with a fatal run-time error.


@node Complex statements, Other statements, Counter and timer statements, Grammar
@section Complex statements

The @ncptl{} statements presented in @ref{Communication statements},
@ref{I/O statements}, and @ref{Other statements} are all known as
@dfn{simple statements}.  This section expands upon the statements
already introduced by presenting @dfn{complex statements}.  In its
most basic form, a @nonterm{complex_stmt} is just a
@nonterm{simple_stmt}.  However, the primary purpose of a
@nonterm{complex_stmt} is to juxtapose simple statements and other
complex statements into more expressive forms.

Complex statements take the following form:

@multitable {@nonterm{complex_stmt}} {::=} {@nonterm{simple_stmt} [@keyw{THEN} @nonterm{complex_stmt}]}
@item @nonterm{complex_stmt}
@tab ::=
@tab @nonterm{simple_stmt} [@keyw{THEN} @nonterm{complex_stmt}]
@end multitable

The constituent simple statements include @keyw{FOR} loops, @keyw{LET}
bindings, @keyw{IF} conditionals, grouping constructs, and all of the
statements introduced in @ref{Communication statements}, @ref{I/O
statements}, and @ref{Other statements}:

@multitable {@nonterm{simple_stmt}} {::=} {@keyw{FOR} @nonterm{expr} @keyw{REPETITIONS} [@keyw{PLUS} @nonterm{expr} @keyw{WARMUP} @keyw{REPETITIONS}}
@item @nonterm{simple_stmt}
@tab ::=
@tab @keyw{FOR} @nonterm{expr} @keyw{REPETITIONS}
  [@keyw{PLUS} @nonterm{expr} @keyw{WARMUP} @keyw{REPETITIONS}
  [@keyw{AND A SYNCHRONIZATION}]]
  @nonterm{simple_stmt}
@item @tab | @tab
  @keyw{FOR EACH} @nonterm{ident} @keyw{IN} @nonterm{range}
  [@samp{,} @nonterm{range}]* @nonterm{simple_stmt}
@item @tab | @tab
  @keyw{FOR} @nonterm{expr} @nonterm{time_unit} @nonterm{simple_stmt}
@item @tab | @tab
  @keyw{LET} @nonterm{let_binding} [@keyw{AND} @nonterm{let_binding}]*
  @keyw{WHILE} @nonterm{simple_stmt}
@item @tab | @tab
  @keyw{IF} @nonterm{rel_expr} @keyw{THEN} @nonterm{simple_stmt}
  [@keyw{OTHERWISE} @nonterm{simple_stmt}]
@item @tab | @tab @samp{@{} [@nonterm{complex_stmt}] @samp{@}}
@item @tab | @tab @nonterm{send_stmt}
@item @tab | @tab @nonterm{receive_stmt}
@item @tab | @tab @nonterm{wait_stmt}
@item @tab | @tab @nonterm{mcast_stmt}
@item @tab | @tab @nonterm{reduce_stmt}
@item @tab | @tab @nonterm{sync_stmt}
@item @tab | @tab @nonterm{output_stmt}
@item @tab | @tab @nonterm{log_stmt}
@item @tab | @tab @nonterm{flush_stmt}
@item @tab | @tab @nonterm{reset_stmt}
@item @tab | @tab @nonterm{store_stmt}
@item @tab | @tab @nonterm{restore_stmt}
@item @tab | @tab @nonterm{assert_stmt}
@item @tab | @tab @nonterm{delay_stmt}
@item @tab | @tab @nonterm{touch_stmt}
@item @tab | @tab @nonterm{touch_buffer_stmt}
@item @tab | @tab @nonterm{processor_stmt}
@item @tab | @tab @nonterm{backend_stmt}
@end multitable

The remainder of this section describes in turn the @keyw{THEN}
construct and each of the just-introduced @nonterm{simple_stmt} types.

@menu
* Combining statements::        Performing multiple statements in sequence
* Iterating::                   Performing a statement multiple times
* Binding variables::           Lending values to variables
* Conditional execution::       Executing statements only if a condition is met
* Grouping::                    Treating multiple statements as one
@end menu


@node Combining statements, Iterating, Complex statements, Complex statements
@subsection Combining statements

The @keyw{THEN} keyword separates statements that are to be performed
sequentially.  For example, a simple ping-pong communication can be
expressed as follows:

@example
ALL TASKS RESET ALL COUNTERS THEN
TASK 0 SENDS A 0 BYTE MESSAGE TO TASK 1 THEN
TASK 1 SENDS A 0 BYTE MESSAGE TO TASK 0 THEN
TASK 0 LOGS elapsed_usecs/2 AS "One-way latency"
@end example

There is no implicit intertask synchronization across @keyw{THEN}
statements.  Consequently, the two communications specified in the
following statement will be performed concurrently:

@example
TASK 0 ASYNCHRONOUSLY SENDS AN 8 KILOBYTE MESSAGE TO TASK 1 THEN
TASK 1 ASYNCHRONOUSLY SENDS AN 8 KILOBYTE MESSAGE TO TASK 0 THEN
ALL TASKS AWAIT COMPLETION
@end example


@node Iterating, Binding variables, Combining statements, Complex statements
@subsection Iterating
@cindex iteration
@cindex loops

@ncptl{} provides a variety of looping constructs designed to
repeatedly execute a @nonterm{simple_stmt}.

@menu
* Counted loops::               Iterating for a given number of iterations
* Range loops::                 Iterating over lists of numbers
* Timed loops::                 Iterating for a given length of time
@end menu


@node Counted loops, Range loops, Iterating, Iterating
@subsubheading Counted loops
@cindex iteration
@cindex loops

The simplest form of iteration in @ncptl{} repeats a
@nonterm{simple_stmt} a given number of times.  The syntax is simply
``@keyw{FOR} @nonterm{expr} @keyw{REPETITIONS}
@nonterm{simple_stmt}''.  As could be expected, the @nonterm{expr}
term (@pxref{Arithmetic expressions}) specifies the number of
repetitions to perform.  Hence, the following @nonterm{simple_stmt}
outputs the phrase ``I will not talk in class'' 100 times:

@example
FOR 100 REPETITIONS ALL TASKS OUTPUT "I will not talk in class."
@end example

@keyw{FOR}@dots{}@keyw{REPETITIONS} can optionally specify a number of
``warmup'' repetitions to perform in addition to the base number of
repetitions.  The syntax is ``@keyw{FOR} @nonterm{expr}
@keyw{REPETITIONS} @keyw{PLUS} @nonterm{expr} @keyw{WARMUP
REPETITIONS} @nonterm{simple_stmt}''.  During warmup repetitions, the
@keyw{OUTPUTS} statement (@pxref{Writing to standard output}), the
@keyw{LOGS} statement (@pxref{Writing to a log file}), and the
@keyw{COMPUTES AGGREGATES} statement (@pxref{Computing aggregates})
are all suppressed (i.e., they have no effect) and none of the special
variables predeclared by @ncptl{} (@pxref{Predeclared variables}) are
updated.  Many benchmarks synchronize all tasks after performing a set
of warmup repetitions.  This behavior can be expressed conveniently as
part of a @ncptl{} @keyw{FOR} loop by appending the @keyw{AND A
SYNCHRONIZATION} clause:

@example
FOR 1000 REPETITIONS PLUS 3 WARMUP REPETITIONS AND A SYNCHRONIZATION
TASK 0 MULTICASTS A 1 MEGABYTE MESSAGE TO ALL OTHER TASKS
@end example

@noindent
@ncptl{} also provides a separate @keyw{SYNCHRONIZES} statement.  This
is described in @ref{Synchronizing}.

The importance of performing warmup repetitions is that many
communication layers give atypically poor performance on the first few
transmissions.  This may be because the messages miss in the cache;
because the communication layer needs to establish connections between
pairs of communicating tasks; or, because the operating system needs
to ``register'' message buffers with the network interface.
Regardless of the reason, specifying warmup repetitions helps make
performance measurements less variable.


@node Range loops, Timed loops, Counted loops, Iterating
@subsubheading Range loops
@cindex iteration
@cindex loops

Range loops are @ncptl{}'s most powerful looping construct.  Unlike
the counted-loop construct presented in @ref{Counted loops}, a range
loop binds a variable to a different value on each iteration.  Range
loops have the following syntax:

@multitable {MMMMM} {@keyw{IN} @nonterm{range} [@code{,} @nonterm{range}]*}
@item @tab @keyw{FOR EACH} @nonterm{ident}
@item @tab @keyw{IN} @nonterm{range} [@code{,} @nonterm{range}]*
@item @tab @nonterm{simple_stmt}
@end multitable

A @nonterm{range} represents a range expression.  Range expressions
are described in @ref{Range expressions}.  In short, a range
expression specifies a list of values by explicit enumeration, numeric
progression, or predicated combinations of other range expressions.
For a range loop, @ncptl{} successively binds a specified variable to
each @nonterm{expr} in each @nonterm{range} and evaluates the given
@nonterm{simple_stmt}.

The following are some examples of the @keyw{FOR EACH} statement from
simplest to most elaborate.  Each example uses @samp{i} as the loop
variable and @samp{TASK 0 OUTPUTS i} as the loop body.  The output
from each example is shown with a ``@print{}'' symbol preceding each
line.

@example
FOR EACH i IN @{8, 7, 5, 4, 5@} TASK 0 OUTPUTS i
@print{} 8
@print{} 7
@print{} 5
@print{} 4
@print{} 5

FOR EACH i IN @{1, ..., 5@} TASK 0 OUTPUTS i
@print{} 1
@print{} 2
@print{} 3
@print{} 4
@print{} 5

FOR EACH i IN @{5, ..., 1@} TASK 0 OUTPUTS i
@print{} 5
@print{} 4
@print{} 3
@print{} 2
@print{} 1

FOR EACH i IN @{1, ..., 5@}, @{8, 7, 5, 4, 5@} TASK 0 OUTPUTS i
@print{} 1
@print{} 2
@print{} 3
@print{} 4
@print{} 5
@print{} 8
@print{} 7
@print{} 5
@print{} 4
@print{} 5

FOR EACH i IN @{1, 4, 7, ..., 30@} TASK 0 OUTPUTS i
@print{} 1
@print{} 4
@print{} 7
@print{} 10
@print{} 13
@print{} 16
@print{} 19
@print{} 22
@print{} 25
@print{} 28

FOR EACH i IN @{3**1, 3**2, 3**3, ..., 3**7@} TASK 0 OUTPUTS i
@print{} 3
@print{} 9
@print{} 27
@print{} 81
@print{} 243
@print{} 729
@print{} 2187

FOR EACH i IN @{0@}, @{1, 2, 4, ..., 256@} TASK 0 OUTPUTS i
@print{} 0
@print{} 1
@print{} 2
@print{} 4
@print{} 8
@print{} 16
@print{} 32
@print{} 64
@print{} 128
@print{} 256

FOR EACH i IN @{neigh FOR EACH neigh IN @{0,...,100@} WHERE
MESH_DISTANCE((10,10), 55, neigh) IS IN @{1, 2@}@} TASK 0 OUTPUTS i.
@print{} 35
@print{} 44
@print{} 45
@print{} 46
@print{} 53
@print{} 54
@print{} 56
@print{} 57
@print{} 64
@print{} 65
@print{} 66
@print{} 75
@end example

That final example loops over all values that are a Manhattan distance
of either 1 or 2 from the @w{number 55} in a @texmath{10{\times}10,
10x10} layout of the numbers 0--99.

@keyw{FOR EACH} loops with constant progressions are executed exactly
once.  Note that if the @nonterm{range} does not contain an ellipsis
then all values are used, regardless of order or constancy:

@example
FOR EACH i IN @{4, 4, 4, ..., 4@} TASK 0 OUTPUTS i
@print{} 4

FOR EACH i IN @{4, 4, 4, 4, 4@} TASK 0 OUTPUTS i
@print{} 4
@print{} 4
@print{} 4
@print{} 4
@print{} 4
@end example


@node Timed loops,  , Range loops, Iterating
@subsubheading Timed loops
@cindex iteration
@cindex loops

A @dfn{timed loop} is similar to a counted loop (@pxref{Counted
loops}) but instead of running for a given number of iterations it
runs for a given length of time.  Timed loops are absent from all
general-purpose programming languages but can be quite useful in the
context of network correctness and performance testing.  The syntax of
@ncptl{}'s timed-loop construct is ``@keyw{FOR} @nonterm{expr}
@nonterm{time_unit} @nonterm{simple_stmt}''.  @nonterm{time_unit} is
unit of time as listed in @ref{Delaying execution} and @nonterm{expr}
specified the number of @nonterm{time_unit}s for which to execute.

The following example shows how to spend three seconds sending
messages from @w{task 0} to @w{task 1:}

@example
FOR 3 SECONDS TASK 0 SENDS A 1 MEGABYTE MESSAGE TO TASK 1
@end example

Although @ncptl{} tries its best to run for exactly the specified
length of time there will invariably be some error in the process.
Always use @ocode{elapsed_usecs} (@pxref{Predeclared variables}) as
the indicator of actual time instead of the time requested in the
loop.


@node Binding variables, Conditional execution, Iterating, Complex statements
@subsection Binding variables
@cindex binding variables
@cindex variables, binding
@cindex assigning values to variables
@cindex variable assignment

There are four ways to bind a value to a variable:

@enumerate
@item
as part a source or target task description (@pxref{Task descriptions})

@item
as part of a range loop (@pxref{Range loops})

@item via a command-line argument (@pxref{Command-line arguments})

@item
explicitly using the @keyw{LET} keyword (this section)
@end enumerate

The @keyw{LET} statement has the following form:

@multitable {MMMMM} {@keyw{WHILE} @nonterm{simple_stmt}}
@item @tab @keyw{LET} @nonterm{let_binding}
@item @tab [@keyw{AND} @nonterm{let_binding}]*
@item @tab @keyw{WHILE} @nonterm{simple_stmt}
@end multitable

@noindent
where @nonterm{let_binding} is defined as follows:

@multitable {@nonterm{let_binding}} {::=} {@nonterm{ident} @keyw{BE}} {|} {@keyw{A RANDOM TASK} [@nonterm{random_task_constraints}]}
@item @nonterm{let_binding}
@tab ::=
@tab @nonterm{ident} @keyw{BE}
@tab @tab expr
@item @tab @tab @tab | @tab @nonterm{source_task}
@item @tab @tab @tab | @tab @keyw{A RANDOM TASK} [@nonterm{random_task_constraints}]
@end multitable

The optional @nonterm{random_task_constraints} limits the set of tasks
from which @keyw{A RANDOM TASK} selects:

@multitable {@nonterm{random_task_constraints}} {::=} {@keyw{IN} @samp{[} @nonterm{expr} @samp{,} @nonterm{expr} @samp{]} [@keyw{BUT NOT} @nonterm{expr}]}
@item @nonterm{random_task_constraints}
@tab ::=
@tab @keyw{OTHER THAN} @nonterm{expr}
@item @tab | @tab @keyw{LESS THAN} @nonterm{expr} [@keyw{BUT NOT} @nonterm{expr}]
@item @tab | @tab @keyw{GREATER THAN} @nonterm{expr} [@keyw{BUT NOT} @nonterm{expr}]
@item @tab | @tab @keyw{IN} @samp{[} @nonterm{expr} @samp{,} @nonterm{expr} @samp{]} [@keyw{BUT NOT} @nonterm{expr}]
@end multitable

An @nonterm{ident} bound using the form @samp{@keyw{LET}
@nonterm{ident} @keyw{BE} @nonterm{source_task}} represents a group of
tasks and must therefore be accessed using the @keyw{TASK GROUP}
construct (@pxref{Source tasks}).  For example, in the @ncptl{}
program

@example
LET left BE TASKS t SUCH THAT t < num_tasks/2 WHILE TASK GROUP left
SENDS A 1 KILOBYTE MESSAGE TO TASK num_tasks - left - 1
@end example

@noindent
the @samp{@keyw{TASK GROUP} left} expression defines @samp{left} as
the group of tasks described by @samp{@keyw{TASKS} t @keyw{SUCH THAT}
t < num_tasks/2}.  The @samp{left} in @samp{num_tasks - left - 1}
refers back to @emph{that} definition of @samp{left}, not the
let-bound @samp{left}.  The @samp{t} in the let-binding is used only
to specify the group of tasks that will be bound to @samp{left}.  Its
scope is limited to the expression @samp{t < num_tasks/2}.  In other
words, the preceding example is equivalent to

@example
TASKS left SUCH THAT left < num_tasks/2 SEND A 1 KILOBYTE MESSAGE TO
TASK num_tasks - left - 1
@end example

The advantage of using @keyw{LET} to define a task group is that the
same---possible complex---description of a set of tasks can be reused
in multiple statements without having to type it repeatedly.

Here are some further examples of @keyw{LET}:

@example
LET reps BE 3 WHILE FOR reps REPETITIONS TASK 0 OUTPUTS "Laissez les
bons temps rouler."

LET src BE num_tasks-1 AND dest BE num_tasks/2 WHILE TASK src SENDS A
55E6 BIT MESSAGE TO TASK dst

LET hotspot BE A RANDOM TASK WHILE TASKS other SUCH THAT
other<>hotspot SEND 1000 1 MEGABYTE MESSAGES TO TASK hotspot

LET target BE A RANDOM TASK OTHER THAN 3 WHILE TASK 3 SENDS A 24 BYTE
MESSAGE TO TASK target

LET x BE A RANDOM TASK AND y be a RANDOM TASK GREATER THAN x WHILE
TASK 0 OUTPUTS "Did you know that " AND x AND " is less than " AND y
AND "?"

LET nonzero BE A RANDOM TASK LESS THAN 10 BUT NOT 0 WHILE TASK nonzero
SLEEPS FOR 2 SECONDS

LET middles BE A RANDOM TASK IN [1, num_tasks-2] WHILE TASK middles
ASYNCHRONOUSLY SENDS A 10 BYTE MESSAGE TO TASK ends SUCH THAT ends IS
NOT IN [1, num_tasks-2]

LET num BE 1000 AND num BE num*2 WHILE TASK 0 OUTPUTS num
@print{} 2000
@end example

That last example demonstrates that @keyw{LET} can bind a variable to
a function of its previous value.  It is important to remember,
though, that variables in @ncptl{} cannot be assigned, only bound to a
value for the duration of the current scope.  They can, however, be
bound to a different value for the duration of a child scope.  The
following example is an attempt to clarify the distinction between
binding and assignment:

@example
LET var BE 123 WHILE FOR 5 REPETITIONS LET var BE var+1 WHILE TASK 0
OUTPUTS var
@print{} 124
@print{} 124
@print{} 124
@print{} 124
@print{} 124
@end example

@noindent
In that example, @samp{var} is bound to @samp{123} for the scope
containing the @keyw{FOR} statement.  Then, within the @keyw{FOR}
statement, a new scope begins with @samp{var} being given one plus the
value it had in the outer scope, resulting in @samp{124}.  If @ncptl{}
supported assignment instead of variable-binding, the program would
have output @samp{124}, @samp{125}, @samp{126}, @samp{127}, and
@samp{128}.  Note that if @keyw{A RANDOM TASK} were used in the
example instead of @samp{var+1}, @samp{var} would get a different
value in each iteration.

When a variable is @keyw{LET}-bound to @keyw{A RANDOM TASK}, all tasks
agree on the random number.  Otherwise, task @var{A} might send a
message to task @var{B} but task @var{B} might be expecting to receive
the message from task @var{C}, thereby leading to a variety of
problems.  If there are no valid random tasks, as in the following
example, @keyw{A RANDOM TASK} will return @samp{-1}:

@example
LET invalid_task BE A RANDOM TASK GREATER THAN num_tasks WHILE TASK 0
OUTPUTS invalid_task
@print{} -1
@end example

@noindent
Furthermore, the @nonterm{expr} passed to @keyw{GREATER THAN} is
bounded from below by @samp{0} and the @nonterm{expr} passed to
@keyw{LESS THAN} is bounded from above by @samp{num_tasks-1}.  Hence,
the following @ncptl{} statement will always output values less than
or equal to @samp{num_tasks-1} (unless @keyw{num_tasks} is greater
than @texmath{1 \times 10^6, 1*10^6}, of course, in which case it will
always output values less than @texmath{1 \times 10^6, 1*10^6}):

@example
LET valid_task BE A RANDOM TASK LESS THAN 1E6 WHILE TASK valid_task
OUTPUTS "Hello from " AND valid_task
@end example


@node Conditional execution, Grouping, Binding variables, Complex statements
@subsection Conditional execution
@cindex conditionals

Like most programming languages, @ncptl{} supports conditional code
execution:

@multitable {@nonterm{if_stmt}} {::=} {[@keyw{OTHERWISE} @nonterm{simple_stmt}]}
@item @nonterm{if_stmt}
@tab ::=
@tab @keyw{IF} @nonterm{rel_expr}
@item @tab @tab @keyw{THEN} @nonterm{simple_stmt}
@item @tab @tab [@keyw{OTHERWISE} @nonterm{simple_stmt}]
@end multitable

The semantics of an @nonterm{if_stmt} are that if @nonterm{rel_expr}
(@pxref{Relational expressions}) is @sc{true} then the first
@nonterm{simple_stmt} is executed.  If @nonterm{rel_expr} is
@sc{false} then the second @nonterm{simple_stmt} is executed.  One
restriction is that @nonterm{rel_expr} must return the same truth
value to every task.  Consequently, functions that involve
task-specific random numbers (@pxref{Random-number functions}) are
forbidden within @nonterm{rel_expr}.

The following is an example of an @nonterm{if_stmt}:

@example
IF this>that THEN TASK 0 SENDS A 3 KILOBYTE MESSAGE TO TASK this
OTHERWISE TASK num_tasks-1 SENDS A 4 KILOBYTE MESSAGE TO TASK that
@end example


@node Grouping,  , Conditional execution, Complex statements
@subsection Grouping
@cindex grouping

@keyw{FOR} loops, @keyw{LET} bindings, and @keyw{IF} statements
operate on a single @nonterm{simple_stmt} (or two
@nonterm{simple_stmt}s in the case of
@keyw{IF}@dots{}@keyw{OTHERWISE}).  Operating on multiple
@nonterm{simple_stmt}s---or, more precisely, operating on a single
@nonterm{complex_stmt} that may consist of multiple
@nonterm{simple_stmt}s---is a simple matter of placing the
@nonterm{simple_stmt}s within curly braces.  Contrast the following:

@example
FOR 3 REPETITIONS TASK 0 OUTPUTS "She loves me." THEN TASK 0 OUTPUTS
"She loves me not."
@print{} She loves me.
@print{} She loves me.
@print{} She loves me.
@print{} She loves me not.

FOR 3 REPETITIONS @{TASK 0 OUTPUTS "She loves me." THEN TASK 0 OUTPUTS
"She loves me not."@}
@print{} She loves me.
@print{} She loves me not.
@print{} She loves me.
@print{} She loves me not.
@print{} She loves me.
@print{} She loves me not.
@end example

@noindent
In other words, everything between @samp{@{} and @samp{@}} is treated
as if it were a single statement.  Hence, the @keyw{FOR} loop applies
only to the ``She loves me'' output in the first statement above,
while the @keyw{FOR} loop applies to both ``She loves me'' and ``She
loves me not'' in the second statement.

Variable scoping is limited to the @nonterm{simple_stmt} in the body
of a @keyw{LET}:

@example
LET year BE 1984 WHILE LET year BE 2084 WHILE TASK 0 OUTPUTS year THEN
TASK 0 OUTPUTS year
@error{} @r{The second @samp{year} is outside the scope of both @samp{LET} statements.}

LET year BE 1984 WHILE @{@{LET year BE 2084 WHILE TASK 0 OUTPUTS year@}
THEN TASK 0 OUTPUTS year@}
@print{} 2084
@print{} 1984
@end example

As indicated by the grammatical rules presented at the beginning of
@ref{Complex statements}, @ncptl{} does support empty pairs of curly
braces, which represent a statement that does nothing and takes no
time to execute.  While never strictly needed, @samp{@{@}} may be a
convenient mechanism for mechanically produced @ncptl{} programs.


@node Other statements, Header declarations, Complex statements, Grammar
@section Other statements

@ncptl{} contains a few more statements than those described in
@ref{Communication statements} and @ref{I/O statements}.  As there is
no category that clearly describes the remaining statements, they are
listed here in this ``catch-all'' section.


@menu
* Asserting conditions::        Aborting if a program requirement is not met
* Delaying execution::          Introducing artificial delays into a program
* Touching memory::             Occupying the CPU or the memory hierarchy
* Reordering task IDs::         Changing the virtual->physical task map
* Injecting arbitrary code::    Executing backend-specific code verbatim
@end menu

@node Asserting conditions, Delaying execution, Other statements, Other statements
@subsection Asserting conditions

@ncptl{} programs can encode the run-time conditions that must hold in
order for the test to run properly.  This is achieved through
@dfn{assertions}, which are expressed as follows:

@multitable {@nonterm{assert_stmt}} {::=} {@keyw{ASSERT THAT} @nonterm{string}}
@item @nonterm{assert_stmt}
@tab ::=
@tab @keyw{ASSERT THAT} @nonterm{string}
@item @tab @tab @keyw{WITH} @nonterm{rel_expr}
@end multitable

@nonterm{string} is a message to be reported to the user if the
assertion fails.  @nonterm{rel_expr} is a relational expression (as
described in @ref{Relational expressions}) that must evaluate to
@sc{true} for the program to continue running.  Assertion failures are
considered fatal errors.  They cause the @ncptl{} program to abort
immediately.

Here are some sample @nonterm{assert_stmt}s:

@example
ASSERT THAT "the bandwidth test requires at least two tasks" WITH
num_tasks >= 2

ASSERT THAT "pairwise ping-pongs require an even number of task"
WITH num_tasks IS EVEN

ASSERT THAT "this program requires a square number of tasks" WITH
SQRT(num_tasks)**2 = num_tasks
@end example

@noindent
(For the last example, recall that @ncptl{} expressions are of integer
type.  Hence, the example's @nonterm{rel_expr} is mathematically
equivalent to
@iftex
@tex
$\lfloor\sqrt{N}\rfloor^2 = N$,
@end tex
@end iftex
@ifnottex
floor(sqrt(@math{N}))^2 = @math{N},
@end ifnottex
which is @sc{true} if and only if @math{N} is a square.)


@node Delaying execution, Touching memory, Asserting conditions, Other statements
@subsection Delaying execution
@cindex delaying execution
@cindex spinning
@cindex computation, simulating

It is sometimes interesting to measure the progress of a communication
pattern when delays are inserted at various times on various tasks.
@ncptl{} provides two mechanisms for inserting delays: one that
relinquishes the CPU while delaying (@keyw{SLEEP}) and one that hoards
it (@keyw{COMPUTE}).

@multitable {@nonterm{delay_stmt}} {::=} {@keyw{FOR} @nonterm{expr} @nonterm{time_unit}}
@item @nonterm{delay_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{SLEEPS} | @keyw{COMPUTES}
@item @tab @tab @keyw{FOR} @nonterm{expr} @nonterm{time_unit}
@end multitable

@nonterm{source_task} (@pxref{Source tasks}) specifies the set of
tasks that will stall.  @nonterm{expr} (@pxref{Arithmetic
expressions}) specifies the number of @nonterm{time_unit}s for which
to delay and @nonterm{time_unit} represents any of the following
measures of time:

@multitable {@nonterm{time_unit}} {::=} {@keyw{MICROSECONDS} | @keyw{MILLISECONDS} | @keyw{SECONDS} | @keyw{MINUTES} | @keyw{HOURS} | @keyw{DAYS}}
@item @nonterm{time_unit}
@tab ::=
@tab @keyw{MICROSECONDS} | @keyw{MILLISECONDS} | @keyw{SECONDS} |
     @keyw{MINUTES} | @keyw{HOURS} | @keyw{DAYS}
@end multitable

Delay times are only approximate.  @keyw{SLEEP}'s accuracy depends
upon the operating-system's clock resolution or length of time quantum
(commonly measured in milliseconds or tens of milliseconds).
@keyw{COMPUTE}, which is implemented by repeatedly reading a variable
until the desired amount of time elapses, is calibrated during the
@ncptl{} run-time system's initialization phase and can be adversely
affected by intermittant system load.  Both forms of
@nonterm{delay_stmt} attempt to measure wall-clock time (``real
time''), not just the time the program is running (``virtual time'').
Because the delay times are approximate, it is strongly recommended
that the @ocode{elapsed_usecs} variable (@pxref{Predeclared
variables}) be employed to determine the actual elapsed time.


@node Touching memory, Reordering task IDs, Delaying execution, Other statements
@subsection Touching memory
@cindex data touching
@cindex touching data

``Touching'' memory means reading and writing it.  The @ncptl{}
@keyw{TOUCHES} statement enables a program to touch memory for one of
two purposes: either to simulate computation in an application by
thrashing some or all of the memory hierarchy or to preload message
buffers into the upper levels of the memory hierarchy in order to
better separate communication costs from memory costs.

@menu
* Simulating computation::      Touching memory to mimic computation
* Priming message buffers::     Touching memory to warm up message buffers
@end menu


@node Simulating computation, Priming message buffers, Touching memory, Touching memory
@subsubheading Simulating computation
@cindex computation, simulating

While the statements described in @ref{Delaying execution} delay for a
specified length of time, it is also possible to delay for the
duration of a specified amount of ``work''.  ``Work'' is expressed in
terms of memory accesses.  That is, a @ncptl{} program can touch
(i.e., read plus write) data with a given stride from a memory region
of a given size.  By varying these parameters, a program can emulate
an application's computation by hoarding the CPU or any level of the
memory hierarchy.

@multitable {@nonterm{touch_stmt}} {::=} {[@keyw{WITH STRIDE} @nonterm{expr} @nonterm{data_type} | @keyw{WITH RANDOM STRIDE}]}
@item @nonterm{touch_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{TOUCHES}
@item @tab @tab [@nonterm{expr} @nonterm{data_type} @keyw{OF}]
@item @tab @tab @keyw{AN} @nonterm{item_size} @keyw{MEMORY REGION}
@item @tab @tab [@nonterm{expr} @keyw{TIMES}]
@item @tab @tab [@keyw{WITH STRIDE} @nonterm{expr} @nonterm{data_type} | @keyw{WITH RANDOM STRIDE}]
@end multitable

@noindent
@nonterm{item_size} and @nonterm{data_type} are described in @ref{Item
size} and @nonterm{expr} is described in @ref{Arithmetic expressions}.

As shown by the formal definition of @nonterm{touch_stmt} the required
components are a @nonterm{source_task} and the size of the memory
region to touch.  By default, every @keyw{WORD} (@pxref{Item size}) of
memory in the region is touched exactly once.  The type of data that
is touched can be varied with an @samp{@nonterm{expr}
@nonterm{data_type} OF} clause.  For instance, @samp{100 BYTES OF} of
a memory region will touch individual bytes.  An optional repeat count
enables the memory region (or subset thereof) to be touched multiple
times.  Hence, if @samp{TASK 0 TOUCHES A 6 MEGABYTE MEMORY REGION 5
TIMES}, then the touch will be performed as if @samp{TASK 0} were told
to @samp{TOUCH 5*6M BYTES OF A 6 MEGABYTE MEMORY REGION 1 TIME} or
simply to @samp{TOUCH 5*6M BYTES OF A 6 MEGABYTE MEMORY REGION}.

By default, every @nonterm{data_type} of data is touched.  However, a
@nonterm{touch_stmt} provides for touching only a subset of the
@nonterm{data_type}s in the memory region.  By writing @samp{WITH
STRIDE @nonterm{expr} @nonterm{data_type}}, only the first
@nonterm{data_type} out of every @nonterm{expr} will be touched.
Instead of specifying an exact stride, the memory region can be
accessed in random order using the @keyw{WITH RANDOM STRIDE} clause.

Unless the number of touches and data type are specified explicitly,
the number of @keyw{WORD}s that are touched is equal to the size of
the memory region divided by the stride length then multiplied by the
repeat count.  Therefore, if @samp{TASK 0 TOUCHES AN 8 MEGABYTE MEMORY
REGION 2 TIMES WITH STRIDE 8 WORDS}, then a total of
@texmath{(2^{23}/(4 \times 8)) \times 2 = 524288, (2^23 / (4*8)) * 2 =
524288} touches will be performed.  For the purpose of the preceding
calculation, @samp{WITH RANDOM STRIDE} should be treated as if it were
@samp{WITH STRIDE 1 WORD} (again, unless the number of touches and
data type are specified explicitly).

To save memory, all @keyw{TOUCH} statements in a @ncptl{} program
access subsets of the same region of memory, whose size is determined
by the maximum needed.  However, each dynamic execution of a
@nonterm{touch_stmt} starts touching from where the previous execution
left off.  For example, consider the following statement:

@example
TASK 0 TOUCHES 100 WORDS OF A 200 WORD MEMORY REGION
@end example

@noindent
The first time that that statement is executed within a loop
(@pxref{Iterating}), the first @w{200 words} are touched.  The second
time, the second @w{200 words} are touched.  The third time, the index
into the region wraps around and the first @w{200 words} are touched
again.

Each static @nonterm{touch_stmt} maintains its own index into the
memory region.  Therefore, the first of the following two statements
will terminate successfully (assuming it's not executed in the body of
a loop) while the second will result in a run-time error because the
final byte of the final word does not fit within the given memory
region.

@example
TASK 0 TOUCHES 100 WORDS OF A 799 BYTE MEMORY REGION THEN
TASK 0 TOUCHES 100 WORDS OF A 799 BYTE MEMORY REGION

FOR 2 REPETITIONS TASK 0 TOUCHES 100 WORDS OF A 799 BYTE MEMORY REGION
@end example

@noindent
(@keyw{THEN} is described in @ref{Combining statements}, and
@keyw{FOR}@dots{}@keyw{REPETITIONS} is described in @ref{Counted
loops}.)  The first statement shown above touches the same @w{100
words} @w{(400 bytes)} in each of the two @nonterm{touch_stmt}s.  The
second statement touches the first @w{100 words} the first time the
@nonterm{touch_stmt} is executed and fails when trying to touch the
(only partially extant) second @w{100 words.}


@node Priming message buffers,  , Simulating computation, Touching memory
@subsubheading Priming message buffers
@cindex message buffers
@cindex buffers, message

@ref{Data touching}, describes how a message sent or received
@keyw{WITH DATA TOUCHING} will have all of its data touched before or
after transmission.  Sometimes, however, a program may want to touch
message data without actually transmitting a message.  For example, a
task could touch message data to load it into the cache, then
@keyw{RESET ITS COUNTERS} (@pxref{Resetting counters}), and finally
send or receive a message without further data touching.  The
@keyw{TOUCHES} statement has an alternate form that touches message
buffers instead of isolated memory regions:

@multitable {@nonterm{touch_buffer_stmt}} {::=} {@ @ | @keyw{THE CURRENT MESSAGE BUFFER}}
@item @nonterm{touch_buffer_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{TOUCHES}
@item @tab @tab @ @ @ @ @keyw{ALL MESSAGE BUFFERS}
@item @tab @tab @ @ | @keyw{MESSAGE BUFFER} @nonterm{expr}
@item @tab @tab @ @ | @keyw{THE CURRENT MESSAGE BUFFER}
@end multitable

The first form, @samp{ALL MESSAGE BUFFERS}, touches all message
buffers available to the program, even those not yet used at the time
@keyw{TOUCHES} is invoked.  In the following statement, for example,
@keyw{TOUCHES} ``knows'' that 10 message buffers will be used and
touches the data in @w{all 10} of them:

@example
ALL TASKS TOUCH ALL MESSAGE BUFFERS THEN
FOR EACH SZ IN @{0, ..., 9@}
  TASK 0 ASYNCHRONOUSLY SENDS AN SZ MEGABYTE MESSAGE TO TASK 1 THEN
ALL TASKS AWAIT COMPLETION
@end example

@noindent
(@ref{Buffer control}, explains why the preceding statement requires
@w{10 buffers}.)  One caveat is that in @ncptl{} @w{version
@value{VERSION},} messages sent or received with the @keyw{UNIQUE}
keyword (@pxref{Unique messages}) are not touched.  This limitation
may be lifted in a later release of @ncptl{}@.

The second form of the @nonterm{touch_buffer_stmt} statement,
@samp{MESSAGE BUFFER @nonterm{expr}}, touches a specific message
buffer.  It is expected to be used in programs that send @samp{FROM
BUFFER @nonterm{expr}} or receive @samp{INTO BUFFER @nonterm{expr}}.

@samp{THE CURRENT MESSAGE BUFFER}, the third and final form of the
@nonterm{touch_buffer_stmt} statement, touches the first message
buffer that is not currently in use @w{(i.e., is} not the source or
destination of an asynchronous operation).  Usually, this is whichever
message buffer will next be sent from or received into.  (The
exception is when a task @keyw{AWAITS COMPLETION} after touching the
current message buffer but before sending or receiving a
message---probably a somewhat contrived situation.)


@node Reordering task IDs, Injecting arbitrary code, Touching memory, Other statements
@subsection Reordering task IDs
@cindex reordering task IDs
@cindex shuffling task IDs

@ncptl{} distinguishes between ``task IDs'', which are used in task
descriptions (@pxref{Task descriptions}) and ``processor IDs'', which
are assigned by the underlying communication layer.  As stated in
@ref{Running coNCePTuaL programs}, a @ncptl{} program has no control
over how processor IDs map to physical processors.  It therefore has
no way to specify, for instance, that a set of tasks must run on the
same multiprocessor node (or on different nodes, for that matter).
Initially, every task's task ID is set equal to its processor ID@.
However, while processor IDs are immutable, task IDs can be changed
dynamically during the execution of a program.  Altering task IDs can
simplify @ncptl{} programs that might otherwise need to evaluate
complex expressions to determine peer tasks.  @ncptl{} enables either
a specific or a randomly selected task to be assigned to a given
processor:

@multitable {@nonterm{processor_stmt}} {::=} {@keyw{PROCESSOR} @nonterm{expr} | @keyw{A RANDOM PROCESSOR}}
@item @nonterm{processor_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{IS ASSIGNED TO}
@item @tab @tab @keyw{PROCESSOR} @nonterm{expr} | @keyw{A RANDOM PROCESSOR}
@end multitable

In addition to performing the specified processor assignment, @ncptl{}
will perform an additional, implicit processor assignment in order to
maintain a bijection between task IDs and processor IDs (i.e., every
task ID corresponds to exactly one processor ID and every processor ID
corresponds to exactly one task ID).  Consider the following
statement:

@example
TASK n SUCH THAT n<(num_tasks+1)/2 IS ASSIGNED TO PROCESSOR n*2
@end example

@noindent
If @keyw{num_tasks} is @samp{8} the preceding statement will cause
@w{@samp{TASK 0}} to refer to @w{processor 0,} @w{@samp{TASK 1}} to
refer to processor @w{processor 2,} @w{@samp{TASK 2}} to refer to
@w{processor 4,} and @w{@samp{TASK 3}} to refer to @w{processor 6.}
What may be unintuitive is that the remaining tasks will not map to
their original processors, as doing so would violate the bijection
invariant.  To clarify @ncptl{}'s implicit processor assignments the
following timeline illustrates the execution of @samp{TASK n SUCH THAT
n<(num_tasks+1)/2 IS ASSIGNED TO PROCESSOR n*2} when @keyw{num_tasks}
is @samp{8}:

@multitable {@samp{n}} {@samp{TASK 0}} {@samp{TASK 1}} {@samp{TASK 2}} {@samp{TASK 3}} {@samp{TASK 4}} {@samp{TASK 5}} {@samp{TASK 6}} {@samp{TASK 7}}
@item @samp{n}
@tab @samp{TASK 0} @tab @samp{TASK 1} @tab @samp{TASK 2} @tab @samp{TASK 3}
@tab @samp{TASK 4} @tab @samp{TASK 5} @tab @samp{TASK 6} @tab @samp{TASK 7}

@item --- @tab 0 @tab 1 @tab 2 @tab 3 @tab 4 @tab 5 @tab 6 @tab 7
@item 0   @tab 0 @tab 1 @tab 2 @tab 3 @tab 4 @tab 5 @tab 6 @tab 7
@item 1   @tab 0 @tab @strong{2} @tab @strong{1} @tab 3 @tab 4 @tab 5 @tab 6 @tab 7
@item 2   @tab 0 @tab 2 @tab @strong{4} @tab 3 @tab @strong{1} @tab 5 @tab 6 @tab 7
@item 3   @tab 0 @tab 2 @tab 4 @tab @strong{6} @tab 1 @tab 5 @tab @strong{3} @tab 7
@end multitable

Initially, task and processor IDs are equal.  When @code{n} takes on
the value 0, @ncptl{} performs the equivalent of @samp{TASK 0 IS
ASSIGNED TO PROCESSOR 0}, which does not change the @w{task ID} to
@w{processor ID} mapping.  When @code{n} is 1, @ncptl{} performs the
equivalent of @samp{TASK 1 IS ASSIGNED TO PROCESSOR 2}, which sets
@w{task 1's} processor to 2.  However, because @w{task 2} also has
@w{processor 2,} @ncptl{} implicitly performs the equivalent of
@samp{TASK 2 IS ASSIGNED TO PROCESSOR 1} in order to preserve the
unique @w{task ID} to @w{processor ID} mapping.  When @code{n} is 2,
@ncptl{} performs the equivalent of @samp{TASK 2 IS ASSIGNED TO
PROCESSOR 4} and, because @w{task 4} also has @w{processor 4}, the
equivalent of @samp{TASK 4 IS ASSIGNED TO PROCESSOR 1}.  Finally, when
@code{n} is 3, @ncptl{} performs the equivalent of @samp{TASK 3 IS
ASSIGNED TO PROCESSOR 6} and, because @w{task 6} also has @w{processor
6}, the equivalent of @samp{TASK 6 IS ASSIGNED TO PROCESSOR 3}.  Thus,
@ncptl{} maintains the invariant that after any processor assignment
every task corresponds to a unique processor and every processor
corresponds to a unique task.


@node Injecting arbitrary code,  , Reordering task IDs, Other statements
@subsection Injecting arbitrary code
@cindex C code
@cindex injecting arbitrary code
@cindex code, injecting arbitrary

There are some features that are outside the scope of the @ncptl{}
language.  However, @ncptl{} provides a mechanism for inserting
backend-specific statements into the control flow of a @ncptl{}
program.  This feature is intended for users with specific needs that
can't be satisfied through the conventional @ncptl{} statements.

@multitable {@nonterm{backend_stmt}} {::=} {[@keyw{AND} @nonterm{expr} | @nonterm{string}]*}
@item @nonterm{backend_stmt}
@tab ::=
@tab @nonterm{source_task}
@item @tab @tab @keyw{BACKEND EXECUTES}
@item @tab @tab @nonterm{expr} | @nonterm{string}
@item @tab @tab [@keyw{AND} @nonterm{expr} | @nonterm{string}]*
@end multitable

The following example assumes a C-based backend:

@example
ALL TASKS taskID BACKEND EXECUTE "my_c_function(" AND taskID AND ");"
@end example

@noindent
The @code{my_c_function()} function needs be defined in some object
file and linked with the @ncptl{}-generated code.

Most users will never need to @keyw{BACKEND EXECUTE} code.  In fact,
most users should @emph{not} use @nonterm{backend_stmt}s as they
produce nonportable code.  One of @ncptl{}'s goals is for programs to
be understandable by people unfamiliar with the language, and
@nonterm{backend_stmt}s thwart that goal.  However,
@nonterm{backend_stmt}s do help ensure that all of the target
language/library's features are available to @ncptl{}@.

All @nonterm{expr}s are passed to the backend in floating-point
context (@pxref{Evaluation contexts}).  Consequently, all backend code
that takes a @ncptl{} @nonterm{expr} needs to expect a floating-point
value (which the backend code can of course cast explicitly to an
integer if necessary).

There is an important special case defined for the argument to the
@keyw{BACKEND EXECUTES} statement: once all of the @nonterm{string}
and @nonterm{expr} arguments are concatenated into a single string,
all occurrences of the substring @samp{[MESSAGE BUFFER @var{expr}]}
are replaced by a pointer to the @var{expr}th message buffer created
using the @keyw{FROM BUFFER} or @keyw{INTO BUFFER} keywords (presented
in @ref{Buffer control}).  This special case makes it easy for a
@ncptl{} program to invoke communication functions provided by the
underlying communications library.  Note that the notion of a default
buffer is not meaningful in the context of @keyw{BACKEND EXECUTES},
which is not a communication statement.

@xref{Backend-specific declarations}, for a description of
@keyw{BACKEND DECLARES}, a companion statement to @keyw{BACKEND
EXECUTES} that enables @ncptl{} programs to directly declare variables
and functions in the target language.


@node Header declarations, Complete programs, Other statements, Grammar
@section Header declarations

@ncptl{} programs may contain a header section that precedes the first
statement in a @ncptl{} program.  The header section contains three
types of declarations that affect the remainder of the program:
language versioning declarations, declarations of command-line
options, and backend-specific variable and function declarations.

@menu
* Language versioning::         Preventing errors caused by language changes
* Command-line arguments::      Setting variables from command-line arguments
* Backend-specific declarations::  Declaring variables and functions verbatim
@end menu


@node Language versioning, Command-line arguments, Header declarations, Header declarations
@subsection Language versioning
@cindex versioning

Because the @ncptl{} language is still under development, the
programmer is forewarned that major changes are likely.  Changes may
prevent old code from compiling or, even worse, may cause old code to
produce incorrect results (e.g., if scoping or block structuring are
altered).  To mitigate future language changes @ncptl{} enables
programs to specify which version of the language they were written
to.  The syntax is straightforward:

@multitable {@nonterm{version_decl}} {::=} {@keyw{REQUIRE LANGUAGE VERSION} @nonterm{string}}
@item @nonterm{version_decl}
@tab ::=
@tab @keyw{REQUIRE LANGUAGE VERSION} @nonterm{string}
@end multitable

The parser issues a warning message if @nonterm{string} does not
exactly match the language version supported by the compiler.  If the
program successfully compiles after a version-mismatch warning, the
programmer should check the output very carefully to ensure that the
program behaved as expected.

The current version of the @ncptl{} language is @samp{@value{LANGUAGE-VERSION}}.  Note
that the language version does not necessarily correspond to the
version of the @ncptl{} toolset (@pxref{Usage}) as a whole.


@node Command-line arguments, Backend-specific declarations, Language versioning, Header declarations
@subsection Command-line arguments
@cindex command-line arguments

@ncptl{} makes it easy to declare command-line parameters, although
the syntax is a bit verbose:

@multitable {@nonterm{param_decl}} {::=} {@keyw{AND COMES FROM} @nonterm{string} @keyw{OR} @nonterm{string}}
@item @nonterm{param_decl}
@tab ::=
@tab @nonterm{ident}
@item @tab @tab @keyw{IS} @nonterm{string}
@item @tab @tab @keyw{AND COMES FROM} @nonterm{string} @keyw{OR} @nonterm{string}
@item @tab @tab @keyw{WITH DEFAULT} @nonterm{expr}
@end multitable

@nonterm{ident} is the @ncptl{} variable being declared.  The first
@nonterm{string} is a descriptive string that is provided when the
user runs the program with @copt{help} or @copts{?}.  The
@samp{@nonterm{string} OR @nonterm{string}} terms list the long name
for the command-line option, preceded by @samp{--}, and the short
(single-character) name, preceded by @samp{-}.  Finally,
@nonterm{expr} specifies the value that will be assigned to
@nonterm{ident} if the command-line option is not used.
@nonterm{expr} must be a constant expression and may not utilize any
of the random-number functions listed in @ref{Random-number
functions}.  Note that short names (also long names) must be unique.

For instance, the declaration @samp{nummsgs IS "Number of messages to
send" AND COMES FROM "--messages" OR "-m" WITH DEFAULT 25*4} declares
a new @ncptl{} variable called @samp{nummsgs}.  @samp{nummsgs} is
given the value @samp{100} (@samp{25*4}) by default.  However, if the
user running the program specifies, for example,
@kbd{@copt{messages}=55} (or, equivalently, @kbd{@copts{m} 55}), then
@samp{nummsgs} will be given the value @samp{55}.  The following is an
example of the output that might be produced if the program is run
with @copt{help} or @copts{?}:

@cartouche
@example
Usage: a.out [OPTION...]
  -m, --messages=<number>     Number of messages to send [default: 100]
  -C, --comment=<string>      Additional commentary to write to the log
                              file, @@FILE to import commentary from FILE,
                              or !COMMAND to import commentary from COMMAND
                              (may be specified repeatedly)
  -L, --logfile=<string>      Log-file template [default: "a.out-%p.log"]
  -N, --no-trap=<string>      List of signals that should not be trapped
                              [default: ""]

Help options:
  -?, --help                  Show this help message
  --usage                     Display brief usage message
@end example
@end cartouche

The above is only an example.  Depending on what libraries were
available when the @ncptl{} run-time system was configured, the output
could be somewhat different.  Also, long options may not be supported
if a suitable argument-processing library was not available at
configuration time.  The above example does indicate one way that help
strings could be formatted.  It also shows that the @ncptl{} run-time
system reserves some command-line options for its own purposes.
Currently, these all use uppercase letters for their short forms so it
should be safe for programs to use any lowercase letter.


@node Backend-specific declarations,  , Command-line arguments, Header declarations
@subsection Backend-specific declarations
@cindex C code
@cindex injecting arbitrary code
@cindex code, injecting arbitrary

The @keyw{BACKEND EXECUTES} statement (@pxref{Injecting arbitrary
code}) provides support for executing non-@ncptl{} code from a
@ncptl{} program.  A related construct, @keyw{BACKEND DECLARES},
provides support for embedding non-@ncptl{} variable and function
declarations in a @ncptl{} program:

@multitable {@nonterm{backend_decl}} {::=} {@keyw{THE BACKEND DECLARES} @nonterm{string}}
@item @nonterm{backend_decl}
@tab ::=
@tab @keyw{THE BACKEND DECLARES} @nonterm{string}
@end multitable

Like @keyw{BACKEND EXECUTES}, @keyw{BACKEND DECLARES} produces
nonportable code.  Its use is therefore strongly discouraged.
However, @keyw{BACKEND DECLARES} and @keyw{BACKEND EXECUTES} together
help ensure that all of the target language/library's features are
available to @ncptl{}.

The following example uses @keyw{BACKEND DECLARES} to declare a C
global variable and two C functions that access that variable:

@cartouche
@example
THE BACKEND DECLARES "
int tally = 0;

void increment_tally (void)
@{
  tally++;
@}

void show_tally (char *msg)
@{
  printf(\"%s%d.\\n\", msg, tally);
@}
".

FOR 3 REPETITIONS PLUS 2 WARMUP REPETITIONS @{
  ALL TASKS src SEND A 512-BYTE MESSAGE TO TASK src+1 THEN
  ALL TASKS BACKEND EXECUTE "increment_tally();"
@} THEN
TASK 0 BACKEND EXECUTES "show_tally(\"Tally is\\n==> \");".
@end example
@end cartouche

@noindent
The preceding code works only when using a C-based backend such as
@backend{c_mpi} or @backend{c_udgram}.  Eliciting the same behavior
from a Python-based backend such as @backend{interpret} or
@backend{latex_vis} requires a complete rewrite of the @ncptl{} code:

@cartouche
@example
THE BACKEND DECLARES "
global tally
tally = 0

def increment_tally():
    global tally
    tally = tally + 1

def show_tally(msg):
    global tally
    print \"%s%d.\\n\" % (msg, tally)
"

FOR 3 REPETITIONS PLUS 2 WARMUP REPETITIONS @{
  ALL TASKS src SEND A 512-BYTE MESSAGE TO TASK src+1 THEN
  ALL TASKS BACKEND EXECUTE "increment_tally()"
@} THEN
TASK 0 BACKEND EXECUTES "show_tally(\"Tally is\\n==> \")".
@end example
@end cartouche

@noindent
It is because of this need to rewrite programs for each set of
backends that @keyw{BACKEND DECLARES} and @keyw{BACKEND EXECUTES}
should be used only when absolutely necessary.


@node Complete programs, Summary of the grammar, Header declarations, Grammar
@section Complete programs

A complete @ncptl{} program consists of zero or more header
declarations (@pxref{Header declarations}), each terminated with a
@samp{.}, followed by one or more complex statements (@pxref{Complex
statements}), each also terminated with a @samp{.}.  More formally,
@ncptl{}'s top-level nonterminal is the @nonterm{program}:

@multitable {@nonterm{program}} {::=} {(@nonterm{version_decl} | @nonterm{param_decl} | @nonterm{backend_decl} [@samp{.}])*}
@item @nonterm{program}
@tab ::=
@tab (@nonterm{version_decl} | @nonterm{param_decl} | @nonterm{backend_decl} [@samp{.}])*
@item @tab @tab (@nonterm{top_level_complex_stmt} [@samp{.}])+
@end multitable

@multitable {@nonterm{top_level_complex_stmt}} {::=} {@nonterm{complex_stmt}}
@item @nonterm{top_level_complex_stmt}
@tab ::=
@tab @nonterm{complex_stmt}
@end multitable

Because a @nonterm{complex_stmt} can reduce to a
@nonterm{simple_stmt}, the most basic, complete @ncptl{} program would
be a @nonterm{simple_stmt} with a terminating period:

@example
ALL TASKS self OUTPUT "Hello from task " AND self AND "!".
@end example

@noindent
A fuller example might contain multiple header declarations and
multiple @nonterm{complex_stmt}s:

@example
# A complete coNCePTuaL program
# By Scott Pakin <pakin@@lanl.gov>

REQUIRE LANGUAGE VERSION "@value{LANGUAGE-VERSION}".

maxval IS "Maximum value to loop to" AND COMES FROM "--maxval" OR
  "-v" WITH DEFAULT 100.

step IS "Increment after each iteration" AND COMES FROM "--step" OR
  "-s" WITH DEFAULT 1.

TASK 0 OUTPUTS "Looping from 0 to " AND maxval AND " by " AND step
  AND "...".

FOR EACH loopvar IN @{0, step, ..., maxval@}
  TASK 0 OUTPUTS "    " AND loopvar.

TASK 0 OUTPUTS "Wasn't that fun?".
@end example

Technically, the @samp{.} is optional; the language is unambiguous
without it.  However, for aesthetic purposes it is recommended that
you terminate sentences with a period, just like in a natural
language.  An exception would be when a @nonterm{complex_stmt} ends
with a curly brace.  The @samp{@}.} syntax is unappealing so a simple
@samp{@}} should be used instead.  @xref{Examples}, for further
examples.


@menu
* Top-level statements and log files::  One statement = one table in the log
@end menu


@node Top-level statements and log files,  , Complete programs, Complete programs
@subheading Top-level statements and log files

The reason that @ncptl{} distinguishes between
@nonterm{top_level_complex_stmt}s and @nonterm{complex_stmt}s is that
@nonterm{top_level_complex_stmt}s begin a new table in the log file
(@pxref{Writing to a log file}) while @nonterm{complex_stmt}s add
columns to the current table.  Consider the following piece of code:

@example
TASK 0 LOGS 111 AS "First" AND
            222 AS "Second".
@end example

Because @samp{First} and @samp{Second} are logged within the same
@nonterm{simple_stmt} they appear in the log file within the same
table but as separate columns:

@cartouche
@example
"First","Second"
"(all data)","(all data)"
111,222
@end example
@end cartouche

The same rule holds when @keyw{LOGS} is used repeatedly across
@nonterm{simple_stmt}s but within the same @nonterm{complex_stmt}:

@example
TASK 0 LOGS 111 AS "First" THEN
TASK 0 LOGS 222 AS "Second".
@end example

However, if @samp{First} and @samp{Second} are logged from separate
@nonterm{top_level_complex_stmt}s, the @ncptl{} run-time library
stores them in separate tables:

@example
TASK 0 LOGS 111 AS "First".
TASK 0 LOGS 222 AS "Second".
@end example

@cartouche
@example
"First"
"(all data)"
111

"Second"
"(all data)"
222
@end example
@end cartouche


@node Summary of the grammar,  , Complete programs, Grammar
@section Summary of the grammar
@cindex grammar, summary

The following is the complete grammar for the @ncptl{} language.  The
EBNF productions appear here in the order that they were presented in
the rest of the chapter.

@include grammar-summary.texi

@sp 1

The primitives @nonterm{ident}, @nonterm{string}, and
@nonterm{integer} are described in @ref{Primitives}.


@node Examples, Implementation, Grammar, Top
@chapter Examples
@cindex sample programs
@cindex example programs
@cindex code examples

This chapter presents a variety of examples of complete @ncptl{}
programs.  The purpose is to put in context the grammatical elements
described in @ref{Grammar} and also to illustrate @ncptl{}'s power and
expressiveness.

@menu
* Latency::                     Measure half the round-trip message latency
* Hot potato::                  Send a message around a ring
* Hot spot::                    Bombard task 0 with messages
* Multicast trees::             Multicast over various k-nomial trees
* Calling MPI functions::       Invoking MPI_Allgather() from coNCePTuaL
@end menu


@node Latency, Hot potato, Examples, Examples
@section Latency
@cindex latency benchmark

One of the most common network performance benchmarks is a ping-pong
latency test.  Not surprisingly, such a test is straightforward to
implement in @ncptl{}:

@cartouche
@example
# A ping-pong latency test written in coNCePTuaL

Require language version "@value{LANGUAGE-VERSION}".

# Parse the command line.
reps is "Number of repetitions of each message size" and comes from
 "--reps" or "-r" with default 1000.
maxbytes is "Maximum number of bytes to transmit" and comes from
 "--maxbytes" or "-m" with default 1M.

# Ensure the we have a peer with whom to communicate.
Assert that "the latency test requires at least two tasks" with
  num_tasks>=2.

# Perform the benchmark.
For each msgsize in @{0@}, @{1, 2, 4, ..., maxbytes@} @{
  for reps repetitions @{
    task 0 resets its counters then
    task 0 sends a msgsize byte message to task 1 then
    task 1 sends a msgsize byte message to task 0 then
    task 0 logs the msgsize as "Bytes" and
                the median of elapsed_usecs/2 as "1/2 RTT (usecs)"
  @} then
  task 0 computes aggregates
@}
@end example
@end cartouche

Note that the outer @keyw{FOR} loop specifies two @nonterm{range}s
(@pxref{Range expressions}).  This is because @samp{@{0, 1, 2, @w{4,
...,} maxbytes@}} is not a geometric progression.  Hence, that
incorrect @nonterm{range} is split into the singleton @samp{@{0@}} and
the geometric progression @samp{@{1, 2, @w{4, ...,} maxbytes@}}.


@node Hot potato, Hot spot, Latency, Examples
@section Hot potato
@cindex hot-potato benchmark

One way to measure performance variance on a parallel system is with a
``hot potato'' test.  The idea is that the tasks send a message in a
ring pattern, then the first task logs the minimum, mean, and variance
of the per-hop latency.  Ideally, the minimum should equal the mean
and these should both maintain a constant value as the number of tasks
increases.  Also, the variance should be small and constant.  The
following @ncptl{} code implements a hot-potato test.

@cartouche
@example
# Virtual ring "hot potato" test

Require language version "@value{LANGUAGE-VERSION}".

trials is "Number of trials to perform" and comes from "--trials" or
  "-t" with default 100000.

Assert that "the hot-potato test requires at least two tasks" with
  num_tasks>=2.

Let len be 0 while @{
  for each task_count in @{2, ..., num_tasks@} @{
    task 0 outputs "Performing " and trials and " " and
                   task_count and "-task runs...." then
    for trials repetitions plus 5 warmup repetitions @{
      task 0 resets its counters then
      task 0 sends a len byte message to unsuspecting task 1 then
      task (n+1) mod task_count receives a len byte message from task
        n such that n<task_count then
      task n such that n>0 /\ n<task_count sends a len byte message
        to unsuspecting task (n+1) mod task_count then
      task 0 logs the task_count as "# of tasks" and
                  the minimum of elapsed_usecs/task_count as
                    "Latency (usecs)" and
                  the mean of elapsed_usecs/task_count as
                    "Latency (usecs)" and
                  the variance of elapsed_usecs/task_count as
                    "Latency (usecs)"
    @} then
    task 0 computes aggregates
  @}
@}
@end example
@end cartouche

All tasks receive from their left neighbor and send to their right
neighbor.  However, in order to avoid a deadlock situation, task 0
sends then receives while all of the other tasks receive then send.


@node Hot spot, Multicast trees, Hot potato, Examples
@section Hot spot
@cindex hot-spot benchmark

Different systems react differently to resource contention.  A
hot-spot test attempts to measure the performance degradation that
occurs when a task is flooded with data.  That is, all tasks @w{except
0} concurrently send a batch of messages to @w{task 0}.  @w{Task 0}
reports the incoming bandwidth, i.e., the number of bytes it received
divided by the time it took to receive that many bytes.  The two
independent variables are the message size and the number of tasks.

@cartouche
@example
# Hot-spot bandwidth

Require language version "@value{LANGUAGE-VERSION}".

maxbytes is "Maximum message size in bytes" and comes from
  "--maxbytes" or "-x" with default 1024.
numtrials is "Number of bursts of each size" and comes from "--trials"
  or "-t" with default 100.
burst is "Number of messages in each burst" and comes from
  "--burstsize" or "-b" with default 1000.

Assert that "the hot-spot test requires at least two tasks" with
  num_tasks>=2.

For each maxtask in @{2, ..., num_tasks@}
  for each msgsize in @{1, 2, 4, ..., maxbytes@} @{
    task 0 outputs "Performing " and numtrials and " " and
                   maxtask and "-task trials with " and
                   msgsize and "-byte messages" then
    for numtrials repetitions plus 3 warmup repetitions @{
      task 0 resets its counters then
      task sender such that sender>0 /\ sender<maxtask asynchronously
        sends burst msgsize byte messages to task 0 then
      all tasks await completion then
      task 0 logs the maxtask as "Tasks" and
                  the msgsize as "Message size (B)" and
                  the mean of (1E6*bytes_received)/(1M*elapsed_usecs)
                    as "Incoming BW (MB/s)"
    @} then
    task 0 computes aggregates
  @}
@end example
@end cartouche


@node Multicast trees, Calling MPI functions, Hot spot, Examples
@section Multicast trees
@cindex trees
@cindex multicast-tree benchmark

It may be worth comparing the performance of a native multicast
operation to the performance achieved by multicasting over a
@var{k}-nomial tree to gauge how well the underlying communication
layer implements multicasts.  The following code records a wealth of
data, varying the tree arity @w{(i.e., @var{k})}, the number of tasks
receiving the multicast, and the message size.  It provides a good
demonstration of how to use the @keyw{KNOMIAL_CHILDREN} and
@keyw{KNOMIAL_CHILD} functions.

@cartouche
@example
# Test the performance of multicasting over various k-nomial trees
# By Scott Pakin <pakin@@lanl.gov>

Require language version "@value{LANGUAGE-VERSION}".

# Parse the command line.
minsize is "Min. message size (bytes)" and comes from "--minbytes" or "-n"
  with default 1.
maxsize is "Max. message size (bytes)" and comes from "--maxbytes" or "-x"
  with default 1M.
reps is "Repetitions to perform" and comes from "--reps" or "-r" with
  default 100.
maxarity is "Max. arity of the tree" and comes from "--maxarity" or "-a"
  with default 2.

Assert that "this program requires at least two processors" with
  num_tasks>=2.

# Send messages from task 0 to 1, 2, 3, ... other tasks in a k-nomial tree.
For each arity in @{2, ..., maxarity@} @{
  for each num_targets in @{1, ..., num_tasks-1@} @{
    for each msgsize in @{minsize, minsize*2, minsize*4, ..., maxsize@} @{
      task 0 outputs "Multicasting a " and msgsize and "-byte message to "
        and num_targets and " target(s) over a " and arity and
        "-nomial tree ..." then
      for reps repetitions @{
        task 0 resets its counters then
        for each src in @{0, ..., num_tasks@}
          for each dstnum in @{0, ..., knomial_children(src, arity,
              num_targets+1)@}
            task src sends a msgsize byte message to task
              knomial_child(src, dstnum, arity) then
        all tasks synchronize then
        task 0 logs the arity as "k-nomial arity" and
                    the num_targets as "# of recipients" and
                    the msgsize as "Message size (bytes)" and
                    the median of (1E6/1M)*(msgsize/elapsed_usecs) as
                      "Incoming bandwidth (MB/s)" and
                    the median of (num_targets*msgsize/elapsed_usecs)*
                      (1E6/1M) as "Outgoing bandwidth (MB/s)"
      @} then
      task 0 computes aggregates
    @}
  @}
@}
@end example
@end cartouche


@node Calling MPI functions,  , Multicast trees, Examples
@section Calling MPI functions

The @ncptl{} language is designed to be highly portable.  Any @ncptl{}
program can be compiled using any of the backends listed in
@ref{Supplied backends}.  A consequence of this portability is that
@ncptl{} does not include primitives that are specific to any
particular target language or communication library.

The @keyw{BACKEND EXECUTES} and @keyw{BACKEND DECLARES} statements
(@pxref{Injecting arbitrary code}, and @ref{Backend-specific
declarations}) give a programmer the ability to sacrifice portability
for the ability to measure the performance of features provided by a
specific target language or communication library.  Hence, it is
possible to write the core parts of a benchmark in a lower-level
language while letting @ncptl{} handle the setup, measurement,
logging, and other mundane operations.

The following program uses @keyw{BACKEND EXECUTES} to measure the
performance of the @ocodecf{MPI_Allgather} function provided by an
@MPI{} library.  Because it utilizes C code to call an @MPI{}
function, the code builds only with the @backend{c_mpi} backend.

@cartouche
@example
# Measure the performance of MPI_Allgather()
# By Scott Pakin <pakin@@lanl.gov>
#
# N.B. Requires the c_mpi backend.

Require language version "@value{LANGUAGE-VERSION}".

# Parse the command line.
numwords is "Message size (words)" and comes from "--msgsize" or "-s" with
default 1.

# Allocate a send buffer and a receive buffer.
Task 0 multicasts a numwords-word message from buffer 0 to all other tasks.
Task 0 multicasts a numwords*num_tasks word message from buffer 1 to all
other tasks.

# Measure the performance of MPI_Allgather().
Task 0 resets its counters then
for 100 repetitions plus 3 warmup repetitions
  all tasks backend execute "
    MPI_Allgather([MESSAGE BUFFER 0], (int)" and numwords and ", MPI_INT,
                  [MESSAGE BUFFER 1], (int)" and numwords and ", MPI_INT,
                  MPI_COMM_WORLD);
  " then
task 0 logs elapsed_usecs/100 as "Gather time (us)".
@end example
@end cartouche

The preceding code demonstrates a few useful techniques:

@itemize @bullet
@item
A pair of @keyw{MULTICASTS} statements (@pxref{Multicasting}) are used
to allocate the two message buffers.

@item
The @keyw{BACKEND EXECUTE} statement uses a value provided on the
command line (@code{numwords}, via @w{@kbd{-@w{}-msgsize}}) in the
call to @ocodecf{MPI_Allgather}.

@item
Pointers to the two message buffers are passed to
@ocodecf{MPI_Allgather} using the @samp{[MESSAGE BUFFER @var{expr}]}
substitution described in @ref{Injecting arbitrary code}.
@end itemize


@node Implementation, Tips and Tricks, Examples, Top
@chapter Implementation
@cindex implementation

@ncptl{} could have been implemented as a benchmarking library instead
of as a special-purpose language.  In addition to improved readability
and the practicality of including entire source programs in every log
file, one advantage of the language approach is that the same @ncptl{}
source code can be used to compare the performance of multiple
communication libraries.  A compiler command-line option selects a
particular backend module to use to generate code.  Each backend
outputs code for a different combination of low-level language and
communication library.

The @ncptl{} compiler is structured into a pipeline of modules.  Thus,
the backend can be replaced without altering the front end, lexer, or
parser modules.  @ncptl{} ensures consistency across backends by
providing a run-time library that generated code can link to.  The
run-time library encapsulates many of the mundane tasks a network
correctness or performance test needs to perform.

@menu
* Overview::                    Summary of coNCePTuaL's construction
* Backend creation::            How to write a new compiler backend
* Run-time library functions::  Description of functions used by backends
@end menu


@node Overview, Backend creation, Implementation, Implementation
@section Overview

@menu
* Compiler::                    Components of the coNCePTuaL compiler
* Run-time library::            The library commonly linked to generated programs
* Build process::               How coNCePTuaL itself is configured and built
@end menu

@node Compiler, Run-time library, Overview, Overview
@subheading Compiler
@cindex compiling

The @ncptl{} compiler is written in @cncp{Python} and is based on the
@PLY{} (Python Lex--Yacc) compiler framework.  Compiler execution
follows a basic pipeline structure.  Compilation starts with the
top-level file (@filespec{ncptl.py}), which processes the command line
then transfers control to the lexer (@filespec{ncptl_lexer.py}).  The
lexer inputs @ncptl{} source code and outputs a stream of tokens
(@filespec{ncptl_token.py}).  Next, the parser
(@filespec{ncptl_parser.py}) finds structure in those tokens based on
@ncptl{}'s grammatical rules and outputs an abstract syntax tree
(@filespec{ncptl_ast.py}).  Finally, the code generator
(@filespec{codegen_@var{language}_@var{library}.py}) that was
designated on the command line walks the abstract syntax tree,
converting it to code in the target language and for the target
communication library.

@node Run-time library, Build process, Compiler, Overview
@subheading Run-time library
@cindex run-time library
@cindex library, run-time

@ncptl{} makes a large run-time library (@filespec{runtimelib.c})
available to generated programs.  The @ncptl{} run-time library, which
is written in C, provides consistent functionality across target
languages and communication layers as well as across hardware
architectures and operating systems.  The library also simplifies code
generation by implementing functions for such tasks as memory
allocation, queue management, and data logging.  The functions in this
library are described in @ref{Run-time library functions}.


@node Build process,  , Run-time library, Overview
@subheading Build process
@cindex building

@ncptl{} is built using the @GNU{} Autotools (@cncp{Autoconf},
@cncp{Automake}, and @cncp{Libtool}).  Consequently, changes should be
made to original files, not generated files.  Specifically,
@filespec{configure.ac} and @filespec{acinclude.m4} should be edited
in place of @filespec{configure}; @filespec{ncptl.h.in} should be
edited in place of @filespec{ncptl.h}; and, the various
@filespec{Makefile.am} files should be edited in place of the
corresponding @filespec{Makefile}s.
@ifinfo
For information about how these various tools operate, @inforef{Top, ,
autoconf}, @inforef{Top, , automake}, and @inforef{Top, , libtool}.
@end ifinfo
@iftex
See the @cite{Autoconf} documentation, the @cite{Automake}
documentation, and the @cite{Libtool} documentation for information
about how these various tools operate.
@end iftex

If @filespec{configure} is given the @copt{enable-maintainer-mode}
option, @kcmd{make} will automatically re-run @kcmd{aclocal},
@kcmd{autoheader}, @kcmd{automake}, @kcmd{autoconf}, and/or
@configure{} as needed.  Developers who plan to modify any of the
``maintainer'' files (@filespec{acinclude.m4},
@filespec{configure.ac}, and the various @filespec{Makefile.am} files)
are strongly encouraged to configure @ncptl{} with
@copt{enable-maintainer-mode} in order to ensure that the build
process is kept current with any changes.


@node Backend creation, Run-time library functions, Overview, Implementation
@section Backend creation
@cindex backend creation

The @ncptl{} compiler's backend generates code from an abstract syntax
tree @w{(@AST{}).}  The compiler was designed to support a variety of
code generators, each targeting a particular programming language and
communication library.  There are two ways to create a new @ncptl{}
backend.  Either a @filespec{codegen_@var{language}_@var{library}.py}
backend supporting an arbitrary language and communication library can
be written from scratch or a C-based @file{codegen_c_@var{library}.py}
backend can be derived from @backendpy{c_generic}.

In the former case, the backend must define an @ocode{NCPTL_CodeGen}
class.  @ocode{NCPTL_CodeGen} class must contain a @ocode{generate}
method with the following signature:

@cartouche
@example
def generate(self, ast, filesource='<stdin>', filetarget='-',
             sourcecode=None):
@end example
@end cartouche

@noindent
That is, @ocode{generate} takes as arguments a class object, the root
of an abstract-syntax tree (as defined in @filespec{ncptl_ast.py}),
the name of the input file containing @ncptl{} code (to be used for
outputting error messages), the name of the output file to produce,
and the complete @ncptl{} source code (which is both stored in
prologue comments and passed to the run-time library).
@ocode{generate} should invoke @code{self.postorder_traversal} to
traverse the @AST{} in a post-order fashion, calling various
code-generating methods as it proceeds.  The @ocode{NCPTL_CodeGen}
must implement all of the methods listed in @ref{Method calls}, each
of which corresponds to some component of the @ncptl{} grammar.  Each
method takes a ``self'' class object an a node of the @AST{} (of type
@ocode{AST}).

The compiler front-end, @filespec{ncptl}, invokes the following two
methods, which must be defined by the backend's @ocode{NCPTL_CodeGen}
class:

@cartouche
@example
@olindex compile_only
def compile_only(self, progfilename, codelines, outfilename,
                 verbose, keepints):
@end example
@end cartouche

@cartouche
@example
@olindex compile_and_link
def compile_and_link(self, progfilename, codelines, outfilename,
                     verbose, keepints):
@end example
@end cartouche

@noindent
The @ocode{compile_only} method compiles the backend-specific code
into an object file.  The @ocode{compile_and_link} method compiles the
backend-specific code into an object file and links it into an
executable file.  For some backends, the notions of ``compile'' and
``link'' may not be appropriate.  In that situation, the backend
should perform the closest meaningful operations.  For example, the
@backend{dot_ast} backend (@pxref{The dot_ast backend}) compiles to a
@file{.dot} file and links into the target graphics format (@file{.ps}
by default).

For both the @ocode{compile_only} and @ocode{compile_and_link}
methods, @code{progfilename} is the name of the @ncptl{} input file
specified on the @filespec{ncptl} command line or the string
@samp{<command line>} if a program was specified literally with
@copt{program}.  @code{codelines} is the output from the
@ocode{generate} method, @w{i.e., a} list of lines of backend-specific
code.  @code{outfilename} is the name of the target file specified on
the @filespec{ncptl} command line with @copt{output} or the string
@samp{-} if @copt{output} was not used.  If @code{verbose} is
@samp{1}, the method should write each operation it plans to perform
to the standard-error device.  For consistency, comment lines should
begin with @samp{#}; shell commands should be output verbatim.  If
@code{verbose} is @samp{0}, corresponding to the @filespec{ncptl}
@copt{quiet} option, the method should output nothing but error
messages.  Finally, @code{keepints} corresponds to the
@copt{keep-ints} option to @filespec{ncptl}.  If equal to @samp{0},
all intermediate files should be deleted before returning; if equal to
@samp{1}, intermediate files should be preserved.  @xref{Compiling
coNCePTuaL programs}, for a description of the various command-line
options to @filespec{ncptl}.

As long as @ocode{NCPTL_CodeGen} implements all of the required
functions it is free to generate code in any way that it sees fit.
However, @ref{Method calls}, lists a large number of methods, many of
which will be identical across multiple code generators for the same
language but different communication libraries.  To simplify a common
case, C plus some messaging library, @ncptl{} provides
@backendpy{c_generic}, to which the remainder of the
Implementation chapter is devoted to explaining.

@menu
* Hook methods::                Injecting code at strategic locations
* A minimal C-based backend::   How to write a trivial, sequential-only backend
* Generated code::              The generated C code's basic structure
* Internals::                   Key parts of codegen_c_generic.py
@end menu


@node Hook methods, A minimal C-based backend, Backend creation, Backend creation
@subsection Hook methods
@cindex hooks

Multiple code generators for the same language but different
communication libraries are apt to contain much code in common.
Because C is a popular language, @ncptl{} provides a
@backendpy{c_generic} module that implements a virtual
@ocode{NCPTL_CodeGen} base class.  This base class implements all of
the methods listed in @ref{Method calls}.  However, rather than
support a particular communication library, the
@backendpy{c_generic} implementation of
@ocode{NCPTL_CodeGen} merely provides a number of calls to ``hook''
methods---placeholders that implement library-specific functionality.
@xref{C hooks}, for a list of all of the hooks that
@backendpy{c_generic} defines.  For clarity, hooks are named
after the method from which they're called but with an all-uppercase
tag appended.  Hook methods take a single parameter, a read-only
dictionary (the result of invoking @cncp{Python}'s @ocode{locals()} function)
of all of the local variables in the caller's scope.  They return C
code in the form of a list with one line of C per element.  A hook
method is invoked only if it exists, which gives the backend developer
some flexibility in selecting places at which to insert code.  Of
course, for coarser-grained control, a backend developer can override
complete methods in @backendpy{c_generic} if desired.
Generally, this will not be necessary as hook invocations are
scattered liberally throughout the file.

@subsubheading An example

@backendpy{c_generic} defines a method named
@ocode{code_specify_include_files}.  (@backendpy{c_generic}
names all of its code-generating helper methods
@samp{code_@var{something}}.)  @ocode{code_specify_include_files}
pushes a sequence of @ocode{#include} directives onto a queue of lines
of C code.  The method is shown below in its entirety:

@cartouche
@example
def code_specify_include_files(self, node):
    "Load all of the C header files the generated code may need."

    # Output a section comment.
    self.pushmany([
        "/*****************",
        " * Include files *",
        " *****************/",
        ""])

    # Enable hooks both before and after the common includes.
    self.pushmany(self.invoke_hook("code_specify_include_files_PRE",
                                   locals(),
                                   before=[
        "/* Header files specific to the %s backend */" %
        self.backend_name],
                                   after=[""]))
    self.pushmany([
        "/* Header files needed by all C-based backends */",
        "#include <stdio.h>",
        "#include <string.h>",
        "#include <ncptl/ncptl.h>"])
    self.pushmany(self.invoke_hook("code_specify_include_files_POST",
                                   locals(),
                                   before=[
        "",
        "/* Header files specific to the %s backend */" %
        self.backend_name]))
@end example
@end cartouche

@ocode{code_specify_include_files} uses the @ocode{pushmany} method
(@pxref{Internals}) to push each element in a list of lines of C code
onto the output queue.  It starts by pushing a section
comment---@backendpy{c_generic} outputs fully commented C
code.  Next, it invokes the @ocode{code_specify_include_files_PRE}
hook if it exists and pushes that method's return value onto the
queue.  Then, it pushes all of the @ocode{#include}s needed by the
generated C code.  Finally, it invokes the
@ocode{code_specify_include_files_POST} hook if it exists and pushes
that method's return value onto the queue.

A backend that requires additional header files from those included by
@ocode{code_specify_include_files} need only define
@ocode{code_specify_include_files_PRE} to add extra header files
before the standard ones or @ocode{code_specify_include_files_POST} to
add extra header files after them.  The following is a sample
(hypothetical) hook definition:

@cartouche
@example
def code_specify_include_files_POST(self, localvars):
    "Specify extra header files needed by the c_pthreads backend."
    return [
        "#include <errno.h>",
        "#include <pthread.h>"]
@end example
@end cartouche

Although the top-level structure of @backendpy{c_generic} is
described in @ref{Internals}, a backend developer will normally need
to study the @backendpy{c_generic} source code to discern
the purpose of each hook method and its relation to the surrounding
code.


@node A minimal C-based backend, Generated code, Hook methods, Backend creation
@subsection A minimal C-based backend

A backend derived from @backendpy{c_generic} starts by defining an
@ocode{NCPTL_CodeGen} child class that inherits much of its
functionality from the parent @ocode{NCPTL_CodeGen} class.  There are
only two items that a C-based backend @emph{must} define:
@ocode{backend_name}, the name of the backend in the form
@samp{c_@var{library}}; and, @ocode{backend_desc}, a brief phrase
describing the backend.  (These are used for error messages and file
comments.)  Also, a backend's @w{@ocode{__init__}} method must accept
an @ocode{options} parameter, which is given a list of command-line
parameters not recognized by @filespec{ncptl.py}.  After
@ocode{NCPTL_CodeGen}'s @w{@ocode{__init__}} method processes the
entries in @ocode{options} that it recognizes, it should pass the
remaining options to its parent class's @w{@ocode{__init__}} method
for further processing.  (For proper initialization, the parent
class's @w{@ocode{__init__}} method must be called, even if there are
no remaining options to process.)

The following is the complete source code to a minimal @ncptl{}
backend.  This backend, @backendpy{c_seq}, supports only sequential
@ncptl{} programs (e.g., @samp{TASK 0 OUTPUTS "Hello, world!"}); any
attempt to use communication statements (@pxref{Communication
statements}) will result in a compile-time error.

@cartouche
@example
#! /usr/bin/env python

#######################################################
# Code generation module for the coNCePTuaL language: #
# Minimal C-based backend -- all communication        #
# operations result in a compiler error               #
#                                                     #
# By Scott Pakin <pakin@@lanl.gov>                     #
#######################################################

import codegen_c_generic

class NCPTL_CodeGen(codegen_c_generic.NCPTL_CodeGen):
    def __init__(self, options):
        "Initialize the sequential C code generation module."
        self.backend_name = "c_seq"
        self.backend_desc = "C, sequential code only"
        codegen_c_generic.NCPTL_CodeGen.__init__(self, options)

        # We don't have our own command-line options but we handle
        # --help, nevertheless.
        for arg in range(0, len(options)):
            if options[arg] == "--help":
                # Output a help message.
                self.show_help()
                raise SystemExit, 0
@end example
@end cartouche

The @backend{c_seq} backend can be used like any other:

@cartouche
@example
ncptl --backend=c_seq \
  --program='For each i in @{10, ..., 1@} task 0 outputs i.' | \
  indent > myprogram.c
@end example
@end cartouche

@noindent
(@backendpy{c_generic} outputs unindented code, deferring
attractive formatting to the Unix @filespec{indent} utility.)

One sequential construct the @backend{c_seq} backend does not support
is randomness, as needed by@keyw{A RANDOM PROCESSOR}
(@pxref{Reordering task IDs}) and @keyw{A RANDOM TASK} (@pxref{Binding
variables}).  @backendpy{c_generic} cannot support
randomness itself because doing so requires broadcasting the seed for
the random-number generator to all tasks.  Broadcasting requires
messaging-layer support, which a derived backend provides through the
@ocode{code_def_init_reseed_BCAST} hook (@pxref{Hook methods}).  For the
sequential backend presented above, a broadcast can be implemented as
a no-op:

@cartouche
@example
def code_def_init_reseed_BCAST(self, localvars):
    '"Broadcast" a random-number seed to all tasks.'
    return []
@end example
@end cartouche

In fact, that same do-nothing hook method is used by the
@backend{c_udgram} backend.  @backend{c_udgram} seeds the
random-number generator before calling @ocodecf{fork}, thereby
ensuring that all tasks have the same seed without requiring an
explicit broadcast.


@node Generated code, Internals, A minimal C-based backend, Backend creation
@subsection Generated code
@cindex generated code
@cindex code, generated

@backendpy{c_generic} generates thoroughly commented C code.
However, the overall structure of the generated code may be somewhat
unintuitive, as it does not resemble the code that a human would write
to accomplish a similar task.  The basic idea behind the generated C
code is that it expands the entire program into a list of ``events'',
then starts the clock, then executes all of the events in a single
loop.  Regardless of the @ncptl{} program being compiled, the body of
the generated C code will look like this:

@cartouche
@example
for (i=0; i<numevents; i++) @{
  CONC_EVENT *thisev = &eventlist[i];

  switch (thisev->type) @{
    case @var{event_1}:
      @center @texmath{\vdots, @dots{}}

    case @var{event_2}:
      @center @texmath{\vdots, @dots{}}

  @}
@}
@end example
@end cartouche

Programs generated by @backendpy{c_generic} define a number of event
types that are summarized in @ref{Event types}.  The @ocode{EV_CODE}
event is used, for example, by the @keyw{BACKEND EXECUTES}
(@pxref{Injecting arbitrary code}), @keyw{LOGS} (@pxref{Writing to a
log file}), and @keyw{OUTPUTS} (@pxref{Writing to standard output})
statements.  Note that there are no loop events---in fact, there are
no complex statements (@pxref{Complex statements}) whatsoever.
Complex statements are expanded into multiple simple statements at
initialization time.

The advantage of completely expanding a @ncptl{} program during the
initialization phase---essentially, ``pre-executing'' the entire
program---is that that enables all of the expensive,
non-communication-related setup to be hoisted out of the timing loop,
which is how a human would normally express a network benchmark.
Pre-execution is possible because the @ncptl{} language is not a
Turing machine; infinite loops are not expressible by the language and
message contents and timings cannot affect program behavior, for
instance.  During its initialization phase, the generated C code
allocates memory for message buffers, evaluates numerical expressions,
verifies program assertions, unrolls loops, and does everything else
that's not directly relevant to communication performance.  For
instance, the @ncptl{} program @samp{TASK tx SUCH THAT tx>4 SENDS 10 1
MEGABYTE MESSAGES TO TASK tx/2} would cause each task to perform the
following steps during initialization:

@itemize @bullet
@item
determine if its @w{task ID} is greater @w{than 4}, making the task a
sender

@item
determine if its @w{task ID} is equal to @samp{tx/4} (rounded down to
the nearest integer) for some task @samp{tx} in the program, making
the task a receiver

@item
allocate 1@dmn{MB} for a message buffer

@item
allocate and initialize a repeat event, specifying that the subsequent
event should repeat @w{10 times}

@item
allocate a send or receive event
@end itemize

@noindent
The final two of those steps repeat as necessary.  For example,
@w{task 3} receives @w{10 messages} from each of @w{task 6} and
@w{task 7}.

Note that each task's receive events (if any) are allocated before its
send events (if any), as described @ref{Sending}.  Also, note that
only a single message buffer is allocated because the @ncptl{} source
did not specify the @keyw{UNIQUE} keyword (@pxref{Unique messages}).

An event is implemented as a C @code{struct} that contains all of the
state needed to perform a particular operation.  For example, an event
corresponding to a synchronous or asynchronous send operation
@w{(@ocode{CONC_SEND_EVENT})} stores the destination @w{task ID,} the
number of bytes to send, the message alignment, the number of
outstanding asynchronous sends and receives, a flag indicating whether
the data is to be touched, and a flag indicating that the message
should be filled with data the receiver can verify.  In addition, the
@ocode{code_declare_datatypes_SEND_STATE} hook (@pxref{Hook methods})
enables a backend to include additional, backend-specific state in the
@w{(@ocode{CONC_SEND_EVENT})} data structure.


@node Internals,  , Generated code, Backend creation
@subsection Internals
@cindex internals

@backendpy{c_generic} is a fairly substantial piece of code.
It is divided into ten sections:

@enumerate
@item
methods exported to the compiler front end

@item
utility functions that do not generate code

@item
utility functions that do generate code

@item
methods for outputting language atoms (@pxref{Primitives})

@item
methods for outputting miscellaneous language constructs
(e.g., restricted identifiers; @pxref{Restricted identifiers})

@item
methods for outputting expressions (@pxref{Expressions})

@item
methods for outputting complete programs (@pxref{Complete programs})

@item
methods for outputting complex statements (@pxref{Complex statements})

@item
methods for outputting simple statements (e.g., communication
statements; @pxref{Communication statements})

@item
methods for outputting nodes with non-textual names (e.g., @samp{...}
and various operators)
@end enumerate

The @ocode{NCPTL_CodeGen} class defined in @backendpy{c_generic}
generates code as follows.  The @ocode{generate} method, which is
invoked by @filespec{ncptl.py}, calls upon @PLY{} to process the
abstract-syntax tree (@AST{}) in postorder fashion.
@ocode{NCPTL_CodeGen} maintains a stack @w{(@ocode{codestack})} on
which code fragments are pushed and popped but that ends up containing
a complete line of C code in each element.  For example, in the
@ncptl{} program @samp{TASK 0 OUTPUTS 1+2*3}, the @ocode{n_outputs}
method will pop @samp{[('expr', '(1)+((2)*(3))')]} (a list containing
the single expression @samp{1+2*3}) and @samp{('task_expr', '0')} (a
tuple designating a task by the expression @samp{0}) and push multiple
lines of code that prepare @w{task 0} to evaluate and output the given
expression.

The utility functions are the most useful for backend developers to
understand, as they are frequently called from hook methods
(@pxref{Hook methods}).  The following should be of particular
importance:

@table @ocode
@item push
@itemx pushmany
Push a single value (typically a string of C code) or each value in a
list of values onto a stack.

@item error_fatal
@itemx error_internal
Output a generic error message or an ``internal error'' error message
and abort the program.

@item code_declare_var
Push (using the @ocode{push} method) a line of C code that declares a
variable with an optionally specified type, name, initial value, and
comment.  Return the variable name actually used.
@end table

@noindent
See the definitions in @backendpy{c_generic} of each of the above to
determine required and optional parameters.  The following, adapted
from @backendpy{c_udgram} demonstrates some of the preceding methods:

@cartouche
@example
def n_for_count_SYNC_ALL(self, localvars):
    "Synchronize all of the tasks in the job."
    synccode = []
    self.push("@{", synccode)
    loopvar = self.code_declare_var(suffix="task",
      comment="Loop variable that iterates over all (physical) ranks",
      stack=synccode)
    self.pushmany([
      "thisev_sync->s.sync.peerqueue = ncptl_queue_init (sizeof(int));",
      "for (%s=0; %s<var_num_tasks; %s++)" %
      (loopvar, loopvar, loopvar),
      "*(int *)ncptl_queue_allocate(thisev_sync->s.sync.peerqueue) = %s;" %
      loopvar,
      "thisev_sync->s.sync.syncrank = physrank;",
      "@}"],
                  stack=synccode)
    return synccode
@end example
@end cartouche

That definition of the @ocode{n_for_count_SYNC_ALL} hook method
defines a new stack @w{(@code{synccode})} and pushes a @samp{@{} onto
it.  It then declares a loop variable, letting
@ocode{code_declare_var} select a name but dictating that it end in
@samp{_task}.  The hook method then pushes some additional C code onto
the @code{synccode} stack and finally returns the stack (which is
really just a list of lines of C code).

Some useful variables defined by @ocode{NCPTL_CodeGen} include the
following:

@table @ocode
@item base_global_parameters
a list of 6-ary tuples defining extra command-line parameters to parse
(format: @{@var{type}, @var{variable}, @var{long_name},
@var{short_name}, @var{description}, @var{default_value}@})

@item events_used
a dictionary containing the names of events actually used by the
program being compiled
@end table

Some methods in @backendpy{c_generic} that are worth
understanding but are unlikely to be used directly in a derived
backend include the following:

@table @ocode
@item pop
Pop a value from a stack.

@item push_marker
Push a specially designated ``marker'' value onto a stack.

@item combine_to_marker
Pop all items off a stack up to the first marker value found; discard
the marker; then, push the popped items as a single list of items.
This is used, for example, by a complex statement (@pxref{Complex
statements}) that applies to a list of statements, which can be popped
as a unit using @ocode{combine_to_marker}.

@item invoke_hook
Call a hook method, specifying code to be pushed before/after the
hook-produced code and alternative text (or @cncp{Python} code) to be pushed
(or executed) in the case that a hook method is not provided.
@end table


@node Run-time library functions,  , Backend creation, Implementation
@section Run-time library functions
@cindex run-time library
@cindex library, run-time

To simplify the backend developer's task and to provide consistent
functionality across backends, @ncptl{} provides a run-time library
that encapsulates many of the common operations needed for
network-correctness and performance-testing programs.  This section
describes all of the functions that the library exports (plus a few
important types and variables).  The library is written in C, so all
of the type/variable/function prototypes are expressed with C syntax.
The library includes, among others, functions that manage
heap-allocated memory, accurately read the time, write results to log
files, control queues of arbitrary data, and implement various
arithmetic operations.  All of these functions should be considered
``slow'' and should therefore generally not be invoked while execution
is being timed.@footnote{Some notable exceptions are the functions
described in @ref{Message-buffer manipulation functions}, which
implement @ncptl{}'s @keyw{WITH DATA TOUCHING} and
@keyw{WITH VERIFICATION} constructs.}

@menu
* Variables and data types::    Non-functions used by backends and the library
* Initialization functions::    The first calls to make from C
* Memory-allocation functions::  Getting memory from the heap
* Message-buffer manipulation functions::  Managing communication buffers
* Time-related functions::      Measuring and consuming time
* Log-file functions::          Writing results to a log file
* Random-task functions::       Selecting tasks at random
* Task-mapping functions::      Mapping between task IDs and processor IDs
* Queue functions::             Manipulating data queues
* Unordered-set functions::     Manipulating unordered sets of data
* Language-visible functions::  Implementing coNCePTuaL functions
* Finalization functions::      Cleanly stopping the run-time library
@end menu


@node Variables and data types, Initialization functions, Run-time library functions, Run-time library functions
@subsection Constants, variables, and data types
@cindex constants, run-time library
@cindex variables, run-time library
@cindex data types, run-time library

The following constants, variables, and data types are used by various
run-time library functions and directly by backends.

@deftp {Data type} ncptl_int
@olindex ncptl_int
The internal data type of the @ncptl{} run-time library is
@ocode{ncptl_int}.  This is normally a 64-bit signed integer type
selected automatically by @filespec{configure} (@pxref{configure}) but
can be overridden with the @copt{with-datatype} option to
@filespec{configure}.  @filespec{ncptl.h} defines a string macro
called @ocode{NICS} that can be used to output an @ocode{ncptl_int}
regardless of how the @ocode{ncptl_int} type is declared:

@cartouche
@example
ncptl_fatal ("My variable contains a negative value (%" NICS ")",
             my_ncptl_int_var);
@end example
@end cartouche

@noindent
@ocode{ncptl_int} constants declared by backends derived from
@backendpy{c_generic} are given an explicit suffix that
defaults to @samp{LL} but can be overridden at configuration time
using the @copt{with-const-suffix} option.
@end deftp

@defvr {Constant} NCPTL_INT_MIN
@olindex NCPTL_INT_MIN
@ocode{NCPTL_INT_MIN} is a @cpreproc{} macro that represents the
smallest @w{(i.e., most} negative) number that can be assigned to an
@ocode{ncptl_int}.  For example, if @ocode{ncptl_int} is a 64-bit
signed integer type, then @ocode{NCPTL_INT_MIN} will be the value
@samp{-9223372036854775808}.
@end defvr

@deftp {Data type} NCPTL_CMDLINE
@olindex NCPTL_CMDLINE
The @ocode{NCPTL_CMDLINE} structure describes an acceptable
command-line option.  It contains a type, which is either
@ocode{NCPTL_TYPE_INT} for an @ocode{ncptl_int} or
@ocode{NCPTL_TYPE_STRING} for a @w{@code{char *},} a pointer to a
variable that will receive the value specified on the command line,
the long name of the argument (without the @samp{--}), the one-letter
short name of the argument (without the @samp{-}), a textual
description of what the argument represents, and a default value to
use if the option is not specified on the command line.
@end deftp

@deftp {Data type} NCPTL_QUEUE
@olindex NCPTL_QUEUE
An @ocode{NCPTL_QUEUE} is an opaque data type that represents a
dynamically growing queue that can be flattened to an array for more
convenient access.  @ocode{NCPTL_QUEUE}s have proved to be quite
useful when implementing @ncptl{} backends.
@end deftp

@deftp {Data type} NCPTL_LOG_FILE_STATE
@olindex NCPTL_LOG_FILE_STATE
Every @ncptl{} log file is backed by a unique
@ocode{NCPTL_LOG_FILE_STATE} opaque data type.  An
@ocode{NCPTL_LOG_FILE_STATE} data type represents all of the state
needed to maintain that file, such as file descriptors, prologue
comments, and data that has not yet been aggregated.
@end deftp

@deftypevar int ncptl_pagesize
@olindex ncptl_pagesize
This variable is initialized by @ocodecf{ncptl_init} to the number of
bytes in an operating-system memory page.  @ocode{ncptl_pagesize} can
be used by backends to implement @ncptl{}'s @keyw{PAGE SIZED}
(@pxref{Item size}) and @keyw{PAGE ALIGNED} (@pxref{Message
alignment}) keywords.
@end deftypevar

@deftypevar int ncptl_fast_init
@olindex ncptl_fast_init
The @ocodecf{ncptl_init} function (@pxref{Initialization functions})
can take many seconds to complete.  Much of this time is spent
calibrating and measuring the quality of the various timers the
run-time library uses.  For backends such as @backend{picl}
(@pxref{The picl backend}) that do not measure real time there is
little need to have an accurate timer.  Setting
@ocode{ncptl_fast_init} to @samp{1} before invoking
@ocodecf{ncptl_init} skips the timer calibration and measurement
steps, thereby leading to faster initialization times.  A user can
also override the setting of @ocode{ncptl_fast_init} at run time by
setting the @envvar{NCPTL_FAST_INIT} environment variable to either
@samp{0} or @samp{1}, as appropriate.
@end deftypevar


@node Initialization functions, Memory-allocation functions, Variables and data types, Run-time library functions
@subsection Initialization functions
@cindex initialization functions
@cindex functions, initialization

The following functions are intended to be called fairly early in the
generated code.

@deftypefun void ncptl_init (int @var{version}, char *@var{program_name})
@olindex ncptl_init
Initialize the @ncptl{} run-time library.  @var{version} is used to
verify that @filespec{runtimelib.c} corresponds to the version of
@filespec{ncptl.h} used by the generated code.  The caller must pass
in @ocode{NCPTL_RUN_TIME_VERSION} for @var{version}.
@var{program_name} is the name of the executable program and is used
for outputting error messages.  The caller should pass in
@code{argv[0]} for @var{program_name}.  @ocodecf{ncptl_init} must be
the first library function called by the generated code (with a few
exceptions, as indicated below).
@end deftypefun

@deftypefun void ncptl_permit_signal (int @var{signalnum})
@olindex ncptl_permit_signal
Indicate that the backend relies on signal @var{signalnum} for correct
operation.  Because signal handling has performance implications, the
@ncptl{} run-time library normally terminates the program upon
receiving a signal.  Hence, the user can be assured that if a program
runs to completion then no signals have affected its performance.
@xref{Running coNCePTuaL programs}, for a description of the
@copt{no-trap} command-line option, which enables a user to permit
additional signals to be delivered to the program (e.g., when linking
with a particular implementation of a communication library that
relies on signals).  @ocodecf{ncptl_permit_signal} must be invoked
before @ocodecf{ncptl_parse_command_line} to have any effect.
@end deftypefun

@deftypefun void ncptl_parse_command_line (int @var{argc}, char *@var{argv}[], NCPTL_CMDLINE *@var{arglist}, int @var{numargs})
@olindex ncptl_parse_command_line
Parse the command line.  @var{argc} and @var{argv} should be the
argument count and argument vector passed to the generated code by the
operating system.  @var{arglist} is a list of descriptions of
acceptable command-line arguments and @var{numargs} is the length of
that list.
@end deftypefun

Because @ocodecf{ncptl_init} takes many seconds to run, it is common
for generated code to scan the command line for @copt{help} or
@copts{?} and, if found, skip @ocodecf{ncptl_init} and immediately
invoke @ocodecf{ncptl_parse_command_line}.  Doing so gives the user
immediate feedback when requesting program usage information.
Skipping @ocodecf{ncptl_init} is safe in this context because
@ocodecf{ncptl_parse_command_line} terminates the program after
displaying usage information; it does not require any information
discovered by @ocodecf{ncptl_init}.

Most generated programs have a @copt{seed}/@copts{S} option that
enables the user to specify explicitly a seed for the random-number
generator with @copt{help}/@copts{?} showing the default seed.
@ocodecf{ncptl_seed_random_task} must therefore be called before
@ocodecf{ncptl_parse_command_line} which, as stated in the previous
paragraph, can be invoked without a prior invocation of
@ocodecf{ncptl_init}.  Consequently, it can be considered safe also to
invoke @ocodecf{ncptl_seed_random_task} before @ocodecf{ncptl_init}.

A generated program's initialization routine will generally exhibit a
structure based on the following pseudocode:

@display
@strong{if} ``@code{--help}'' @strong{or} ``@code{-?}'' @strong{in} command-line options @strong{then}
   @var{only_help} := @sc{true}
@strong{else}
   @var{only_help} := @sc{false}
   @code{ncptl_init(@dots{})}
@strong{end if}
@var{random_seed} := @code{ncptl_seed_random_task(0)}
@code{ncptl_parse_command_line(@dots{})}
@strong{if} @var{only_help} = @sc{true} @strong{then}
   @code{ncptl_error("Internal error; should have exited")}
@strong{end if}
@code{ncptl_seed_random_task(@var{random_seed})}
@end display


@node Memory-allocation functions, Message-buffer manipulation functions, Initialization functions, Run-time library functions
@subsection Memory-allocation functions
@cindex memory-allocation functions
@cindex functions, memory-allocation

The @ncptl{} run-time library provides its own wrappers for
@code{malloc()}, @code{free()}, @code{realloc()}, and @code{strdup()}
as well as a specialized @code{malloc()} designed specifically for
allocating message buffers.  The wrappers' ``value added'' is that
they support the explicit data alignments needed by @keyw{ALIGNED}
messages (@pxref{Message alignment}) and that they automatically call
@ocodecf{ncptl_fatal} on failure, so the return value does not need to
be checked for @code{NULL}.

@deftypefun {void *} ncptl_malloc (ncptl_int @var{numbytes}, ncptl_int @var{alignment})
@olindex ncptl_malloc
Allocate @var{numbytes} bytes of memory aligned to an
@var{alignment}-byte boundary.  If @var{alignment} is @samp{0},
@ocodecf{ncptl_malloc} will use whatever alignment is ``natural'' for
the underlying architecture.  @ocodecf{ncptl_malloc} will
automatically call @ocodecf{ncptl_fatal} if memory allocation fails.
Therefore, unlike @code{malloc()}, there is no need to check the
return value for @code{NULL}.
@end deftypefun

@deftypefun {void *} ncptl_malloc_misaligned (ncptl_int @var{numbytes}, ncptl_int @var{misalignment})
@olindex ncptl_malloc_misaligned
Allocate @var{numbytes} bytes of memory from the heap aligned
@var{misalignment} bytes past a page boundary.  If @var{alignment} is
@samp{0}, @ocodecf{ncptl_malloc_misaligned} will return page-aligned
memory.  @ocodecf{ncptl_malloc_misaligned} will automatically call
@ocodecf{ncptl_fatal} if memory allocation fails.  Therefore, unlike
@code{malloc()}, there is no need to check the return value for
@code{NULL}.
@end deftypefun


@deftypefun void ncptl_free (void *@var{pointer})
@olindex ncptl_free
Free memory previously allocated by @ocodecf{ncptl_malloc}.  It is an
error to pass @ocodecf{ncptl_free} memory not allocated by
@ocodecf{ncptl_malloc}.
@end deftypefun

@deftypefun {void *} ncptl_realloc (void *@var{pointer}, ncptl_int @var{numbytes}, ncptl_int @var{alignment})
@olindex ncptl_realloc
Given a pointer returned by @ocodecf{ncptl_malloc}, change its size to
@var{numbytes} and byte-alignment to @var{alignment} without altering
the contents (except for truncation in the case of a smaller target
size).  If @var{alignment} is @samp{0}, @ocodecf{ncptl_realloc} will
use whatever alignment is ``natural'' for the underlying architecture.
@ocodecf{ncptl_realloc} will automatically call @ocodecf{ncptl_fatal}
if memory allocation fails.  Therefore, unlike @code{realloc()}, there
is no need to check the return value for @code{NULL}.
@end deftypefun

@deftypefun {char *} ncptl_strdup (const char *@var{string})
@olindex ncptl_strdup
@ocodecf{ncptl_strdup} copies a string as does the standard C
@ocodecf{strdup} function.  However, @ocodecf{ncptl_strdup} uses
@ocodecf{ncptl_malloc} instead of @ocodecf{malloc} to allocate memory
for the copy, which must therefore be deallocated using
@ocodecf{ncptl_free}.
@end deftypefun

@deftypefun {void *} ncptl_malloc_message (ncptl_int @var{numbytes}, ncptl_int @var{alignment}, ncptl_int @var{outstanding}, int @var{misaligned})
@olindex ncptl_malloc_message
Allocate @var{numbytes} bytes of memory from the heap either aligned
on an @var{alignment}-byte boundary (if @var{misaligned} is @samp{0})
or @var{alignment} bytes past a page boundary (if @var{misaligned} is
@samp{1}).  All calls with the same value of @var{outstanding} will
share a buffer.  @ocodecf{ncptl_malloc_message} is intended to be used
in two passes.  The first time the function is called on a set of
messages it merely determines how much memory to allocate.  The second
time, it returns valid memory buffers.  Note that the returned pointer
can be neither @code{free()}d nor @ocodecf{ncptl_free}d.
@end deftypefun

@deftypefun {void *} ncptl_get_message_buffer (ncptl_int @var{buffernum})
@olindex ncptl_get_message_buffer
Return a pointer to a message buffer previously allocated (and
finalized) by @ocodecf{ncptl_malloc_message}.  The @var{buffernum}
argument to @ocodecf{ncptl_get_message_buffer}, which corresponds to
the @var{outstanding} argument to @ocodecf{ncptl_malloc_message},
specifies the number of the buffer to return.
@ocodecf{ncptl_get_message_buffer} returns @code{NULL} if buffer
@var{buffernum} is either unallocated or uninitialized.
@end deftypefun


@node Message-buffer manipulation functions, Time-related functions, Memory-allocation functions, Run-time library functions
@subsection Message-buffer manipulation functions
@cindex message buffers
@cindex buffers, message
@cindex functions, message-buffer

The @ncptl{} language facilitates verifying message contents and
touching every word in a message (@pxref{Data touching}).  The
following functions implement those features.

@deftypefun void ncptl_fill_buffer (void *@var{buffer}, ncptl_int @var{numbytes}, int @var{validity})
@olindex ncptl_fill_buffer
Fill a region of memory with known values.  If @var{validity} is
@samp{+1}, @ocodecf{ncptl_fill_buffer} will fill the first
@var{numbytes} bytes of @var{buffer} with a verifiable sequence of
integers (@pxref{Data touching}).  If @var{validity} is @samp{-1},
@ocodecf{ncptl_fill_buffer} will pollute the first @var{numbytes}
bytes of @var{buffer}.  Receive buffers should be polluted before
reception to avoid false negatives caused, for example, by an
inadvertently dropped message destined for a previously validated
buffer.
@end deftypefun

@deftypefun ncptl_int ncptl_verify (void *@var{buffer}, ncptl_int @var{numbytes})
@olindex ncptl_verify
Verify the contents of memory filled by @ocodecf{ncptl_fill_buffer}.
The function returns the number of erroneous bits.
@ocodecf{ncptl_verify} is used to implement @ncptl{}'s @keyw{WITH
VERIFICATION} construct (@pxref{Data touching}).
@end deftypefun

@deftypefun void ncptl_touch_data (void *@var{buffer}, ncptl_int @var{numbytes})
@olindex ncptl_touch_data
Touch every byte in a given buffer.  @ocodecf{ncptl_touch_data} is
used to implement the @keyw{WITH DATA TOUCHING} construct described in
@ref{Data touching}.
@end deftypefun


The following function, @ocodecf{ncptl_touch_memory}, does not
actually manipulate message buffers.  It is included in this section
because of its similarity to @ocodecf{ncptl_touch_data}.
@ocodecf{ncptl_touch_data} touches message buffers to implement the
@keyw{WITH DATA TOUCHING} construct; @ocodecf{ncptl_touch_memory}
touches a hidden memory region to implement the @keyw{TOUCHES}
statement.

@deftypefun void ncptl_touch_memory (void *@var{buffer}, ncptl_int @var{bufferbytes}, ncptl_int @var{wordbytes}, ncptl_int @var{firstbyte}, ncptl_int @var{numaccesses}, ncptl_int @var{bytestride})
@olindex ncptl_touch_memory
Walk a memory region @var{buffer} of size @var{bufferbytes} bytes.
Each ``word'' to touch contains @var{wordbytes} bytes.
@var{firstbyte} indicates the byte index into @var{buffer} from which
to start touching.  The function will read and write @var{numaccesses}
``words'' with stride @var{bytestride} bytes.  For example,
@samp{ncptl_touch_memory (mybuffer, 1048576, 64, 192, 10000, 4096)}
will read and write (but otherwise do nothing with) the @w{64 bytes}
that lie @w{192 bytes} into a 1@dmn{MB} memory region, then the @w{64
bytes} starting at offset 4288, then the 64 bytes starting at
@texmath{192+4096\times 2, 192+4096*2}, then at
@texmath{192+4096\times 3, 192+4096*3}, then at
@texmath{192+4096\times 4, 192+4096*4}, and so forth up to
@texmath{192+4096\times 10000, 192+4096*10000}, wrapping around the
1@dmn{MB} region as necessary.

@iindent
A @var{bytestride} of @ocode{NCPTL_INT_MIN} implies a random stride.

@iindent
As an important special case, if @var{firstbyte} is @samp{-1}, then
@ocodecf{ncptl_touch_memory} will touch one or more message buffers
(cf.@: @ocodecf{ncptl_malloc_message} in @ref{Memory-allocation
functions}) instead of the given @var{buffer}.  In that case,
@var{bufferbytes} stores the buffer number (a nonnegative number).  If
@var{bufferbytes} is @samp{-1}, however, then @emph{all} message
buffers are touched.  Note that when @var{firstbyte} is @samp{-1}, all
parameters to @ocodecf{ncptl_touch_memory} other than
@var{bufferbytes} are ignored.

@iindent
@ocodecf{ncptl_touch_memory} is intended to to be used to implement
the @keyw{TOUCHES} statement (@pxref{Touching memory}).
@end deftypefun


@node Time-related functions, Log-file functions, Message-buffer manipulation functions, Run-time library functions
@subsection Time-related functions
@cindex time-related functions
@cindex functions, time-related

An essential component of any benchmarking system is an accurate
timer.  @ncptl{}'s @ocodecf{ncptl_time} function selects from a
variety of timers at configuration time, first favoring lower-overhead
cycle-accurate timers, then higher-overhead cycle-accurate, and
finally non-cycle-accurate timers.  @ocodecf{ncptl_init} measures the
actual timer overhead and resolution and
@ocodecf{ncptl_log_write_prologue} writes this information to the log
file.  Furthermore, the @filespec{validatetimer} program
(@pxref{Validating the coNCePTuaL timer}) can be used to verify that
the timer used by @ocodecf{ncptl_init} truly does correspond to
wall-clock time.

The @ncptl{} language provides a few time-related functions.  These
are supported by the functions described below.

@deftypefun uint64_t ncptl_time (void)
@olindex ncptl_time
Return the time in microseconds.  The timer ticks even when the
program is not currently scheduled.  No assumptions can be made about
the relation of the value returned to the time of day;
@ocodecf{ncptl_time} is intended to be used strictly for computing
elapsed time.  The timer's resolution and accuracy are logged to the
log file by @ocodecf{ncptl_log_write_prologue} (more precisely, by the
internal @ocodecf{log_write_prologue_timer} function, which is called by
@ocodecf{ncptl_log_write_prologue}).  Note that @ocodecf{ncptl_time}
always returns a 64-bit unsigned value, regardless of how
@ocode{ncptl_int} is declared.

@cindex timer selection
@iindent
The @ncptl{} @filespec{configure} script (@pxref{configure}) searches
for a number of high-resolution timers and selects the best timer
mechanism from among the ones available.  The selection criteria is as
follows:

@enumerate
@item
If @configure{} was passed @copt{with-gettimeofday}
(@pxref{configure}) then @ocodecf{ncptl_time} uses
@ocodecf{gettimeofday} as its timer mechanism.

@item
If @configure{} was passed @copt{with-mpi-wtime} (@pxref{configure})
then @ocodecf{ncptl_time} uses @ocodecf{MPI_Wtime} as its timer
mechanism.

@item
If @configure{} recognizes the CPU architecture, knows how to instruct
the C compiler to insert inline assembly code, and can determine the
number of clock cycles per second, then @ocodecf{ncptl_time} reads the
timer using inline assembly code.  If the cycle counter is likely to
wrap around during a moderately long benchmark @w{(i.e., because} the
cycle counter is a 32-bit register), @ocodecf{ncptl_time} augments the
inline assembly code with calls to @ocodecf{gettimeofday} in an
attempt to produce accurate timings that don't suffer from clock
wraparound.

@item
If the @Linux{} @ocodecf{get_cycles} function is available and
@configure{} can determine the number of clock cycles per second then
@ocodecf{ncptl_time} uses @ocodecf{get_cycles} to measure execution
time.

@item
If the @cncp{PAPI} library is available, @ocodecf{ncptl_time} becomes
a call to PAPI's @ocodecf{PAPI_get_real_usec} function.

@item
If the @w{System V} @ocodecf{clock_gettime} function is available and
the @ocode{CLOCK_SGI_CYCLE} macro is defined, @ocodecf{ncptl_time}
invokes @ocodecf{clock_gettime} with the @ocode{CLOCK_SGI_CYCLE}
argument.  If @ocode{CLOCK_SGI_CYCLE} is not defined but
@ocode{CLOCK_REALTIME} is, then @ocodecf{ncptl_time} invokes
@ocodecf{clock_gettime} with the @ocode{CLOCK_REALTIME} argument.

@item
Intel's (now obsolete) supercomputers provide a @ocodecf{dclock}
function for reading the time.  @ocodecf{ncptl_time} makes use of
@ocodecf{dclock} if it's available.

@item
Microsoft Windows provides functions for reading a high-resolution
timer (@ocodecf{QueryPerformanceCounter}) and for determining the
number of ticks per second that the timer measures
(@ocodecf{QueryPerformanceFrequency}).  If those functions are
available, @ocodecf{ncptl_time} uses them.

@item
As a last resort,  @ocodecf{ncptl_time} uses
@ocodecf{gettimeofday} to measure execution time.
@end enumerate

Furthermore, @ncptl{} makes use of the @cncp{High-Precision Event
Timers (HPET)} device if and only if all of the following conditions
hold at run time:

@itemize @bullet
@item
neither @copt{with-gettimeofday}, @copt{with-mpi-wtime}, nor
@copt{disable-hpet} was specified to @configure{}

@item
@file{/dev/hpet}---or an alternative device specified at configuration
time with @copt{enable-hpet}---exists, is readable, and can be
memory-mapped into user space

@item
the HPET device's main counter is a 64-bit value, not a 32-bit value

@item
the period of the HPET counter is within the ranges required by the
HPET specification, i.e., @w{between 0} and @w{100 nanoseconds}
@end itemize

@cindex High-Precision Event Timers (HPET)
@noindent
Failing any of those conditions, @ncptl{} falls back to the timer
selected at configuration time.  See the
@uref{http://www.intel.com/hardwaredesign/hpetspec.htm, HPET
specification} for more information on HPET.
@end deftypefun

@deftypefun void ncptl_set_flag_after_usecs (volatile int *@var{flag}, uint64_t @var{delay})
@olindex ncptl_set_flag_after_usecs
@ocodecf{ncptl_set_flag_after_usecs} uses the operating system's
interval timer to asynchronously set a variable to @samp{1} after a
given number of microseconds.  This function is intended to be used to
support the @samp{@keyw{FOR} @var{time}} construct (@pxref{Timed
loops}).  Note that @var{delay} is a 64-bit unsigned value, regardless
of how @ocode{ncptl_int} is declared.

@iindent
@ocodecf{ncptl_set_flag_after_usecs} is implemented in terms of the
@ocodecf{setitimer} function and issues a run-time error if the
@ocodecf{setitimer} function is not available.
@end deftypefun

@deftypefun void ncptl_udelay (uint64_t @var{delay}, int @var{spin0block1})
@olindex ncptl_udelay
If @var{spin0block1} is @samp{0}, @ocodecf{ncptl_udelay} spins for
@var{delay} microseconds (i.e., using the CPU)@.  If @var{spin0block1}
is @samp{1}, @ocodecf{ncptl_udelay} sleeps for @var{delay}
microseconds (i.e., relinquishing the CPU)@.  Note that @var{delay} is
a 64-bit unsigned value, regardless of how @ocode{ncptl_int} is
declared.  @ocodecf{ncptl_udelay} is intended to be used to support
the @ncptl{} language's @keyw{SLEEPS} and @keyw{COMPUTES} statements
(@pxref{Delaying execution}).

@iindent
When @var{spin0block1} is @samp{0}, @ocodecf{ncptl_udelay} uses
@ocodecf{ncptl_time} to determine when @var{delay} microseconds have
elapsed.  Unless @ocodecf{ncptl_time} is known to utilize an extremely
low-overhead timer, @ocodecf{ncptl_udelay} intersperses calls to
@ocodecf{ncptl_time} with writes to a dummy variable.  When
@var{spin0block1} is @samp{0}, @ocodecf{ncptl_udelay} invokes
@ocodecf{nanosleep} to introduce delays.  @ocodecf{ncptl_udelay}
issues a run-time error if the @ocodecf{nanosleep} function is not
available.
@end deftypefun


@node Log-file functions, Random-task functions, Time-related functions, Run-time library functions
@subsection Log-file functions
@cindex log files
@cindex functions, log-file

Benchmarking has limited value without a proper record of the
performance results.  The @ncptl{} run-time library provides functions
for writing data to log files.  It takes care of much of the work
needed to calculate statistics on data columns and to log a thorough
experimental setup to every log file.

The library treats a log file as a collection of tables of data.  Each
table contains a number of rows, one per dynamic invocation of the
@keyw{LOGS} statement (@pxref{Writing to a log file}).  Each row
contains a number of columns, one per aggregate expression
(@pxref{Aggregate expressions}) expressed statically in a @ncptl{}
program.@footnote{Writing @keyw{A HISTOGRAM OF THE} @nonterm{expr}
produces two columns, one for values and one for tallies.}  Log-file
functions should be called only if the @ncptl{} source code accesses a
log file (@pxref{Writing to a log file}).

@deftypefun void ncptl_log_add_comment (const char *@var{key}, const char *@var{value})
@olindex ncptl_log_add_comment
@ocodecf{ncptl_log_add_comment} makes it possible for a backend to add
backend-specific @texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} pairs to the set of prologue or epilogue
comments that get written to a log file (@pxref{Log-file format}).
@ocodecf{ncptl_log_add_comment} can be called repeatedly.  All calls
that precede @ocodecf{ncptl_log_open} are included in the log-file
prologue.  All calls that follow @ocodecf{ncptl_log_open} are included
in the log-file epilogue.  Note that @ocodecf{ncptl_log_add_comment}
makes a copy of @var{key} and @var{value}, so these need not be
heap-allocated.
@end deftypefun

@deftypefun {NCPTL_LOG_FILE_STATE *} ncptl_log_open (char *@var{template}, ncptl_int @var{processor})
@olindex ncptl_log_open
Given a filename template containing a @samp{%d} placeholder and a
processor number (i.e., the process's physical rank in the
computation), @ocodecf{ncptl_log_open} creates and opens a log file
named by the template with @samp{%d} replaced by @var{processor}.  For
example, if @var{template} is @file{/home/me/myprog-%d.log} and
@var{processor} is @samp{3}, the resulting filename will be
@file{/home/me/myprog-3.log}.  @ocodecf{ncptl_log_open} must be called
before any of the other @code{ncptl_log_@var{something}()}
functions---except for @ocodecf{ncptl_log_add_comment}, which should
be called before @ocodecf{ncptl_log_open}.  @ocodecf{ncptl_log_open}
returns a pointer to an opaque @ocode{NCPTL_LOG_FILE_STATE} value; the
backend will need to pass this pointer to nearly all of the other
log-file functions described in this section.

@iindent
There are three special cases for @var{template}.  First, if
@var{template} points to an empty string, all log-file output is sent
to the null device (i.e., @file{/dev/null} on Unix and Unix-like
operating systems).  Second, if @var{template} is a single dash
(@samp{-}), all log-file output is sent to the standard output device.
Third, if @var{template} is a single dollar sign (@samp{$}), all
log-file output is buffered in a library-internal string.  The string
can be retrieved using @ocodecf{ncptl_log_get_contents}.
@end deftypefun

@deftypefun {char *} ncptl_log_generate_uuid (void)
@olindex ncptl_log_generate_uuid
Return a random string of hexadecimal digits formatted as
``@var{xxxxxxxx}-@var{xxxx}-@var{xxxx}-@var{xxxx}-@var{xxxxxxxxxxxx}''
(@w{36 bytes} plus a @code{NULL} byte) to pass to
@ocodecf{ncptl_log_write_prologue}.  The caller should
@ocodecf{ncptl_free} the string when it is no longer needed
(generally, as soon as @ocodecf{ncptl_log_write_prologue} returns).
@end deftypefun

@deftypefun void ncptl_log_write_prologue (NCPTL_LOG_FILE_STATE *@var{logstate}, char *@var{progname}, char *@var{uuid}, char *@var{backend_name}, char *@var{backend_desc}, ncptl_int @var{numtasks}, NCPTL_CMDLINE *@var{arglist}, int @var{numargs}, char **@var{sourcecode})
@olindex ncptl_log_write_prologue
@ocodecf{ncptl_log_write_prologue} standardizes the prologue with
which all log files begin.  @var{progname} is the name of the program
executable (@code{argv[0]} in C).  @var{uuid} is a value returned by
@ocodecf{ncptl_log_generate_uuid}.  Note that every process in a
program must pass the same value of @var{uuid} to
@ocodecf{ncptl_log_write_prologue}.  @var{backend_name} is the name of
the backend in @samp{@var{language}_@var{library}} format (e.g.,
@samp{java_rmi}).  @var{backend_desc} is a brief description of the
backend (e.g., @samp{Java + RMI}).  @var{numtasks} is the total number
of tasks in the program.  @var{arglist} is the list of arguments
passed to @ocodecf{ncptl_parse_command_line} and @var{numargs} is the
number of entries in that list.  @var{sourcecode} is the complete
@ncptl{} source code stored as a @code{NULL}-terminated list of
@code{NULL}-terminated strings.
@end deftypefun

@deftypefun {char *} ncptl_log_lookup_string (NCPTL_LOG_FILE_STATE *@var{logstate}, char *@var{key})
@olindex ncptl_log_lookup_string
@ocodecf{ncptl_log_write_prologue} stores every
@texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} comment it writes into an in-memory database.
@ocodecf{ncptl_log_lookup_string} searches the comment database for a
key and returns the corresponding value.  The function returns the
empty string if the key is not found in the database.  In either case,
the caller should not deallocate the result.
@ocodecf{ncptl_log_lookup_string} is intended to be used to implement
@ncptl{}'s @keyw{THE VALUE OF} construct (@pxref{Utilizing log-file
comments}).
@end deftypefun

@deftypefun void ncptl_log_write (NCPTL_LOG_FILE_STATE *@var{logstate}, int @var{logcolumn}, char *@var{description}, LOG_AGGREGATE @var{aggregate}, double @var{value})
@olindex ncptl_log_write
Push value @var{value} onto column @var{logcolumn} of the current
table.  Gaps between columns are automatically elided.
@var{description} is used as the column header for column
@var{logcolumn}.  Acceptable values for @var{aggregate} are defined in
@ref{Representing aggregate functions}.
@end deftypefun

@deftypefun void ncptl_log_compute_aggregates (NCPTL_LOG_FILE_STATE *@var{logstate})
@olindex ncptl_log_compute_aggregates
@ocodecf{ncptl_log_compute_aggregates} implements the @keyw{COMPUTES
AGGREGATES} construct described in @ref{Computing aggregates}.  When
@ocodecf{ncptl_log_compute_aggregates} is invoked, the @ncptl{}
run-time library uses the aggregate function specified by
@ocodecf{ncptl_log_write} to aggregate all of the data that
accumulated in each column since the last invocation of
@ocodecf{ncptl_log_compute_aggregates}.  Note that
@ocodecf{ncptl_log_compute_aggregates} is called implicitly by
@ocodecf{ncptl_log_commit_data}.
@end deftypefun

@deftypefun void ncptl_log_commit_data (NCPTL_LOG_FILE_STATE *@var{logstate})
@olindex ncptl_log_commit_data
The @ncptl{} run-time library keeps the current data table in memory
and doesn't write anything to the log file until
@ocodecf{ncptl_log_commit_data} is called, at which point the run-time
library writes all accumulated data to the log file and begins a new
data table.  Note that @ocodecf{ncptl_log_commit_data} is called
implicitly by @ocodecf{ncptl_log_close}.  Furthermore, a backend
should call @ocodecf{ncptl_log_commit_data} when beginning execution
of a new statement in a @ncptl{} program.  For instance, the
@backendpy{c_generic} backend invokes
@ocodecf{ncptl_log_commit_data} from @ocode{code_def_main_newstmt}.
@end deftypefun

@deftypefun void ncptl_log_write_epilogue (NCPTL_LOG_FILE_STATE *@var{logstate})
@olindex ncptl_log_write_epilogue
Write a stock set of comments as an epilogue to the log file.
@end deftypefun

@deftypefun {const char *} ncptl_log_get_contents (NCPTL_LOG_FILE_STATE *@var{logstate})
@olindex ncptl_log_get_contents
Return the current contents of the log file as a string.  The caller
must not use the string after the next run-time library call that
modifies the log file, modify the string, or free the string.  The
caller should copy the string (e.g., with @ocodecf{ncptl_strdup}) if
any of those actions are necessary.  If the the log file does not
support random access (because it goes to the standard-output device
or the null device), @code{NULL} is returned.
@end deftypefun

@deftypefun void ncptl_log_close (NCPTL_LOG_FILE_STATE *@var{logstate})
@olindex ncptl_log_close
Close the log file.  No @code{ncptl_log_@var{something}()} function
should be called after @ocodecf{ncptl_log_close} is invoked.
@end deftypefun


@node Random-task functions, Task-mapping functions, Log-file functions, Run-time library functions
@subsection Random-task functions
@cindex random tasks
@cindex functions, random-task

Randomness appears in various forms in the @ncptl{} language, such as
when assigning a task to @keyw{A RANDOM PROCESSOR} (@pxref{Reordering
task IDs}) or when let-binding @keyw{A RANDOM TASK} or
@keyw{A RANDOM TASK OTHER THAN} a given task ID to a variable
(@pxref{Binding variables}).  The following functions are used to
select tasks at random.  @ncptl{} currently uses the Mersenne Twister
as its random-number generator.  Hence, given the same seed, a
@ncptl{} program will see the same random-number sequence on every
platform.

@deftypefun int ncptl_seed_random_task (int @var{seed}, ncptl_int @var{procID})
@olindex ncptl_seed_random_task
Initialize the random-number generator needed by
@ocodecf{ncptl_random_task}.  If @var{seed} is zero,
@ocodecf{ncptl_seed_random_task} selects an arbitrary seed value.
@ocodecf{ncptl_seed_random_task} returns the seed that was used.
@var{procID} specifies the (physical) processor ID of the calling task
and is needed to seed the task-local random-number generators used by
some of the functions in @ref{Language-visible functions}.
@end deftypefun

@deftypefun ncptl_int ncptl_random_task (ncptl_int @var{lower_bound}, ncptl_int @var{upper_bound}, ncptl_int @var{excluded})
@olindex ncptl_random_task
Return a randomly selected task number from @var{lower_bound} to
@var{upper_bound} (both inclusive).  If @var{excluded} is nonnegative
then that task number will never be selected, even if it's within
range.
@end deftypefun


@node Task-mapping functions, Queue functions, Random-task functions, Run-time library functions
@subsection Task-mapping functions
@cindex task-mapping functions
@cindex functions, task-mapping

@deftypefun {NCPTL_VIRT_PHYS_MAP *} ncptl_allocate_task_map (ncptl_int @var{numtasks})
@olindex ncptl_allocate_task_map
Allocate and initialize an opaque @ocode{NCPTL_VIRT_PHYS_MAP} object
and return a pointer to it.
@end deftypefun

@deftypefun ncptl_int ncptl_virtual_to_physical (NCPTL_VIRT_PHYS_MAP *@var{procmap}, ncptl_int @var{virtID})
@olindex ncptl_virtual_to_physical
Given a process map allocated by @ocodecf{ncptl_allocate_task_map} and
a (virtual) task ID, return the corresponding (physical) process ID.
@end deftypefun

@deftypefun ncptl_int ncptl_physical_to_virtual (NCPTL_VIRT_PHYS_MAP *@var{procmap}, ncptl_int @var{physID})
Given a process map allocated by @ocodecf{ncptl_allocate_task_map} and
a (physical) process ID, return the corresponding (virtual) task ID.
@end deftypefun

@deftypefun ncptl_int ncptl_assign_processor (ncptl_int @var{virtID}, ncptl_int @var{physID}, NCPTL_VIRT_PHYS_MAP *@var{procmap}, ncptl_int @var{physrank})
@olindex ncptl_assign_processor
Assign a (physical) processor ID, @var{physID}, to a (virtual) task
ID, @var{virtID} given a virtual-to-physical mapping table,
@var{procmap}.  Return a new task ID for the caller's processor given
its @w{processor ID,} @var{physrank}.
@ocodecf{ncptl_assign_processor} is intended to implement the @keyw{IS
ASSIGNED TO} construct (@pxref{Reordering task IDs}).
@end deftypefun


@node Queue functions, Unordered-set functions, Task-mapping functions, Run-time library functions
@subsection Queue functions
@cindex queue functions
@cindex functions, queue

Because queues are a widely applicable construct, the run-time library
provides support for queues of arbitrary datatypes.  In the current
implementation, these can more precisely be termed ``dynamically
growing lists'' than ``queues''.  However, they may be extended in a
future version of the library to support more queue-like
functionality.

@deftypefun {NCPTL_QUEUE *} ncptl_queue_init (ncptl_int @var{eltbytes})
@olindex ncptl_queue_init
@ocodecf{ncptl_queue_init} creates and initializes a dynamically
growing queue in which each element occupies @var{eltbytes} bytes of
memory.
@end deftypefun

@deftypefun {void *} ncptl_queue_allocate (NCPTL_QUEUE *@var{queue})
@olindex ncptl_queue_allocate
Allocate a new data element at the end of queue @var{queue}.  The
queue passed to @ocodecf{ncptl_queue_allocate} must be one returned by
@ocodecf{ncptl_queue_init}.  @ocodecf{ncptl_queue_allocate} returns a
pointer to the data element allocated.
@end deftypefun

@deftypefun {void *} ncptl_queue_push (NCPTL_QUEUE *@var{queue}, void *@var{element})
@olindex ncptl_queue_push
Push (via a memory copy) the element pointed to by @var{element} onto
the end of queue @var{queue} and return a pointer to the copy in the
queue.  The queue passed to @ocodecf{ncptl_queue_allocate} must be one
returned by @ocodecf{ncptl_queue_init}.  (@ocodecf{ncptl_queue_push}
is actually implemented in terms of @ocodecf{ncptl_queue_allocate}.)
@end deftypefun

@deftypefun {void} ncptl_queue_push_all (NCPTL_QUEUE *@var{target_queue}, NCPTL_QUEUE *@var{source_queue})
@olindex ncptl_queue_push_all
Push (via a memory copy) all of the elements in @var{source_queue}
onto the end of @var{target_queue}.  A fatal error will occur if the
two queues were not initialized with the same @var{eltbytes} argument
to @ocodecf{ncptl_queue_init}.  @ocodecf{ncptl_queue_push_all} does
not modify @var{source_queue}.
@end deftypefun

@deftypefun {void *} ncptl_queue_pop (NCPTL_QUEUE *@var{queue})
@olindex ncptl_queue_pop
Pop a pointer to the element at the head of queue @var{queue}.  If
@var{queue} is empty, return @code{NULL}.  The pointer returned by
@ocodecf{ncptl_queue_pop} is guaranteed to be valid until the next
invocation of @ocodecf{ncptl_queue_empty}.
@end deftypefun

@deftypefun {void *} ncptl_queue_pop_tail (NCPTL_QUEUE *@var{queue})
@olindex ncptl_queue_pop_tail
@cindex stack functions
@cindex functions, stack
Pop a pointer to the element at the tail of queue @var{queue}.  If
@var{queue} is empty, return @code{NULL}.  In essence, this lets the
caller treat the queue as a stack.  The pointer returned by
@ocodecf{ncptl_queue_pop_tail} is guaranteed to be valid until the
next invocation of @ocodecf{ncptl_queue_empty},
@ocodecf{ncptl_queue_allocate} or @ocodecf{ncptl_queue_push}.
@end deftypefun

@deftypefun {void *} ncptl_queue_contents (NCPTL_QUEUE *@var{queue}, int @var{copyelts})
@olindex ncptl_queue_contents
Return queue @var{queue} as an array of elements.  If
@ocodecf{ncptl_queue_contents} is passed @samp{1} for @var{copyelts},
a new array is allocated using @ocodecf{ncptl_malloc}; the queue's
internal array is copied to the newly allocated array; and, this new
array is returned to the caller.  It is the caller's responsibility to
pass the result to @ocodecf{ncptl_free} when the array is no longer
needed.  If @ocodecf{ncptl_queue_contents} is passed @samp{0} for
@var{copyelts}, a pointer to the queue's internal array is returned
without first copying it.  This pointer should not be passed to
@ocodecf{ncptl_free} as it is still needed by @var{queue}.
@end deftypefun

@deftypefun ncptl_int ncptl_queue_length (NCPTL_QUEUE *@var{queue})
@olindex ncptl_queue_length
Return the number of elements in queue @var{queue}.
@end deftypefun

@deftypefun void ncptl_queue_empty (NCPTL_QUEUE *@var{queue})
@olindex ncptl_queue_empty
Empty a queue, freeing the memory that had been allocated for its
elements.  Queue contents returned by @ocodecf{ncptl_queue_contents}
with @var{copyelts} set to @samp{0} are also invalidated.  The queue
itself can continue to be used and should be deallocated with
@ocodecf{ncptl_free} (@pxref{Memory-allocation functions}) when no
longer needed.
@end deftypefun


@node Unordered-set functions, Language-visible functions, Queue functions, Run-time library functions
@subsection Unordered-set functions
@cindex set functions
@cindex functions, set

Because unordered collections of data are a widely applicable
construct, the run-time library provides support for sets.  A set
contains zero or more keys, each of which must be unique within the
set.  Furthermore, each key can be associated with a data value.  Sets
are currently implemented in the @ncptl{} run-time library as hash
tables.

@deftypefun {NCPTL_SET *} ncptl_set_init (ncptl_int @var{numelts}, ncptl_int @var{keybytes}, ncptl_int @var{valuebytes})
@olindex ncptl_set_init
Allocate and initialize a set object and return a pointer to it.  Each
element in the set maps a @var{keybytes}-byte key to a
@var{valuebytes}-byte value.  The @var{numelts} parameter is an
estimate of the maximum number of elements in the set.
@ocodecf{ncptl_set_init} returns a pointer to the set.
@end deftypefun

@deftypefun {void *} ncptl_set_find (NCPTL_SET *@var{set}, void *@var{key})
@olindex ncptl_set_find
Given a set and a pointer to a key, return a pointer to the associated
value or @code{NULL} if the key is not found in the set.
@end deftypefun

@deftypefun void ncptl_set_insert (NCPTL_SET *@var{set}, void *@var{key}, void *@var{value})
@olindex ncptl_set_insert
Insert a key into a set and associate a value with it.
@ocodecf{ncptl_set_insert} copies both @var{key} and @var{value} so
stack-allocated keys and values are acceptable inputs.  The run-time
library aborts with an error message if the key is already in the set.
@end deftypefun

@deftypefun void ncptl_set_walk (NCPTL_SET *@var{set}, void (*@var{userfunc})(void *, void *))
@olindex ncptl_set_walk
Execute function @var{userfunc} for every
@texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} pair in a set.  @var{userfunc} must take two
@code{void *} values as input: a pointer to a key and a pointer to a
value.  The order in which keys and values are passed to the function
is unspecified.
@end deftypefun

@deftypefun void ncptl_set_remove (NCPTL_SET *@var{set}, void *@var{key})
@olindex ncptl_set_remove
Remove a key and its associated value from a set.  The run-time
library aborts with an error message if the key is not found in the
set.
@end deftypefun

@deftypefun void ncptl_set_empty (NCPTL_SET *@var{set})
@olindex ncptl_set_empty
Empty a set, freeing the memory that had been allocated for its
contents.  The set itself can continue to be used and should be
deallocated with @ocodecf{ncptl_free} (@pxref{Memory-allocation
functions}) when no longer needed.
@end deftypefun

@deftypefun ncptl_int ncptl_set_length (NCPTL_SET *@var{set})
@olindex ncptl_set_length
Return the number of
@texmath{\langle\hbox{\var{key}:\var{value}}\rangle,
<@var{key}:@var{value}>} pairs in set @var{set}.
@end deftypefun


@node Language-visible functions, Finalization functions, Unordered-set functions, Run-time library functions
@subsection Language-visible functions
@cindex functions, language-visible

The @ncptl{} language contains a number of built-in functions that
perform various operations on floating-point numbers (used when
writing to a log file or the standard output device) and integers
(used at all other times) and that determine the IDs of neighboring
tasks on a variety of topologies.  Each function occurs in two forms:
@code{ncptl_func_@var{function}}, which maps @ocode{ncptl_int}s to
@ocode{ncptl_int}s, and @code{ncptl_dfunc_@var{function}}, which maps
@code{double}s to @ocode{double}s.  @xref{Built-in functions}, for
additional details about each function's semantics.

Although some of the functions described in this section are fairly
simple, including them in the run-time library ensures that each
function returns the same value across different backends and across
different platforms.

@menu
* Integer-function descriptions::  Mapping one integer to another
* Floating-point-function descriptions::  Mapping one FP number to another
* Topology-function descriptions::  Locating nearby tasks
* Random-number-function descriptions::  Choosing numbers at random
@end menu


@node Integer-function descriptions, Floating-point-function descriptions, Language-visible functions, Language-visible functions
@subsubheading Integer functions
@cindex integer functions
@cindex functions, integer

@deftypefun ncptl_int ncptl_func_sqrt (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_sqrt (double @var{num})
@olindex ncptl_func_sqrt
@olindex ncptl_dfunc_sqrt
@ocodecf{ncptl_func_sqrt} returns the unique integer @math{x} such
that @texmath{x^2 \leq \var{num}~\wedge~ (x+1)^2 > @var{num}, x*x <=
@var{num} and (x+1)*(x+1) > @var{num}}.  @ocodecf{ncptl_dfunc_sqrt}
returns
@iftex
@texmath{\sqrt{\var{num}}, N/A}
@end iftex
@ifnottex
the square root of @var{num}
@end ifnottex
in double-precision arithmetic.
@end deftypefun

@deftypefun ncptl_int ncptl_func_cbrt (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_cbrt (double @var{num})
@olindex ncptl_func_cbrt
@olindex ncptl_dfunc_cbrt
@ocodecf{ncptl_func_cbrt} returns the unique integer @math{x} such
that @texmath{x^3 \leq \var{num}~\wedge~ (x+1)^3 > @var{num}, x*x*x <=
@var{num} and (x+1)*(x+1)*(x+1) > @var{num}}.
@ocodecf{ncptl_dfunc_cbrt} returns
@iftex
@texmath{\root 3 \of {\hbox{\var{num}}}, N/A}
@end iftex
@ifnottex
the cube root of @var{num}
@end ifnottex
in double-precision arithmetic.
@end deftypefun

@deftypefun ncptl_int ncptl_func_root (ncptl_int @var{root}, ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_root (double @var{root}, double @var{num})
@olindex ncptl_func_root
@olindex ncptl_dfunc_root
Return the @var{root}th root of a number @var{num}.
@iftex
More precisely, @ocodecf{ncptl_dfunc_root} returns @texmath{\root
{root} \of {num}, N/A} while
@end iftex
@ocodecf{ncptl_func_root} returns the largest-in-magnitude integer
@var{x} with the same sign as @var{num} such that
@texmath{|x^{root}| \leq |@var{num}|, |@var{x}^@var{root}|
<= |@var{num}|}.  Currently, @var{num} must be nonnegative but this
may change in a future release of @ncptl{}@.
@end deftypefun

@deftypefun ncptl_int ncptl_func_bits (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_bits (double @var{num})
@olindex ncptl_func_bits
@olindex ncptl_dfunc_bits
Return the minimum number of bits needed to represent a given integer.
(@var{num} is rounded up to the nearest integer in the case of
@ocodecf{ncptl_dfunc_bits}.)
@end deftypefun

@deftypefun ncptl_int ncptl_func_shift_left (ncptl_int @var{num}, ncptl_int @var{bits})
@deftypefunx double ncptl_dfunc_shift_left (double @var{num}, double @var{bits})
@olindex ncptl_func_shift_left
@olindex ncptl_dfunc_shift_left
Shift a number to the left by @var{bits} bits.  This corresponds to
multiplying @var{num} by @texmath{2^{bits}, 2^bits}.  In the case of
@ocodecf{ncptl_dfunc_shift_left}, @var{num} and @var{bits} are first
converted to @ocode{ncptl_int} values.  There are no corresponding
@ocodecf{ncptl_func_shift_right} or @ocodecf{ncptl_dfunc_shift_right}
functions because shifting right by @math{x} is defined to be
equivalent to shifting left by @math{-x}.
@end deftypefun

@deftypefun ncptl_int ncptl_func_log10 (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_log10 (double @var{num})
@olindex ncptl_func_log10
@olindex ncptl_dfunc_log10
Return
@iftex
@texmath{\log_{10} (@var{num}), N/A}
@end iftex
@ifnottex
the base-10 logarithm of @var{num}.
@end ifnottex
In the case of @ocodecf{ncptl_func_log10}, this value is rounded down
to the nearest integer.
@end deftypefun

@deftypefun ncptl_int ncptl_func_factor10 (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_factor10 (double @var{num})
@olindex ncptl_func_factor10
@olindex ncptl_dfunc_factor10
Return @var{num} rounded down to the nearest single-digit factor of a
power @w{of 10.}
@end deftypefun

@deftypefun ncptl_int ncptl_func_abs (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_abs (double @var{num})
@olindex ncptl_func_abs
@olindex ncptl_dfunc_abs
Return
@iftex
@texmath{|@var{num}|, N/A}.
@end iftex
@ifnottex
@var{num}'s absolute value.
@end ifnottex
In the case of @ocodecf{ncptl_func_log10}, this value is rounded down
to the nearest integer.
@end deftypefun

@deftypefun ncptl_int ncptl_func_power (ncptl_int @var{base}, ncptl_int @var{exponent})
@deftypefunx double ncptl_dfunc_power (double @var{base}, double @var{exponent})
@olindex ncptl_func_power
@olindex ncptl_dfunc_power
Return @var{base} raised to the power of @var{exponent}.
@end deftypefun

@deftypefun ncptl_int ncptl_func_modulo (ncptl_int @var{numerator}, ncptl_int @var{denominator})
@deftypefunx double ncptl_dfunc_modulo (double @var{numerator}, double @var{denominator})
@olindex ncptl_func_modulo
@olindex ncptl_dfunc_modulo
Return the remainder of dividing @var{numerator} by @var{denominator}.
The result is guaranteed to be a nonnegative integer.
@ocodecf{ncptl_dfunc_modulo} rounds each of @var{numerator} and
@var{denominator} down to the nearest integer before dividing and
taking the remainder.
@end deftypefun

@deftypefun ncptl_int ncptl_func_min (ncptl_int @var{count}, @dots{})
@deftypefunx double ncptl_dfunc_min (double @var{count}, @dots{})
@olindex ncptl_func_min
@olindex ncptl_dfunc_min
Return the minimum of a list of numbers.  The first argument specifies
the number of remaining arguments and must be a positive integer.
@end deftypefun

@deftypefun ncptl_int ncptl_func_max (ncptl_int @var{count}, @dots{})
@deftypefunx double ncptl_dfunc_max (double @var{count}, @dots{})
@olindex ncptl_func_max
@olindex ncptl_dfunc_max
Return the maximum of a list of numbers.  The first argument specifies
the number of remaining arguments and must be a positive integer.
@end deftypefun


@node Floating-point-function descriptions, Topology-function descriptions, Integer-function descriptions, Language-visible functions
@subsubheading Floating-point functions
@cindex floating-point functions
@cindex functions, floating-point

@deftypefun ncptl_int ncptl_func_floor (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_floor (double @var{num})
@olindex ncptl_func_floor
@olindex ncptl_dfunc_floor
Return
@iftex
@texmath{\lfloor @var{num} \rfloor, N/A}.
@end iftex
@ifnottex
the floor of @var{num}.
@end ifnottex
(This is the identity function in the case of
@ocodecf{ncptl_func_floor}.)
@end deftypefun

@deftypefun ncptl_int ncptl_func_ceiling (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_ceiling (double @var{num})
@olindex ncptl_func_ceiling
@olindex ncptl_dfunc_ceiling
Return
@iftex
@texmath{\lceil @var{num} \rceil, N/A}.
@end iftex
@ifnottex
the ceiling of @var{num}.
@end ifnottex
(This is the identity function in the case of
@ocodecf{ncptl_func_ceiling}.)
@end deftypefun

@deftypefun ncptl_int ncptl_func_round (ncptl_int @var{num})
@deftypefunx double ncptl_dfunc_round (double @var{num})
@olindex ncptl_func_round
@olindex ncptl_dfunc_round
Return @var{num} rounded to the nearest integer.  (This is the
identity function in the case of @ocodecf{ncptl_func_round}.)
@end deftypefun


@node Topology-function descriptions, Random-number-function descriptions, Floating-point-function descriptions, Language-visible functions
@subsubheading Topology functions
@cindex topology functions
@cindex functions, topology

In the following functions, the @samp{dfunc} versions merely cast
their arguments to @ocode{ncptl_int}s and call the corresponding
@samp{func} versions.

@deftypefun ncptl_int ncptl_func_tree_parent (ncptl_int @var{task}, ncptl_int @var{arity})
@deftypefunx double ncptl_dfunc_tree_parent (double @var{task}, double @var{arity})
@olindex ncptl_func_tree_parent
@olindex ncptl_dfunc_tree_parent
Return task @var{task}'s parent in an @var{arity}-ary tree.
@end deftypefun

@deftypefun ncptl_int ncptl_func_tree_child (ncptl_int @var{task}, ncptl_int @var{child}, ncptl_int @var{arity})
@deftypefunx double ncptl_dfunc_tree_child (double @var{task}, double @var{child}, double @var{arity})
@olindex ncptl_func_tree_child
@olindex ncptl_dfunc_tree_child
Return child @var{child} of task @var{task} in an @var{arity}-ary tree.
@end deftypefun

@deftypefun ncptl_int ncptl_func_mesh_coord (ncptl_int var{task}, ncptl_int @var{coord}, ncptl_int @var{width}, ncptl_int @var{height}, ncptl_int @var{depth})
@deftypefunx double ncptl_dfunc_mesh_coord (double var{task}, double @var{coord}, double @var{width}, double @var{height}, double @var{depth})
@olindex ncptl_func_mesh_coord
@olindex ncptl_dfunc_mesh_coord
Return task @var{task}'s @math{x} coordinate (@math{@var{coord}=0}),
@math{y} coordinate (@math{@var{coord}=1}), or @math{z} coordinate
(@math{@var{coord}=2}) on a @texmath{@var{width} \times @var{height}
\times @var{depth}, @var{width}*@var{height}*@var{depth}} mesh (or
torus).
@end deftypefun

@deftypefun ncptl_int ncptl_func_mesh_neighbor (ncptl_int @var{width}, ncptl_int @var{height}, ncptl_int @var{depth}, ncptl_int @var{xtorus}, ncptl_int @var{ytorus}, ncptl_int @var{ztorus}, ncptl_int @var{task}, ncptl_int @var{xdelta}, ncptl_int @var{ydelta}, ncptl_int @var{zdelta})
@deftypefunx double ncptl_dfunc_mesh_neighbor (double @var{width}, double @var{height}, double @var{depth}, double @var{xtorus}, double @var{ytorus}, double @var{ztorus}, double @var{task}, double @var{xdelta}, double @var{ydelta}, double @var{zdelta})
@olindex ncptl_func_mesh_neighbor
@olindex ncptl_dfunc_mesh_neighbor
Return one of task @var{task}'s neighbors---not necessarily an
immediate neighbor---on a 3-D mesh or torus.  For the following
explanation, assume that task @var{task} lies at coordinates @math{(x,
y, z)} on a @texmath{@var{width} \times @var{height} \times
@var{depth}, @var{width}*@var{height}*@var{depth}} mesh or torus.  In
the mesh case (@math{@var{xtorus}=@var{ytorus}=@var{ztorus}=0}), the
value returned is the task ID corresponding to coordinates
@math{(x+@var{xdelta}, y+@var{ydelta}, z+@var{zdelta})}.  In the
full-torus case (@math{@var{xtorus}=@var{ytorus}=@var{ztorus}=1}), the
value returned is the task ID corresponding to coordinates
@iftex
@math{\big((x+@var{xdelta}) \hbox{~mod~} @var{width}, (y+@var{ydelta})
\hbox{~mod~} @var{height}, (z+@var{zdelta}) \hbox{~mod~}
@var{depth}\big)}.
@end iftex
@ifnottex
@math{((x+@var{xdelta}) mod @var{width}, (y+@var{ydelta}) mod
@var{height}, (z+@var{zdelta}) mod @var{depth})}.
@end ifnottex
@end deftypefun

Note that there are no 1-D or 2-D grid functions.  Instead, the
appropriate 3-D function should be used with @var{depth} and---in the
1-D case---@var{height} set to @samp{1}.

@deftypefun ncptl_int ncptl_func_knomial_parent (ncptl_int @var{task}, ncptl_int @var{arity}, ncptl_int @var{numtasks})
@deftypefunx double ncptl_dfunc_knomial_parent (double @var{task}, double @var{arity}, double @var{numtasks})
@olindex ncptl_func_knomial_parent
@olindex ncptl_dfunc_knomial_parent
Return task @var{task}'s parent in an @var{arity}-nomial tree of
@var{numtasks} tasks.
@end deftypefun

@deftypefun ncptl_int ncptl_func_knomial_child (ncptl_int @var{task}, ncptl_int @var{child}, ncptl_int @var{arity}, ncptl_int @var{numtasks}, ncptl_int @var{count_only})
@deftypefunx double ncptl_dfunc_knomial_child (double @var{task}, double @var{child}, double @var{arity}, double @var{numtasks}, double @var{count_only})
@olindex ncptl_func_knomial_child
@olindex ncptl_dfunc_knomial_child
If @var{count_only} is @samp{0}, return task @var{task}'s
@var{child}th child in an @var{arity}-nomial tree of @var{numtasks}
tasks.  If @var{count_only} is @samp{1}, return the number of children
task @var{task} has in an @var{arity}-nomial tree of @var{numtasks}
tasks.
@end deftypefun


@node Random-number-function descriptions,  , Topology-function descriptions, Language-visible functions
@subsubheading Random-number functions
@cindex random numbers
@cindex functions, random-number

@deftypefun ncptl_int ncptl_func_random_uniform (ncptl_int @var{lower_bound}, ncptl_int @var{upper_bound})
@deftypefunx double ncptl_dfunc_random_uniform (double @var{lower_bound}, double @var{upper_bound})
@olindex ncptl_func_random_uniform
@olindex ncptl_dfunc_random_uniform
Return a number in the interval [@var{lower_bound}, @var{upper_bound})
selected at random with a uniform distribution.
@end deftypefun

@deftypefun ncptl_int ncptl_func_random_gaussian (ncptl_int @var{mean}, ncptl_int @var{stddev})
@deftypefunx double ncptl_dfunc_random_gaussian (double @var{mean}, double @var{stddev})
@olindex ncptl_func_random_gaussian
@olindex ncptl_dfunc_random_gaussian
Return a number selected at random from a Gaussian distribution with
mean @var{mean} and standard deviation @var{stddev}.
@end deftypefun

@deftypefun ncptl_int ncptl_func_random_poisson (ncptl_int @var{mean})
@deftypefunx double ncptl_dfunc_random_poisson (double @var{mean})
@olindex ncptl_func_random_poisson
@olindex ncptl_dfunc_random_poisson
Return an integer selected at random from a Poisson distribution with
mean @var{mean} and standard deviation @texmath{\sqrt{@var{mean}},
sqrt(@var{mean})}.
@end deftypefun

@deftypefun ncptl_int ncptl_func_random_pareto (ncptl_int @var{shape}, ncptl_int @var{lower_bound}, ncptl_int @var{upper_bound})
@deftypefunx double ncptl_dfunc_random_pareto (double @var{shape}, double @var{lower_bound}, double @var{upper_bound})
@olindex ncptl_func_random_pareto
@olindex ncptl_dfunc_random_pareto
If @var{lower_bound}@math{=}@var{upper_bound}, return a value selected
at random from a Pareto distribution with shape @var{shape} and scale
@var{lower_bound}.  If @var{lower_bound}@texmath{\neq,
<>}@var{upper_bound}, return a value selected at random from a bounded
Pareto distribution with shape @var{shape} and bounded by the range
[@var{lower_bound}, @var{upper_bound}].
@end deftypefun


@node Finalization functions,  , Language-visible functions, Run-time library functions
@subsection Finalization functions
@cindex finalization functions
@cindex functions, finalization

The following function should be called towards the end of the generated
code's execution.

@deftypefun void ncptl_finalize (void)
@olindex ncptl_finalize
Shut down the @ncptl{} run-time library.  No run-time library
functions should be invoked after @ocodecf{ncptl_finalize}.
@end deftypefun

@deftypefun void ncptl_fatal (char *@var{format}, @dots{})
@olindex ncptl_fatal
Output an error message and abort the program.  @ocodecf{ncptl_fatal}
takes the same types of arguments as C's @ocodecf{printf} routine.
@end deftypefun



@node Tips and Tricks, Troubleshooting, Implementation, Top
@chapter Tips and Tricks
@cindex tips and Tricks

The following sections present some ways to make better use of
@ncptl{} in terms of producing simpler, more efficient programs or
being able to run on complex computer systems.

@menu
* Using out-of-bound task IDs to simplify code::  Exploiting dropped messages
* Proper use of conditionals::  When and when not to use IF...THEN
* Memory efficiency::           Reducing programs' memory usage
* Cross-compilation::           Compiling on one architecture to run on another
* Implicit dynamic-library search paths::  Not needing to set LD_LIBRARY_PATH
* Running without installing::  Compiling right from the build directory
* Reporting configuration information::  Self-describing coNCePTuaL libraries
@end menu


@node Using out-of-bound task IDs to simplify code, Proper use of conditionals, Tips and Tricks, Tips and Tricks
@section Using out-of-bound task IDs to simplify code
@cindex tasks

@xref{Task descriptions}, mentions a language feature that can
substantially simplify @ncptl{} programs: Operations involving
out-of-bound task IDs are silently ignored.  The beauty of this
feature is that it reduces the need for special cases at network
boundaries.  Consider, for example, a simple pipeline pattern in which
each task in turn sends a message to the subsequent task:

@example
ALL TASKS t SEND A 64 DOUBLEWORD MESSAGE TO TASK t+1.
@end example

Because implicit receives are posted before the corresponding sends
(@pxref{Sending}), all tasks except @w{task 0} start by posting a
blocking receive.  (No task is sending to @w{task 0}.)  @w{Task 0} is
therefore free to send a message to @w{task 1}.  Receipt of that
message unblocks @w{task 1,} who then sends a message to @w{task 2},
thereby unblocking @w{task 3}, and so forth.  Without needing an
explicit special case in the program, task @samp{num_tasks-1} receives
a message from task @samp{num_tasks-2} but does not attempt to send a
message to nonexistent task @samp{num_tasks}, thanks to the rule that
communication with nonexistent tasks turns into a no-op (i.e., is
elided from the program).

As a more complex variation of the same program, consider a wavefront
communication pattern that progresses from the upper-left corner of a
mesh to the lower-right corner.  Such a pattern can be expressed in
just four lines of @ncptl{} (receive left, receive up, send right,
send down) by relying on the property that communication with a
nonexistent task is simply not executed:

@example
TASK MESH_NEIGHBOR(src, xsize, +1, ysize,  0) RECEIVES A
  64 DOUBLEWORD MESSAGE FROM ALL TASKS src THEN
TASK MESH_NEIGHBOR(src, xsize,  0, ysize, +1) RECEIVES A
  64 DOUBLEWORD MESSAGE FROM ALL TASKS src THEN
ALL TASKS src SEND A 64 DOUBLEWORD MESSAGE TO
  UNSUSPECTING TASK MESH_NEIGHBOR(src, xsize, +1, ysize,  0) THEN
ALL TASKS src SEND A 64 DOUBLEWORD MESSAGE TO
  UNSUSPECTING TASK MESH_NEIGHBOR(src, xsize,  0, ysize, +1).
@end example

To understand the preceding program recall that @keyw{MESH_NEIGHBOR}
returns @samp{-1} for nonexistent neighbors.  Because @samp{-1} is
outside of the range [0, @keyw{num_tasks}) communication with a
nonexistent neighbor is ignored.  To help the reader understand the
preceding program, we present a trace of the events it posts as it
runs with a @texmath{2 \times 2, 2 by 2} arrangement of tasks:

@example
[TRACE] phys: 0 | virt: 0 | action: SEND | event: 1 / 2 | lines: 3 - 3
[TRACE] phys: 1 | virt: 1 | action: RECV | event: 1 / 2 | lines: 1 - 1
[TRACE] phys: 2 | virt: 2 | action: RECV | event: 1 / 2 | lines: 2 - 2
[TRACE] phys: 3 | virt: 3 | action: RECV | event: 1 / 2 | lines: 1 - 1

[TRACE] phys: 0 | virt: 0 | action: SEND | event: 2 / 2 | lines: 4 - 4
[TRACE] phys: 1 | virt: 1 | action: SEND | event: 2 / 2 | lines: 4 - 4

[TRACE] phys: 2 | virt: 2 | action: SEND | event: 2 / 2 | lines: 3 - 3

[TRACE] phys: 3 | virt: 3 | action: RECV | event: 2 / 2 | lines: 2 - 2
@end example

The @backend{c_trace} backend (@pxref{The c_trace backend}) was used
to produce that trace.  To increase clarity, we manually added blank
lines to group concurrent events (i.e., there is no significance to
the order of the @code{TRACE} lines within each group).  The important
thing to notice is that there are exactly four receives and exactly
four sends:

@itemize @bullet
@item
Although all tasks are instructed to receive a message from the left,
only @w{tasks 1} @w{and 3} actually do so;

@item
although all tasks are instructed to receive a message from above,
only @w{tasks 2} @w{and 3} actually do so;

@item
although all tasks are instructed to send a message to the right, only
@w{tasks 0} @w{and 2} actually do so; and,

@item
although all tasks are instructed to send a message downwards, only
@w{tasks 0} @w{and 1} actually do so.
@end itemize

@noindent
Because communication with nonexistent tasks is elided at program
initialization time there is no run-time cost for such operations---as
evidenced by the @backend{c_trace} output presented above.
Furthermore, there is no reliance on the backend to drop messages from
nonexistent senders or to nonexistent receivers; it is perfectly safe
to utilize no-op'ed communcation in any @ncptl{} program and when
using any backend.


@node Proper use of conditionals, Memory efficiency, Using out-of-bound task IDs to simplify code, Tips and Tricks
@section Proper use of conditionals
@cindex conditionals

@ncptl{} supports two forms of conditional execution: conditional
expressions (@pxref{Arithmetic expressions}) and conditional
statements (@pxref{Conditional execution}).  From the perspective of
code readability and ``thinking in @ncptl{}'' it is generally
preferable to use restricted identifiers (@pxref{Restricted
identifiers}) to select groups of tasks rather than a loop with a
conditional as would be typical in other programming languages.  For
example, consider the following code in which certain even-numbered
tasks each send a message to the right:

@example
FOR EACH evtask IN @{0, ..., num_tasks-1@}
  IF evtask IS EVEN /\ evtask MOD 3 <> 2 THEN
    TASK evtask SENDS A 64 BYTE MESSAGE TO TASK evtask+1
@end example

@noindent
While the preceding control flow is representative of that in other
programming languages, @ncptl{} can express the same communication
pattern without needing either a loop or an explicit conditional
statement:

@example
TASK evtask SUCH THAT evtask IS EVEN /\ evtask MOD 3 <> 2 SENDS A 64
BYTE MESSAGE TO TASK evtask+1
@end example

One situation in which conditional statements do not have a convenient
analogue is when a program selects among multiple disparate
subprograms based on a command-line parameter:

@cartouche
@example
func IS "Operation to perform (1=@var{op1}; 2=@var{op2}; 3=@var{op3})" AND COMES FROM
"--function" OR "-f" WITH DEFAULT 1.

ASSERT THAT "the function must be 1, 2, or 3" WITH func>=1 /\ func<=3.

IF func = 1 THEN @{
  @i{Perform operation @var{op1}.}
@}
OTHERWISE IF func = 2 THEN @{
  @i{Perform operation @var{op2}.}
@}
OTHERWISE IF func = 3 THEN @{
  @i{Perform operation @var{op3}.}
@}
@end example
@end cartouche


@node Memory efficiency, Cross-compilation, Proper use of conditionals, Tips and Tricks
@section Memory efficiency
@cindex memory efficiency

As described in @ref{Generated code}, the @backend{c_generic} backend
(and therefore all derived backends) generates programs that run by
executing a sequence of events in an event list.  While this form of
program execution makes it possible to hoist a significant amount of
computation out of the timing loop, it does imply that a program's
memory requirements are proportional to the number of statements that
the program executes.

@ncptl{}'s memory usage can be reduced by taking advantage of repeat
counts within statements that support such a construct.  The
language's @nonterm{send_stmt} (@pxref{Sending}),
@nonterm{receive_stmt} (@pxref{Receiving}), and @nonterm{touch_stmt}
(@pxref{Touching memory}) are all examples of statements that accept
repeat counts.  For other statements and for groups of statements that
repeat, the @keyw{FOR}@dots{}@keyw{REPETITIONS} statement produces a
single @ocode{EV_REPEAT} event followed by a single instance of the
events in the loop body.  This technique is valid because @ncptl{}
knows @i{a priori} that every iteration is identical to every other
iteration.  In contrast, the more general @keyw{FOR EACH} statement
can induce different behavior each iteration based on the value of the
loop variable so programs must conservatively instantiate the events
in the loop body for every iteration.  Consider the following
examples:

@table @emph
@item Least efficient:
@samp{FOR EACH i IN @{1, ..., 1000@} TASK 0 TOUCHES A 1 WORD MEMORY REGION} @*
(1000 @ocode{EV_TOUCH} events on @w{task 0})

@item More efficient:
@samp{FOR 1000 REPETITIONS TASK 0 TOUCHES A 1 WORD MEMORY REGION} @*
(an @ocode{EV_REPEAT} event and an @ocode{EV_TOUCH} event on @w{task 0})

@item Most efficient:
@samp{TASK 0 TOUCHES A 1 WORD MEMORY REGION 1000 TIMES} @*
(one @ocode{EV_TOUCH} event on @w{task 0})

@sp 1

@item Least efficient:
@samp{FOR EACH i IN @{1, ..., 1000@} TASK 0 SENDS A 32 KILOBYTE
MESSAGE TO TASK 1} @*
(1000 @ocode{EV_SEND} events on @w{task 0} and 1000 @ocode{EV_RECV}
events on @w{task 1})

@item More efficient:
@samp{FOR 1000 REPETITIONS TASK 0 SENDS A 32 KILOBYTE MESSAGE TO TASK 1} @*
(an @ocode{EV_REPEAT} event and an @ocode{EV_SEND} event on @w{task 0}
plus an @ocode{EV_REPEAT} event and an @ocode{EV_RECV} event on
@w{task 1})

@item Most efficient:
@samp{TASK 0 SENDS 1000 32 KILOBYTE MESSAGES TO TASK 1} @*
(currently the same as the above although a future release of @ncptl{}
may reduce this to a single @ocode{EV_SEND} event on @w{task 0} and a
single @ocode{EV_RECV} event on @w{task 1})
@end table


@node Cross-compilation, Implicit dynamic-library search paths, Memory efficiency, Tips and Tricks
@section Cross-compilation
@cindex cross-compilation

Some experimental architectures lack native compilers and therefore
require programs to be compiled on an architecturally distinct
front-end machine.  @ncptl{} can be configured to support such an
arrangement.  As an example, we follow how @ncptl{} was recently
configured to run on a Cray/SNL @cncp{Red Storm} prototype.  The
@cncp{Red Storm} prototype requires programs to be cross-compiled from
a compile server then launched from an execution server to run on the
compute nodes.  The CPUs in all three node types use the @cncp{x86-64}
architecture but the compile server and execution server run @Linux{}
while the compute nodes run the lightweight @cncp{Catamount} kernel.
Cross-compilation is necessary to prevent the @configure{} script
that runs on the compile server from attempting to execute small
programs to test run-time features---these would be guaranteed to
fail.

@configure{} (@pxref{configure}) enters cross-compilation mode if the
build system---specified with @copt{build}---has a different CPU,
comes from a different vendor, or runs a different operating system
from the execution system---specified with @copt{host}.  The
@filespec{config.guess} script outputs the build-system type in the
form @var{CPU}-@var{vendor}-@var{operating system}:

@cartouche
@example
% ./config.guess
x86_64-unknown-linux-gnu
@end example
@end cartouche

@noindent
(That is, the CPU architecture is @samp{x86_64}; the computer vendor
is @samp{unknown}; and, the operating system is @samp{linux-gnu}.)

As a special case of cross-compilation, if the build system and
execution system utilize the same CPU and operating system@footnote{As
long as the host and build operating systems have moderately similar
interfaces @w{(e.g., both} are Unix-like) and the same CPU
architecture @w{(e.g., both} are @cncp{x86-64} variants),
@copt{with-cross-compilation} should be applicable.}  (but presumably
differ in terms of other feature), @configure{} provides a
@copt{with-cross-compilation} option to force a cross-compile.  The
alternative is to modify one of the build-system name components; best
is to modify the vendor component as that's used solely for
informational purposes.  For our @cncp{Red Storm} configuration (which
predated the @copt{with-cross-compilation} option) we renamed
@var{vendor} from @samp{unknown} to @samp{cray}.

Because @filespec{configure} assumes it cannot execute small test
programs on the execution system, it is unable to determine valid
memory-buffer alignments.  Consequently, the @copt{with-alignment}
option must also be passed to @filespec{configure} to specify
explicitly the minimum number of bytes at which data must be aligned.
(If not specified, the minimum alignment defaults to @samp{8}.)  We
know @i{a priori} that the @cncp{x86-64} architecture can support
byte-aligned data.  Hence, we specify @coptargs{with-alignment, 1}.

A command line like the following was used to configure @ncptl{} for
the @cncp{Red Storm} prototype:

@cartouche
@example
% ./configure --build=x86_64-unknown-linux-gnu --host=x86_64-cray-linux-gnu
    --with-alignment=1 CC=mpicc
@end example
@end cartouche

Once @ncptl{} is configured to cross-compile, there is nothing special
about performing the compilation itself.  The @kcmd{make} command runs
unmodified from its description in @ref{make}.

Running @kcmd{make check} can be tricky because it involves both
compilation and execution.  As stated previously, these cannot be
performed on the same servers in the @cncp{Red Storm} prototype.  The
solution is first to run @kcmd{make check} on the compile server.
This compiles all of the @ncptl{} regression tests---and
unsuccessfully attempts to run them.  Then, when @kcmd{make check} is
run on the execution server it does not need to compile any of the
tests (which it can't do successfully, anyway) but can simply run each
of them.

One catch is that the @cncp{Red Storm} execution server cannot
directly run compute-node programs.  Rather, it needs to spawn a job
launcher (@kcmd{yod}) for each test program.  The mechanism for doing
this is the @envvar{TESTS_ENVIRONMENT} variable, which @kcmd{make
check} prepends to every command it executes.  We were therefore able
to regression-test the @ncptl{} run-time library on the @cncp{Red
Storm} prototype with the following command:

@cartouche
@example
% make TESTS_ENVIRONMENT="yod -list 4" check
@end example
@end cartouche

If the system for which you're cross-compiling is unable to run
@cncp{Python} or unable to build the interpreter-based backends, you might
consider building @ncptl{} twice---cross-compiled for the target
system and compiled regularly for the front-end system.  The
@copt{prefix} option to @filespec{configure} (@pxref{configure})
specifies the top-level directory for the @ncptl{} installation.


@node Implicit dynamic-library search paths, Running without installing, Cross-compilation, Tips and Tricks
@section Implicit dynamic-library search paths
@cindex dynamic libraries

By default, @ncptl{} installs both a static and dynamic library with
the dynamic library taking precedence (at least on most Unix and
Unix-like operating systems).  While dynamic libraries offer a number
of benefits---such as not requiring applications to be relinked every
time a library is upgraded---one inconvenience is the need to set the
@envvar{LD_LIBRARY_PATH} environment variable to point to the @ncptl{}
library directory if the @ncptl{} run-time library is not installed in
a standard location @w{(e.g., @file{/usr/lib})}.

An alternative to setting @envvar{LD_LIBRARY_PATH} is to specify the
target library directory at configuration time via the
@envvar{LDFLAGS} variable and let the linker embed that directory into
the @ncptl{} run-time library's dynamic search path.  Many linkers
accept a @copts{rpath} option for exactly that purpose.  With the
@GNU{} @w{C compiler} and linker the appropriate option is
@kbd{LDFLAGS="-Wl,-rpath,@var{directory}"} (e.g.,
@samp{LDFLAGS="-Wl,-rpath,/usr/local/ncptl/lib"}).  Other compilers
may have analogous mechanisms for passing flags directly to the
linker.

@node Running without installing, Reporting configuration information, Implicit dynamic-library search paths, Tips and Tricks
@section Running without installing
@cindex installation

You can compile @ncptl{} programs without having first to do a
@kcmd{make install} by using the same mechanism as was discussed in
@ref{Implicit dynamic-library search paths}.

First, @cncp{Libtool} builds the @ncptl{} run-time library in the
@filespec{.libs} subdirectory.  Hence, you should add
@samp{LDFLAGS="-L`pwd`/.libs -Wl,-rpath,`pwd`/.libs"} to the
@configure{} command line (@pxref{configure}) to point both the static
and dynamic linkers to the @ncptl{} @cncp{build directory}.

Second, @ncptl{}-generated C code specifies @samp{#include
<ncptl/ncptl.h>}.  To ensure that the generated code can find
@filespec{ncptl.h} you should add @samp{CPPFLAGS="-I`pwd`"} to the
@configure{} command line to point the C compiler to the @ncptl{}
@cncp{build directory}.  Then, create a symbolic link from the
@ncptl{} @cncp{build directory} to an @file{ncptl} directory by
running @kbd{ln -s `pwd` ncptl} from the build directory.

After running @configure{} and @kcmd{make}, you can compile @ncptl{}
programs by invoking the compiler as @kbd{./ncptl.py} instead of the
usual @kcmd{ncptl}.


@node Reporting configuration information,  , Running without installing, Tips and Tricks
@section Reporting configuration information
@cindex configuration information

On platforms that support it, the @ncptl{} run-time library is also an
executable program that can be run from the command line.  Executing
the library outputs to the standard output device a complete log-file
prologue and epilogue but no data.@footnote{This is the same
information produced by @kcmd{make empty.log} (@pxref{make}).}  This
feature makes it quite convenient to determine all of the
configuration options, compiler features, etc.@: that were used to
build the run-time library.


@node Troubleshooting, Reserved Words, Tips and Tricks, Top
@chapter Troubleshooting
@cindex troubleshooting

In any complex system, things are bound to go wrong.  The following
sections present solutions to various problems that have been
encountered when building @ncptl{} and running @ncptl{} programs.

@menu
* Problems with configure::     What to do when configure fails
* Problems with make::          What to do when make fails
* Problems running::            What to do when a generated program fails
* When all else fails::         Contacting the coNCePTuaL developers
@end menu


@node Problems with configure, Problems with make, Troubleshooting, Troubleshooting
@section Problems with configure

For typical @ncptl{} usage, the most important function of the
@filespec{configure} script is to prepare the system to build the
@ncptl{} run-time library.  @ncptl{}'s functionality is severely
restricted without that library.  This section provides information to
help ensure that configuration succeeds.

@menu
* Interpreting configure warnings::  General problem-solving instructions
* PRId64 is not a valid printf conversion specifier::  A common problem on BSD
* present but cannot be compiled::  Warning messages involving header files
* Checking maximum line length is slow::  A pathologically slow configure test
* configure is slow::           All configure tests are pathologically slow
* Problems with ``C compiler used for Python extension modules''::  Can't link
* Manual configuration::        Bypassing configure entirely
@end menu


@node Interpreting configure warnings, PRId64 is not a valid printf conversion specifier, Problems with configure, Problems with configure
@subsection Interpreting configure warnings

The @filespec{configure} script performs a large number of tests to
ensure that @ncptl{} will compile properly and function as expected.
In particular, any missing or improperly functioning feature upon
which the C run-time library relies causes @configure{} to issue a
@samp{not building the C run-time library} warning.  Without its
run-time library, @ncptl{}'s functionality is severely limited so it's
worth every effort to get @configure{} to build that.

Like all @cncp{Autoconf} scripts, @filespec{configure} logs detailed
information to a @filespec{config.log} file.  As a general diagnostic
technique one should search for puzzling output in
@filespec{config.log} and examine the surrounding context.  For
instance, on one particular system, @configure{} output @samp{no}
following @samp{checking if we can run a trivial program linked with
"-lrt -lm -lpopt "} and then refused to build the run-time library.
The following relevant lines appeared in @filespec{config.log}:

@cartouche
@example
configure:12845: checking if we can run a trivial program linked with "-lrt
-lm -lpopt "
configure:12862: /usr/local/bin/gcc  -o conftest -g -O2   conftest.c -lrt
-lm -lpopt  >&5
configure:12865: $? = 0
configure:12867: ./conftest
@fiindex libpopt.so
ld.so.1: ./conftest: fatal: libpopt.so.0: open failed: No such file or
directory
./configure: line 1:  5264 Killed                  ./conftest$ac_exeext
configure:12870: $? = 137
configure: program exited with status 137
configure: failed program was:
#line 12851 "configure"
#include "confdefs.h"

int
main (int argc, char *argv[])
@{
  return 0;
@}
configure:12879: result: no
@end example
@end cartouche

@fiindex libpopt.so
Note the error message from @file{ld.so.1} about @file{libpopt.so.0}
not being found.  Further investigation revealed that although
@file{/usr/local/bin/gcc} knew to look in @file{/usr/local/lib/} for
shared libraries, that directory was not in the search path utilized
by @file{ld.so.1}.  Consequently, it couldn't find
@file{/usr/local/lib/libpopt.so.0}.  The solution in this case was to
add @file{/usr/local/lib/} to the @envvar{LD_LIBRARY_PATH} environment
variable before running @configure{}.

In general, @filespec{config.log} should be the first place to look
when trying to interpret warnings issued by @configure{}.
Furthermore, note that certain command-line options to @configure{}
(@pxref{configure}) may help bypass problematic operations that the
script stumbles over.


@node PRId64 is not a valid printf conversion specifier, present but cannot be compiled, Interpreting configure warnings, Problems with configure
@subsection @samp{PRId64 is not a valid printf conversion specifier}

The following configuration warning was encountered on various BSD
Unix systems (@w{OpenBSD 3.4} and @w{FreeBSD 4.10-BETA}, both IA-32)
and inhibited the building of the @ncptl{} run-time library:

@cartouche
@example
PRId64 is not a valid printf conversion specifier for values of type int64_t
@end example
@end cartouche

@cindex quotes
The @filespec{config.log} file indicated the source of the problem was
a @samp{syntax error before `PRId64'} that was reported when
compiling a sample program.  A brief search revealed that the
@ocode{PRId64} macro is not defined in any of the standard C header
files on the systems in question.  The solution turned out to be to
configure with @configure{--with-printf-format='"lld"'} to instruct
the C compiler to use @ocodecf{printf} format strings such as
@samp{%lld} when outputting 64-bit signed integers.  The extra pair of
double quotes is required because the conversion specifier is used in
constructs like the following:

@example
printf ("The number is %10" @var{conversion-specifier} "!\n", num);
@end example

@noindent
Most---but apparently not all---C compilers define the @ocode{PRId64}
macro (``@code{PRI}nt signed @code{d}ecimal number of length
@w{@code{64} bits}'') in one the standard header files.  Typical
values of @ocode{PRId64} include the strings @code{"lld"} and
@code{"ld"}.


@node present but cannot be compiled, Checking maximum line length is slow, PRId64 is not a valid printf conversion specifier, Problems with configure
@subsection Header is @samp{present but cannot be compiled}

On some platforms @configure{} may output one or more warnings of the
following form:

@example
WARNING: @var{filename}.h: present but cannot be compiled
WARNING: @var{filename}.h:     check for missing prerequisite headers?
WARNING: @var{filename}.h: see the Autoconf documentation
WARNING: @var{filename}.h:     section "Present But Cannot Be Compiled"
WARNING: @var{filename}.h: proceeding with the preprocessor's result
WARNING: @var{filename}.h: in the future, the compiler will take precedence
WARNING:     ## ----------------------------- ##
WARNING:     ## Report this to pakin@@lanl.gov ##
WARNING:     ## ----------------------------- ##
@end example

Typically, such warnings indicate that the header file in question was
written for one compiler but a different compiler is being used to
build @ncptl{}@.  Unless the header file in question poses problems
during the run of @kcmd{make}, the @samp{present but cannot be
compiled} warnings can be ignored and there is no need to report the
compiler-preprocessor mismatch to the e-mail address shown.


@node Checking maximum line length is slow, configure is slow, present but cannot be compiled, Problems with configure
@subsection Slow @samp{checking the maximum length of command line arguments...}

Recent versions of @cncp{Libtool} need to know the maximum supported
command-line length.  Normally, @filespec{configure} determines this
value by invoking a test script with successively longer command lines
until such an invocation fails.  On most platforms, the maximum
command-line length is determined almost instantaneously.  However, on
one test system, a 600@dmn{MHz} @i{x}86 running the original---not
@GNU{}---@Bourne{} shell under Solaris, @configure{} was stuck
@samp{checking the maximum length of command line arguments...} for
approximately @w{45 @emph{minutes}}.

Inspecting the @filespec{configure} script revealed that the result of
executing the length-checking code in @filespec{configure} is an
assignment to the @ocode{lt_cv_sys_max_cmd_len} shell variable.
Consequently, running @configure{lt_cv_sys_max_cmd_len=8192} (or some
other conservative estimate of the maximum command-line length) caused
@configure{} to skip the unduly slow length-checking test and use the
given value instead.


@node configure is slow, Problems with ``C compiler used for Python extension modules'', Checking maximum line length is slow, Problems with configure
@subsection @samp{configure} is slow

On a few systems, @configure{} has been observed to take an extremely
long time to run.  A common source of the problem is a slow
filesystem.  During the course of its execution the
@filespec{configure} script creates and compiles a large number of
small files.  If the current directory resides in a filesystem that
exhibits poor small-file performance, then this may explain why
@configure{} runs slowly.  Try to configure @ncptl{} from a local
filesystem @w{(e.g., @file{/tmp})} and see if it runs faster.

A second source of poor @ncptl{} configuration speed regards poor
implementations of the @Bourne{} shell.  One test system, a
1.9@dmn{GHz} PowerPC running the original---not @GNU{}---@Bourne{}
shell under AIX, took several @emph{hours} to run @configure{} to
completion.  Fortunately, the system adminstrator had installed the
@GNU{} Bourne Again shell (@filespec{bash}), which does not exhibit
the same poor performance as the default @Bourne{} shell.
@configure{} can be instructed to use @filespec{bash}---or any
@Bourne{}-compatible shell---by setting the @envvar{CONFIG_SHELL}
environment variable:

@cartouche
@example
env CONFIG_SHELL=/usr/local/bin/bash ./configure
@end example
@end cartouche

The preceding command reduced configuration time from over two hours
to under two minutes.

@node Problems with ``C compiler used for Python extension modules'', Manual configuration, configure is slow, Problems with configure
@subsection Problems with @samp{C compiler used for Python extension modules}
@cindex Python interface, failure to build
@cindex can't link against the output of gcc

The following message from @filespec{configure} is not uncommon:

@example
 * Not building the Python interface to the coNCePTuaL run-time
   library because the C compiler used for Python extension modules
   (gcc -pthread) can't link against the output of gcc
@end example

@noindent
Without the @cncp{Python} interface, none of the @cncp{Python}-based
backends can be built, either:

@example
 * Not installing the coNCePTuaL interpreter because it depends upon
   the Python interface to the coNCePTuaL run-time library
 * Not installing the statistics backend because it depends upon the
   coNCePTuaL interpreter
 * Not installing the PICL backend because it depends upon the
   coNCePTuaL interpreter
 * Not installing the Paraver backend because it depends upon the
   coNCePTuaL interpreter
 * Not installing the LaTeX visualization backend because it depends
   upon the coNCePTuaL interpreter
@end example

Note that @ncptl{} is still quite usable without the
@cncp{Python}-based backends; the C+@MPI{} backend (@pxref{The c_mpi
backend}), for example, does not rely on @cncp{Python}.

A typical cause of the @samp{can't link} message is that the
@filespec{configure} script is unable to locate the @cncp{Python}
development files that are needed to build a @cncp{Python} module.
Most @cncp{Python} installations exclude the development files by
default, requiring that they be installed separately.  In some
@Linux{} distributions these files are provided by a package with a
name like @file{python-dev}.  A key file to look for is
@filespec{Python.h}.  If @configure{} cannot find @filespec{Python.h},
the @samp{can't link} message will almost certainly appear.


@node Manual configuration,  , Problems with ``C compiler used for Python extension modules'', Problems with configure
@subsection Manual configuration
@cindex manual configuration
@cindex configuration, manual

One of the most important by-products of running @configure{} is a
@filespec{config.h} file that is used to build the @ncptl{} run-time
library.  If the approach outlined in @ref{Interpreting configure
warnings} proves unable to convince @ncptl{} to build the library or
other component, it may be possible to address the failed tests
manually by editing any incorrect definitions in @filespec{config.h}.
In addition, running @configure{} with the
@copt{enable-broken-components} option will force @kcmd{make} to
attempt to build and install @emph{everything}, no matter how unlikely
the prospects of success are.  You may need to @kcmd{make} individual
rules from the makefile in order to skip over unsalvageable parts of
the build process.

The @copt{with-header-code} option to @filespec{configure} lets you
specify a single line of C code to insert into every test file that
@filespec{configure} generates and also into the header files used to
build the run-time library.  This extra line of code can be used to
make up for missing functionality or to load nonstandard header files.
If you need to inject more than one line of code use
@configure{--with-header=code='#include "myheaders.h"'} and create an
appropriate @file{myheaders.h} file.

@cindex variables, @file{configure} cache
@cindex @file{configure} cache variables
@cindex cache variables
Like all @cncp{Autoconf} scripts, @filespec{configure} runs a large
number of small test programs to characterize the user's system.  It
keeps track of the results of these tests in a set of @dfn{@cncp{cache
variables}}.  If a cache variable is assigned a value on the command
line, @filespec{configure} will skip the associated test and simply
assume that the cache variable's value represents the test result.
Thus, @cncp{cache variables} provide a fine level of control over the
behavior of the @filespec{configure} script and are a useful mechanism
for working around the idiosyncrasies of any given system.
@xref{Cache Variables}, for a list of many of the @cncp{cache
variables} recognized by the @ncptl{} @filespec{configure} script.

It is highly unlikely that @configure{} will fail completely.  If it
does, a working @ncptl{} system may still be possible.  Manually edit
@filespec{config.h} for your system.  (If @filespec{config.h} could
not be created, copy @filespec{config.h.in} to @filespec{config.h}.)
Do likewise for @filespec{ncptl.h}.  Finally, copy
@filespec{Makefile.simple.in} to @filespec{Makefile.simple} if
necessary and replace all text bracketed by @w{at signs} with
appropriate values or blanks.  In particular, @samp{@@DEFS@@} should
be replaced by the string @samp{-DHAVE_CONFIG_H} as this instructs the
various C files to include @filespec{config.h}.  @xref{Building on
problematic platforms}, for more information about
@filespec{Makefile.simple}.  Although @filespec{Makefile.in} can be
copied to @filespec{Makefile} and edited, doing so requires many more
string replacements.  The advantage is that the result will support
all of the options described in @ref{make}.


@node Problems with make, Problems running, Problems with configure, Troubleshooting
@section Problems with make

Once @ncptl{} is configured, the next step is to build the various
components.  This section explains what to do if a compile fails or
@kcmd{make} is otherwise unable to perform all of its operations.

@menu
* Failure following "missing" check::  
* Too many columns in multitable item::  Building Emacs info files
* Can't find compiler_version.h::  Running `make install' properly
* Could not read symbols::      Linking with the correct libraries
* Incorrect tools/flags are utilized::  ncptl ignores configure variables
* Compaq compilers on Alpha CPUs::  Dealing with compiler idiosyncrasies
* undefined type found DEFINE____::  Thwarting an excessively "smart" cpp
* "makehelper.py config" fails::  Using Cygwin Python with a non-Cygwin cpp
* Building on problematic platforms::  Hacking makefiles by hand
@end menu

@node Failure following "missing" check, Too many columns in multitable item, Problems with make, Problems with make
@subsection Failure following @file{missing} check

The @filespec{Makefile} produced by @configure{} sometimes gets
confused into thinking that it needs to recreate one or more of the
@GNU{} Autotools build files such as @filespec{aclocal.m4},
@filespec{config.h.in}, @filespec{configure}, or
@filespec{Makefile.in}.  A symptom of this confusion is an error
message following an invocation of the @filespec{missing} script:

@cartouche
@example
$ make
cd . && /bin/sh ./config.status ncptl.h
config.status: creating ncptl.h
config.status: ncptl.h is unchanged
cd . && /bin/sh /home/me/conceptual-@value{VERSION}/missing --run autoheader
@end example
@center [@i{Error message appears here.}]
@end cartouche

The source of the problem is usually an incongruous timestamp on some
file relative to that of some other file.  Unfortunately, identifying
the files in question can be difficult.  The quick fix is to edit the
@filespec{missing} script, putting @samp{exit 0} at the beginning of
the file, right after the @samp{#! /bin/sh} line.  This tells the
@filespec{Makefile} that none of the @GNU{} Autotools build files need
to be recreated.

@node Too many columns in multitable item, Can't find compiler_version.h, Failure following "missing" check, Problems with make
@subsection @samp{Too many columns in multitable item}

Very old versions of @kcmd{makeinfo} are unable to process
@filespec{conceptual.texi} into @cncp{Emacs} @samp{info}-format
documentation; instead, they fail with a large number of @samp{Too
many columns in multitable item @w{(max 1)}} errors.  Simply
re-running @kcmd{make} should bypass the failing
documentation-building step.


@node Can't find compiler_version.h, Could not read symbols, Too many columns in multitable item, Problems with make
@subsection Can't find @file{compiler_version.h}

The @ncptl{} build process currently requires @kcmd{make} to be
executed before @kcmd{make install}.  Skipping the @kcmd{make} step
results in a @filespec{compiler_version.h} error resembling the
following:

@cartouche
@example
logfilefuncs.c:18:30: compiler_version.h: No such file or directory
@end example
@end cartouche

Ergo, make sure always to run @kcmd{make} before running
@kcmd{make install}.


@node Could not read symbols, Incorrect tools/flags are utilized, Can't find compiler_version.h, Problems with make
@subsection @samp{could not read symbols}

An attempt to link the @ncptl{} run-time library on one @cncp{x86-64}
@Linux{} platform aborted with the following error:

@fiindex libpopt.so
@cartouche
@example
/usr/lib/libpopt.so: could not read symbols: File in wrong format
@end example
@end cartouche

@noindent
An attempt on another @cncp{x86-64} @Linux{} platform aborted with a
similar error:

@fiindex libpopt.so
@cartouche
@example
/usr/lib/libpopt.so: could not read symbols: Invalid operation
@end example
@end cartouche

@fiindex libpopt.so
The problem on both platforms turned out to be that the
@file{/usr/lib/libpopt.so} is a 32-bit binary and could not be linked
with a 64-bit library.  The solution was to configure with
@configure{LDFLAGS=-L/usr/lib64} to indicate that libraries should be
read from @file{/usr/lib64} instead of the default of
@file{/usr/lib64}.


@node Incorrect tools/flags are utilized, Compaq compilers on Alpha CPUs, Could not read symbols, Problems with make
@subsection Incorrect tools/flags are utilized
@cindex compiler, incorrect
@cindex flags, incorrect

@cindex Environment Modules
You might find that although you specified a particular tool or flag
at configuration time @w{(e.g., with} @samp{MPICC=mympicompiler}; see
@ref{configure}), the @filespec{ncptl} compiler seems to ignore it.  A
likely culprit is that an environment variable with the same name as
the configuration parameter is set @w{(e.g., the} @envvar{MPICC}
environment variable may be set to @samp{othermpicompiler}) and
therefore overrides all prior settings.  This situation sometimes
arises when a compiler or @MPI{} library is made available using the
Environment Modules system @w{(e.g., with} the @kcmdargs{module, load}
command).

The solution is simply to undefine or properly redefine the offending
environment variable.  In most Unix environments the @filespec{env}
command can be used to redefine an environment variable for the
duration of a single command:

@cartouche
@example
env MPICC=mympicompiler ncptl --backend=c_mpi myprogram.ncptl
@end example
@end cartouche


@node Compaq compilers on Alpha CPUs, undefined type found DEFINE____, Incorrect tools/flags are utilized, Problems with make
@subsection Compaq compilers on Alpha CPUs
@cindex compiling

Although @ncptl{} builds fine on Alpha-based systems when using a
@filespec{gcc} compiler, Compaq's C compilers are sometimes
problematic.  For instance, the @filespec{libncptl_wrap.c} source file
fails to compile on a system with the following versions of the
operating system, C compiler, and @cncp{Python} interpreter:

@cartouche
@example
% uname -a
OSF1 qsc14 V5.1 2650 alpha
% cc -V
Compaq C V6.5-011 on Compaq Tru64 UNIX V5.1B (Rev. 2650)
Compiler Driver V6.5-003 (sys) cc Driver
% python -V
Python 2.3
@end example
@end cartouche

On the system that was tested, @filespec{cc} aborts with a set of
@samp{Missing type specifier or type qualifier} messages.  The problem
appears to be that some of Compaq's standard C header files fail to
@code{#include} various header files they depend upon.  A workaround
is to insert the following @cpreproc{} directives in
@filespec{libncptl_wrap.c} before the line reading @samp{#include
"Python.h"}:

@example
#include <sys/types.h>
#include <sys/time.h>
#include <sys/stat.h>
@end example

@sp 1

A second problem with Compaq compilers on Alpha-based systems occurs
under @Linux{} when using Compaq's @filespec{ccc} compiler:

@cartouche
@example
% uname -a
Linux wi 2.4.21-3.7qsnet #2 SMP Fri Oct 17 14:08:00 MDT 2003 alpha unknown
% ccc -V
Compaq C T6.5-002 on Linux 2.4.21-3.7qsnet alpha
Compiler Driver T6.5-001 (Linux) cc Driver
Installed as ccc-6.5.6.002-1
Red Hat Linux release 7.2 (Enigma)
Using /usr/lib/gcc-lib/alpha-redhat-linux/2.96 (4).
@end example
@end cartouche

@noindent
When linking files into a shared object, @filespec{ccc} aborts with a
@samp{@r{[@dots{}]}/.libs: file not recognized: Is a directory} error
message.  The problem appears to be that @filespec{libtool} is
confused about the arguments it's supposed to pass to the linker;
@filespec{libtool} uses @samp{--rpath} (two hyphens) where the Compaq
linker expects @samp{-rpath} (one hyphen).  As a workaround, you can
edit the @filespec{libtool} file after running @configure{} but before
running @kcmd{make}.  Simply replace @samp{--rpath} with @samp{-rpath}
in the following @filespec{libtool} line and the problem should go
away:

@example
hardcode_libdir_flag_spec="\$@{wl@}--rpath \$@{wl@}\$libdir"
@end example


@node undefined type found DEFINE____, "makehelper.py config" fails, Compaq compilers on Alpha CPUs, Problems with make
@subsection @samp{undefined type, found `DEFINE_____'}
@olindex undefined type

The @w{GCC 2.95.2} compiler on at least one @w{MacOS 10.1} system
complains repeatedly about an @samp{undefined type, found
`DEFINE_____'} while trying to preprocess a data file generated by
@filespec{makehelper.py} and based upon the contents of
@filespec{config.h} @filespec{substitutions.dat}.  Fortunately, the
complaint is only a warning and can be ignored.
@cindex smart preprocessing
@fiindex cpp-precomp
The problem is that the @cpreproc{} performs ``smart preprocessing''
if given a filename on the command line (as is the case here) but
``basic preprocessing'' when reading from the standard input device.
Because the input does not represent syntactically correct @w{C
code}---the @cpreproc{} is used only as a convenient device for
performing macro substitutions---the syntax-aware smart preprocessing
fails.  However, the @cpreproc{} then reprocesses the file with basic
preprocessing (as indicated by the message @samp{cpp-precomp: warning:
errors during smart preprocessing, retrying in basic mode}) and
succeeds.


@node "makehelper.py config" fails, Building on problematic platforms, undefined type found DEFINE____, Problems with make
@subsection @kbd{makehelper.py config} fails

When @filespec{makehelper.py} is run with the @samp{config} option, it
generates a temporary @file{.c} file that it runs through the @w{C
preprocessor}.  Problems @w{(e.g., a} @samp{gcc.exe: no input files}
error message) may occur when running under @cncp{Cygwin} (a Unix-like
user environment for Microsoft Windows) with a @cncp{Cygwin}
@cncp{Python} interpreter but a non-@cncp{Cygwin} @cpreproc{}
@w{(e.g., @cncp{MinGW}'s)} because @filespec{makehelper.py} may try to
pass a Unix-style filename to the @cpreproc{}, which expects to
receive a Windows-style filename.

A workaround is to specify explicitly a temporary directory for
@filespec{makehelper.py} to use.  Use forward slashes and filenames
without spaces @w{(e.g., DOS-style} 8.3 filenames) as in the following
example:

@example
make TEMP=C:/DOCUME~1/user/LOCALS~1/Temp
@end example


@node Building on problematic platforms,  , "makehelper.py config" fails, Problems with make
@subsection Building on problematic platforms
@cindex building

Some experimental systems require rather specialized build procedures
that thwart @ncptl{}'s standard makefile.  Unfortunately,
@filespec{Makefile} is complex and difficult to edit by hand.  Users
comfortable with @cncp{Automake} should edit
@filespec{Makefile.am}---which is used to generate
@filespec{Makefile}---and re-run @kcmd{automake}, @kcmd{autoconf}, and
@configure{} as described in @ref{make}.

@ncptl{} includes an alternate Makefile called
@filespec{Makefile.simple} (generated at configuration time from
@filespec{Makefile.simple.in}).  @filespec{Makefile.simple} is a
stripped-down version of @filespec{Makefile} that is designed to be
easy to edit by hand.  @kcmdargs{make, -f Makefile.simple} builds a
static version of the @ncptl{} run-time library in the current
directory.  @kcmdargs{make, -f Makefile.simple clean} deletes the
run-time library and all of the object files used to build it.
@filespec{Makefile.simple} supports no other features.  The intention
is to provide the bare minimum needed to get backends such as
@backend{c_mpi} to produce executable programs even when running in
unusual environments.


@node Problems running, When all else fails, Problems with make, Troubleshooting
@section Problems running
@cindex running programs

After @ncptl{} is configured, compiled, built, and installed, there is
still the chance that @ncptl{}-generated executables fail to run.
This section addresses some common problems and presents their
solutions.

As a quick tip, a very conservative way to run a @ncptl{} program is
with the @envvar{NCPTL_NOFORK} environment variable set to @samp{1},
the @envvar{NCPTL_CHECKPOINT} environment variable set to @samp{0},
and with @coptargs{no-trap, 1-63} on the command line.  Such usage
should work around some of the most common---and some of the hardest
to diagnose---problems that may impact a @ncptl{} program.  Read the
corresponding sections (@ref{Miscellaneous mysterious hangs or
crashes}; @ref{Extremely noisy measurements}; and, @ref{Keeping
programs from dying on a signal}) for information about the drawbacks
of each of the preceding settings.

@menu
* ``cannot open shared object file''::  Preventing problems with libncptl.so
* Miscellaneous mysterious hangs or crashes::  Programs die inexplicably
* Extremely noisy measurements::  Data exhibits excessive variability
* Keeping programs from dying on a signal::  Handling unexpected terminations
* ``Unaligned access'' warnings::  What these mean and how to prevent them
* ``Unable to determine the OS page size''::  Specifying page sizes
* Invalid timing measurements::  coNCePTuaL's timer is completely wrong
* ``TeX capacity exceeded''::   Problems drawing complex diagrams with latex_vis
* Bad bounding boxes from latex_vis::  Generated pictures are truncated
@end menu


@node ``cannot open shared object file'', Miscellaneous mysterious hangs or crashes, Problems running, Problems running
@subsection @samp{cannot open shared object file}
@cindex shared objects
@cindex dynamic libraries
@cindex libraries, dynamic

A common problem on many workstation clusters is that the head node
(on which @configure{} is run) has more libraries installed than do
the compute nodes (on which @ncptl{} programs themselves are run).
Consequently, @ncptl{} programs that compile and link properly on the
head node will fail with a @samp{cannot open shared object file} error
if they try to dynamically link a shared object that is absent on the
compute nodes.

Ideally, the missing shared objects should be installed on each of the
compute nodes.  If they cannot be installed in their standard
locations @w{(e.g., @file{/usr/lib})}, they can be installed elsewhere
@w{(e.g., in} the user's home directory) and that location can be
pointed to using @copts{rpath} or @envvar{LD_LIBRARY_PATH}, as
described below.  Alternatively, @filespec{configure} can be
instructed to disregard certain libraries---even if they exist on the
head node---by passing the @copt{with-ignored-libs} option to
@filespec{configure} (@pxref{configure}).  For example, if
@filespec{libpopt.so} is not installed on the compute nodes one can
run @configure{--with-ignored-libs=popt} to prevent
@filespec{libpopt.so} from being used.

The @copt{with-ignored-libs} option is of little use if the @ncptl{}
library itself cannot be found at run time.  By default, @kcmd{make}
will build and @kcmd{make install} will install both a static and a
dynamic version of the @ncptl{} run-time library.  Most linkers give
precedence to the dynamic library over the static library unless the
static library is requested explicitly.  As a consequence, the dynamic
version of the @ncptl{} run-time library needs to be available at
program-load time in order to avoid error messages like the following:

@cartouche
@example
a.out: error while loading shared libraries: libncptl.so.0: cannot open
shared object file: No such file or directory
@end example
@end cartouche

There are a few alternatives for pointing the dynamic loader to the
@ncptl{} run-time library.  On systems that support it, the best
option is the @copts{rpath} approach described in @ref{Implicit
dynamic-library search paths}.  The second-best option is to add the
directory in which @filespec{libncptl.so} was installed (by default,
@file{/usr/local/lib}) to your @envvar{LD_LIBRARY_PATH} environment
variable.  Finally, as a last resort, you can use the
@copt{disable-shared} configuration option (@pxref{configure}) to
prevent @ncptl{} from building the dynamic version of the run-time
library altogether, thereby forcing the linker to use the static
version:

@cartouche
@kyindex make uninstall
@kyindex make clean
@kyindex configure
@kyindex make
@kyindex make install
@example
make uninstall
make clean
./configure --disable-shared @dots{}
make
make install
@end example
@end cartouche

@noindent
As mentioned in @ref{configure}, however, @filespec{libncptlmodule.so}
can't be built when @copt{disable-shared} is in effect.


@node Miscellaneous mysterious hangs or crashes, Extremely noisy measurements, ``cannot open shared object file'', Problems running
@subsection Miscellaneous mysterious hangs or crashes
@cindex crashed processes
@cindex hung processes

In some implementations of the software stack for
@cncp{InfiniBand}---and possibly for some other networks as
well---invocations of the @ocodecf{fork} system call made while the
network device is open can corrupt process memory and hang or crash
the corresponding process.  (On Unix and Unix-like operating systems
this is typically via a @cncp{segmentation fault}.)

The workaround is to build @ncptl{} using the @copt{without-fork}
option (@pxref{configure}).  Alternatively, you can set the
@envvar{NCPTL_NOFORK} environment variable when running a @ncptl{}
program.  Either option suppresses the @ncptl{} run-time library's use
of all process-spawning functions.  @xref{Environment Variables}, for
a description of @envvar{NCPTL_NOFORK}'s side effects.  The same
description also applies to @copt{without-fork}.

@sp 1

The C library that comes bundled with a lightweight run-time kernel or
other custom operating system may provide broken versions of some of
the functions on which the @ncptl{} run-time library relies.  If a
debugger or crash-analysis tool indicates that a particular function
is problematic it may be possible to disable that function at
configuration time.  For example, the current (at the time of this
writing) release of @cncp{Red Storm}'s software stack includes a
faulty @ocodecf{getrusage} function that crashes consistently.
Observing that @filespec{configure} checks for @ocodecf{getrusage} we
searched the generated @filespec{config.log} file and encountered the
corresponding shell variable, @samp{ac_cv_func_getrusage}, which was
set to @samp{yes}.  Rerunning @configure{} with
@samp{ac_cv_func_getrusage=no} on the command line disabled the
@ncptl{} run-time library's use of @ocodecf{getrusage} and thereby
resulted in crash-free execution of @ncptl{} programs.


@node Extremely noisy measurements, Keeping programs from dying on a signal, Miscellaneous mysterious hangs or crashes, Problems running
@subsection Extremely noisy measurements
@cindex variability in data values

Sometimes a @ncptl{} program runs to completion but the data written
to the log files exhibit high levels of variability across runs or
even across trials within a single run.  A possible source of this
variability---especially for long-running programs running on a large
number of processors---is the run-time library's log-file
checkpointing mechanism.  Because each process in a @ncptl{} programs
writes its own log file, poorly scalable shared filesystems, limited
spare network bandwidth, and asynchronous operating-system buffer
flushes may each impact program performance in an unpredictable manner
and at unpredictable times.

Setting the @envvar{NCPTL_CHECKPOINT} environment variable to @samp{0}
disables log-file checkpointing and may thereby reduce some of the
data variability.  The caveat is that a program that aborts abnormally
will leave behind @emph{no} data in its log files.  @xref{Environment
Variables}, for more information about @envvar{NCPTL_CHECKPOINT}.


@node Keeping programs from dying on a signal, ``Unaligned access'' warnings, Extremely noisy measurements, Problems running
@subsection Keeping programs from dying on a signal
@cindex signals
@kyindex Received signal

By default, @ncptl{} programs terminate upon receiving @emph{any}
unexpected signal.  The error message list the signal number and, if
available, a human-readable signal name:

@cartouche
@example
myprogram: Received signal 28 (Window changed); specify --no-trap=28 to
ignore
@end example
@end cartouche

The motivation behind this decision to abort on unexpected signals is
that signal-handling adversely affects a program's performance.
Hence, by running to completion, a program indicates that it did not
receive any unexpected signals.  However, some messaging layers use
signals internally (most commonly @code{SIGUSR1} and @code{SIGUSR2})
to coordinate helper processes.  To permit a program to deliver such
signals to the messaging layer a user should use the program's
@copt{no-trap} command-line option as described in @ref{Running
coNCePTuaL programs}.


@node ``Unaligned access'' warnings, ``Unable to determine the OS page size'', Keeping programs from dying on a signal, Problems running
@subsection @samp{Unaligned access} warnings
@cindex unaligned accesses

On some platforms you may encounter messages like the following
written to the console and/or various system log files (e.g.,
@filespec{/var/log/messages}):

@example
myprog(25044): unaligned access to 0x6000000000001022,
ip=0x40000000000009e1
@end example

@noindent
Alternatively:

@example
Unaligned access pid=7890104 <myprog> va=0x140004221 pc=0x1200012b4
ra=0x1200012a4 inst=0xb449fff8
@end example

What's happening is that some CPUs require @math{n}-byte-wide data to
be aligned on an @math{n}-byte boundary.  For example, a 64-bit
datatype can be accessed properly only from memory locations whose
address is a multiple of @w{64 bits} @w{(8 bytes)}.  On some
platforms, misaligned accesses abnormally terminate the program,
typically with a @code{SIGBUS} signal.  On other platforms, misaligned
accesses interrupt the operating system.  The operating system fixes
the access by splitting it into multiple aligned accesses plus some
bit masking and shifting and then notifying the user and/or system
administrator that a fixup occurred.

@ncptl{}'s @filespec{configure} script automatically determines what
data alignments are allowed by the architecture but it has no way to
determine if fixups occurred as these are transparent to programs.
The result is annoying ``unaligned access'' messages such as those
quoted above.  One solution is to use the @copt{with-alignment} option
to @filespec{configure} to specify explicitly the minimum data
alignment that @ncptl{} should be permitted to use.  Alternatively,
some operating systems provide a mechanism to cause misaligned
accesses to result in a @code{SIGBUS} signal instead of a fixup and
notification message.  On @Linux{}/IA-64 this is achieved with the
command
@fiindex prctl
@kbd{prctl --unaligned=signal}.  On OSF1/Alpha the equivalent command
is
@fiindex uac
@kbd{uac p sigbus}.  Be sure to rerun @filespec{configure} after
issuing those commands to make it reexamine the set of valid data
alignments.


@node ``Unable to determine the OS page size'', Invalid timing measurements, ``Unaligned access'' warnings, Problems running
@subsection @samp{Unable to determine the OS page size}

To implement @keyw{PAGE ALIGNED} messages (@pxref{Message alignment})
a program needs to be able to query the operating system's page size.
The @ncptl{} run-time library performs this query using one of the
@ocodecf{getpagesize} or @ocodecf{sysconf} operating-system calls.  If
neither call is available or functional the run-time library aborts
with an @samp{Unable to determine the OS page size} error.

As a workaround, @filespec{configure} provides a @copt{with-page-size}
option that enables the user to manually specify the page size.
Because any manually specified value is prone to error, @ncptl{} log
files include a @samp{Page size was specified manually at
configuration time} warning if the run-time library was configured
using @copt{with-page-size}.


@node Invalid timing measurements, ``TeX capacity exceeded'', ``Unable to determine the OS page size'', Problems running
@subsection Invalid timing measurements
@cindex timings, invalid
@cindex clock, incorrect readings

Although the @ncptl{} @filespec{configure} script is usually good at
selecting a mechanism for measuring elapsed time, there are a few
systems that confuse the script.  For example, different Intel
processors use different mechanisms for mapping cycle counts to time
(cf. @url{http://en.wikipedia.org/wiki/RDTSC}); the correct mapping
cannot always be determined at configuration time and may require
administrator privileges to calculate.  Consequently, if
@filespec{configure} determines that the @ncptl{} timer should read
the cycle counter directly, incorrect times may be reported.

The best way to test the timer quality is to run the
@filespec{validatetimer} program (@pxref{Validating the coNCePTuaL
timer}).  If the difference between wall-clock time and
@ncptl{}-reported time is great, the @copt{with-gettimeofday}
configuration option (@pxref{configure}) is usually a safe bet for
improving accuracy, albeit at a slight cost in measurement overhead.


@node ``TeX capacity exceeded'', Bad bounding boxes from latex_vis, Invalid timing measurements, Problems running
@subsection @samp{TeX capacity exceeded}

@TEX{}---and by consequence, @latex{}---does not use dynamically
allocated memory.  Therefore, attempting to produce a very large
diagram with the @backend{latex_vis} backend (@pxref{The latex_vis
backend}) will likely exceed @TEX{}'s hardwired memory capacity:

@cartouche
@example
! TeX capacity exceeded, sorry [main memory size=350001].
\psm@@endnode@@i ... \endgroup \psm@@endmath \egroup
                                                  \use@@par \@@psttrue
l.489 \task
           @{0@} & \task@{1@} \\
No pages of output.
@end example
@end cartouche

@noindent
@TEX{}/@latex{}'s memory capacity can be increased but the mechanism
for doing so varies from one @TEX{} distribution to another and is
rarely straightforward.  See
@uref{http://www.tex.ac.uk/cgi-bin/texfaq2html?label=enlarge} for a
few terse pointers.  In general, it is best to try to minimize the
number of loop repetitions when running programs through the
@backend{latex_vis} backend.

An alternative is to use a prebuilt large-memory @filespec{latex}.
Some @TEX{} distributions come with a @filespec{hugelatex} executable,
which is just like @file{latex} but compiled with larger memory
limits.  @filespec{ncptl} can be told to use @filespec{hugelatex} by
setting the @envvar{LATEX} environment variable (e.g., with @samp{env
LATEX=hugelatex ncptl @dots{}}).  This may be the most convenient way
to produce complex diagrams with @backend{latex_vis} when simplifying
the run is not an option.


@node Bad bounding boxes from latex_vis,  , ``TeX capacity exceeded'', Problems running
@subsection Bad bounding boxes from @code{latex_vis}
@cindex bounding box

Very tall program visualizations are susceptible to @cncp{Ghostscript}
@w{bug #202735}, ``bbox device doesn't allow min @w{coords < 0}''.
@backend{latex_vis} attempts to work around that bug by defining a
large @cncp{PostScript} @code{ImagingBBox} as described in
@url{http://bugs.ghostscript.com/show_bug.cgi?id=202735}.  While no
problems with the @backend{latex_vis} workaround have yet been
reported, if problems do occur it should be sufficient to set the
@envvar{GS} environment variable to @samp{:} or the name of a program
known not to exist.  @backend{latex_vis} will then issue a warning
message and generate an EPS file with an acceptable but slightly loose
@cncp{bounding box}, as mentioned in @ref{The latex_vis backend}.


@node When all else fails,  , Problems running, Troubleshooting
@section When all else fails

The @ncptl{} project pages on
@uref{http://sourceforge.net/, SourceForge.net} provide a variety of
mechanisms for providing feedback to the @ncptl{} developers:

@table @asis
@item Mailing lists
Read and post messages on the @ncptl{} mailing lists at
@uref{http://sourceforge.net/mail/?group_id=117615}.

@item Trackers
Search for old or post new
@uref{http://sourceforge.net/tracker/?group_id=117615&atid=678627, bug
reports},
@uref{http://sourceforge.net/tracker/?group_id=117615&atid=678630,
feature requests}, or
@uref{http://sourceforge.net/tracker/?group_id=117615&atid=678629,
code patches} at
@uref{http://sourceforge.net/tracker/?group_id=117615}.
@end table


@node Reserved Words, Backend Developer's Reference, Troubleshooting, Top
@appendix Reserved Words
@cindex reserved words

As mentioned in @ref{Primitives}, not all identifiers can be used as
variables.  The following sections provide a complete list of
identifiers that are forbidden as variable names.  These identifiers
fall into two categories: keywords, which are never allowed as
variable names, and predeclared variables, which are ``read-only''
variables; they can be utilized just like any other variables but
cannot be redeclared.

@menu
* Keywords::                    List of coNCePTuaL keywords
* Predeclared variables::       List of variables made available to programs
@end menu


@node Keywords, Predeclared variables, Reserved Words, Reserved Words
@appendixsec Keywords
@cindex keywords

The following is a list of all currently defined keywords in the
@ncptl{} language.  It is an error to try to use any of these as
identifiers.

@include keywords.texi


@node Predeclared variables,  , Keywords, Reserved Words
@appendixsec Predeclared variables
@cindex predeclared variables
@cindex variables, predeclared

@ncptl{} predeclares a set of variables that programs can use but not
redeclare.  These variables and their descriptions are listed below.

@include variables.texi

As should be evident from their descriptions, @ncptl{}'s predeclared
variables are updated dynamically.  Each access can potentially return
a different result.  Furthermore, unlike user-declared variables,
predeclared variables in can have a different value on each task.

The following notes clarify the semantics that relate to the updating
of some of the preceding variables:

@table @asis
@item @keyw{ASYNCHRONOUSLY} (@pxref{Blocking semantics})
A message that is @emph{sent} @keyw{ASYNCHRONOUSLY} immediately
increments each of @ocode{msgs_sent} and @ocode{total_msgs} @w{by 1}
and each of @ocode{bytes_sent} and @ocode{total_bytes} by the message
size.  A message that is @emph{received} @keyw{ASYNCHRONOUSLY}
increments none of the predeclared variables.  However, after the
receiving task @keyw{AWAITS COMPLETION} (@pxref{Awaiting completion})
it increments each of @ocode{msgs_received} and @ocode{total_msgs}
@w{by 1} and each of @ocode{bytes_received} and @ocode{total_bytes} by
the message size.

@item @keyw{MULTICASTS} (@pxref{Multicasting})
None of the byte or message variables are updated as part of a
multicast operation, regardless of how the underlying messaging layer
implements multicasts.

@item @keyw{SYNCHRONIZES} (@pxref{Synchronizing})
None of the byte or message variables are updated as part of a barrier
synchronization, regardless of how the underlying messaging layer
implements barriers.
@end table


@node Backend Developer's Reference, Environment Variables, Reserved Words, Top
@appendix Backend Developer's Reference

Programmers wishing to develop their own @ncptl{} backends can refer
to the information presented in this appendix as a complement to the
more tutorial-in-nature @ref{Implementation}.

@menu
* Method calls::                Methods a backend must implement
* C hooks::                     Methods a C-based backend may implement
* Event types::                 Types of events defined by c_generic programs
* Representing aggregate functions::  An enumerated type of aggregates
@end menu


@node Method calls, C hooks, Backend Developer's Reference, Backend Developer's Reference
@appendixsec Method calls

The following method calls must be defined when writing a @ncptl{}
backend from scratch.  They are invoked indirectly as part of @PLY{}'s
@AST{} traversal.  @xref{Backend creation}, for more information.

@include methods.texi


@node C hooks, Event types, Method calls, Backend Developer's Reference
@appendixsec C hooks

To save the backend developer from having to implement @ncptl{}
backends entirely from scratch, @ncptl{} provides a
@backendpy{c_generic} module that defines a base class for
code generators that output C code.  The base class handles the
features that are specific to C but independent of any messaging
library.  Derived classes need only define those ``hook'' functions
that are needed to implement library-specific functionality.

Hooks are named after the method from which they're called but with an
all-uppercase tag appended.  The following list shows each
hook-calling method in @backendpy{c_generic} and the set of
hooks it calls.  @xref{Hook methods}, for more information.

@include c_hooks.texi


@node Event types, Representing aggregate functions, C hooks, Backend Developer's Reference
@appendixsec Event types

Programs generated by @backendpy{c_generic} define the
following event types:

@cindex event types, defined by @file{codegen_c_generic.py}
@include eventlist.texi

@ref{Generated code}, motivates the use of event-based execution for
@ncptl{} programs.


@node Representing aggregate functions,  , Event types, Backend Developer's Reference
@appendixsec Representing aggregate functions
@cindex aggregate functions
@cindex functions, aggregate

The @ocode{LOG_AGGREGATE} enumerated type, defined in
@filespec{ncptl.h}, accepts the following values:

@include aggregates.texi


@node Environment Variables, Cache Variables, Backend Developer's Reference, Top
@appendix Environment Variables
@cindex environment variables
@cindex variables, environment

The @ncptl{} compiler (@filespec{ncptl}) honors the following
environment variables:

@table @envvar
@item NCPTL_BACKEND
Name a default backend for the compiler to use.  For example, setting
@envvar{NCPTL_BACKEND} to @samp{c_udgram} tells @filespec{ncptl} to
use the @backend{c_udgram} backend unless the @copt{backend} compiler
option designates a different backend.  @xref{Compiling coNCePTuaL
programs}, for more information.

@item NCPTL_PATH
Specify a colon-separated list of directories in which to search for
compiler backends.  @xref{Compiling coNCePTuaL programs}, for more
information.
@end table

The following environment variables are honored when running a
@ncptl{} program (any backend):

@table @envvar
@item NCPTL_CHECKPOINT
Specify the minimum number of seconds between log-file checkpoints
(default: 60).  The @ncptl{} run-time library buffers logged data in
memory because @ncptl{} programs are not restricted to writing data in
a top-to-bottom, left-to-right format.  The following program, for
example, writes @w{row 9}, @w{column 2} before writing @w{row 5},
@w{column 1}:

@example
FOR EACH i IN @{1, ..., 10@} @{IF i IS EVEN THEN TASK 0 LOGS i
AS "Even numbers" THEN TASK 0 LOGS i AS "All numbers"@}
@end example

@iindent
Buffering data in memory enables that sort of ``two-dimensional''
logging.  However, it is not robust to computer crashes or uncatchable
signals @w{(e.g., @code{SIGKILL})}.  Consequently, every @keyw{LOGS}
statement (@pxref{Writing to a log file}) that is executed at least
@envvar{NCPTL_CHECKPOINT} seconds after the previous one forces the
@ncptl{} run-time library to write its partial data to the log file.
Specifically, the library flushes its partial-data buffers then
rewinds the write pointer to the beginning of that partial data.
Hence, the partial data is overwritten by a later checkpoint or by the
complete data set.

@iindent
Smaller values of @envvar{NCPTL_CHECKPOINT} provide more robustness to
crashes and uncatchable signals.  Larger values put less stress on the
filesystem.  As a special case, if @envvar{NCPTL_CHECKPOINT} is set to
@samp{0} then log-file checkpointing is disabled altogether.

@item NCPTL_FAST_INIT
If set to @samp{1}, more quickly initialize the run-time library by
skipping the timer calibration and measurement steps.  As a
consequence, all timing measurements will be meaningless.
@envvar{NCPTL_FAST_INIT} may be useful during the development of a
@ncptl{} program or compiler backend to enable shorter turnaround
times.  If set to @samp{0}, @envvar{NCPTL_FAST_INIT} forces a thorough
initialization even for backends that do not rely on timing
measurements, for instance the @backend{picl} backend (@pxref{The picl
backend}).  @xref{Variables and data types}, for more information.

@item NCPTL_LOG_DELAY
Artificially delay each log-file open and flush operation by a random
number of milliseconds in the range 0@dots{}@envvar{NCPTL_LOG_DELAY}
(default: @samp{0}).  For example, if 1000 CPUs share a single
filesystem, an @envvar{NCPTL_LOG_DELAY} of @samp{2000} @w{(i.e., 2
seconds)} will probabilistically ensure that a log-file creation
request will be issued only once every @texmath{2000 \div 1000 = 2,
2000/1000 = 2} milliseconds instead of all at once.
@envvar{NCPTL_LOG_DELAY} is intended to help @ncptl{} programs run
atop broken filesystems that are unable to handle large numbers of
concurrent accesses---an all-too-common problem on large-scale
workstation clusters and parallel computers in which hundreds or
thousands of diskless compute nodes compete for access to the same
filesystem.

@item NCPTL_LOG_ONLY
Limit the set of processes that produce log files.
@envvar{NCPTL_LOG_ONLY} accepts a comma-separated list of
dash-separated process ranges such as @samp{0-3,12-16,24,25,32-48}.
Only processes included in the list produce log files.  @xref{Running
coNCePTuaL programs}, for more information.

@item NCPTL_NOFORK
If set, inhibit the use of @ocodecf{fork}, @ocodecf{system},
@ocodecf{popen}, and other process-spawning functions.  The result is
that some information will be omitted from the log-file prologue.
@envvar{NCPTL_NOFORK} is intended to be used on systems in which such
functions corrupt messaging-layer state, hang or crash processes, or
wreak other such havoc.
@end table


@node Cache Variables, Referenced Applications, Environment Variables, Top
@appendix @file{configure} Cache Variables
@cindex variables, @file{configure} cache
@cindex @file{configure} cache variables
@cindex cache variables

The @filespec{configure} script that is used to build @ncptl{}
internally uses a number of @cncp{Autoconf} cache variables to store
configuration information that it discovers while it runs.  If these
variables are set on the @configure{} command line, the given value
will be used instead of an automatically determined value.  This
feature gives the user precise control over many aspects of @ncptl{}
configuration.  For example, to prevent the @ncptl{} run-time library
from using the @ocodecf{gethostbyname} function you can specify
@samp{ac_cv_func_gethostbyname=no} on the @configure{} command line to
convince @filespec{configure} that @ocodecf{gethostbyname} does not
exist.

The variables and descriptions in the following list were extracted
mechanically from @filespec{configure.ac} and @filespec{config.log}.
Consequently, some variables may be missing, and some descriptions may
be inaccurate or hard to understand.

@include cachevars.texi


@node Referenced Applications, License, Cache Variables, Top
@unnumbered Referenced Applications

A number of third-party applications are mentioned throughout this
document.  For your convenience, the following list states the URL of
each application's home page.

@table @asis
@item @cncp{a2ps}
@uref{http://www.gnu.org/software/a2ps/}

@item @cncp{Dimemas}
See @cncp{Paraver}.

@item @cncp{dot}
See @cncp{Graphviz}.

@item @cncp{Emacs}
@uref{http://www.gnu.org/software/emacs/}

@item @cncp{Extrae}
See @cncp{Paraver}.

@item Environment Modules
@uref{http://modules.sourceforge.net/}

@item @cncp{GeSHi}
@uref{http://qbnz.com/highlighter/}

@item @cncp{Graphviz}
@uref{http://www.graphviz.org/}

@item @latex{}
@uref{http://www.latex-project.org/}

@item @cncp{LibSea}
@uref{http://www.caida.org/tools/visualization/libsea/}

@item @cncp{Mediawiki}
@uref{http://www.mediawiki.org/}

@item @cncp{MPICL}
@uref{http://www.csm.ornl.gov/picl/}

@item @cncp{ParaGraph}
@uref{http://www.csar.uiuc.edu/software/paragraph/}

@item @cncp{Paraver}
@uref{http://www.bsc.es/paraver}

@item @cncp{PICL}
See @cncp{MPICL}.

@item @cncp{pkg-config}
@uref{http://pkg-config.freedesktop.org/wiki/}

@item @cncp{PSTricks}
@uref{http://www.tug.org/applications/PSTricks/}

@item @cncp{Python}
@uref{http://www.python.org/}

@item @cncp{SLOCCount}
@uref{http://www.dwheeler.com/sloccount/}

@item @cncp{Source-highlight}
@uref{http://www.gnu.org/software/src-highlite/}

@item @TEX{}
See @latex{}.

@item @cncp{Vim}
@uref{http://www.vim.org/}

@item @cncp{Walrus}
@uref{http://www.caida.org/tools/visualization/walrus/}
@end table


@node License, Index, Referenced Applications, Top
@unnumbered License

@cartouche
@noindent
@include license.texi

@end cartouche

@iftex
@sp 3
@end iftex

@subsubheading Summary

This is a BSD license with the additional proviso that modified
versions of @ncptl{} must indicate that they are, in fact, modified.


@node Index,  , License, Top
@unnumbered Index

@printindex al

@bye
